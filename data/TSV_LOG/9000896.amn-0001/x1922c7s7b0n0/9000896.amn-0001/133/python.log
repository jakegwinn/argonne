2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/133', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '133', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/133/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/133', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c7s7b0n0.133.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/133/0.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/133'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x14f431bf9be0>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/133/0.1.model.h5
2024-05-22 19:47:23 Between random pairs in y_val:
2024-05-22 19:47:23   mse: 0.04767920
2024-05-22 19:47:23   mae: 0.16005990
2024-05-22 19:47:23   r2: -1.00023588
2024-05-22 19:47:23   corr: -0.00011794
2024-05-22 19:47:23 Data points per epoch: train = 469620, val = 117405, test = 684
2024-05-22 19:47:23 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-22 19:47:24 Epoch 0: lr=0.001
2024-05-22 19:48:35 [Epoch: 0] loss: 0.026878, mae: 0.079392, r2: -0.154953, val_loss: 0.009338, val_mae: 0.068233, val_r2: 0.541865
2024-05-22 19:48:35 Epoch 1: lr=0.00082
2024-05-22 19:49:45 [Epoch: 1] loss: 0.008004, mae: 0.064016, r2: 0.619920, val_loss: 0.007726, val_mae: 0.061596, val_r2: 0.630561
2024-05-22 19:49:45 Epoch 2: lr=0.00064
2024-05-22 19:50:55 [Epoch: 2] loss: 0.007326, mae: 0.060843, r2: 0.651103, val_loss: 0.007166, val_mae: 0.061552, val_r2: 0.658277
2024-05-22 19:50:55 Epoch 3: lr=0.00046
2024-05-22 19:52:05 [Epoch: 3] loss: 0.006850, mae: 0.058724, r2: 0.672843, val_loss: 0.006823, val_mae: 0.059681, val_r2: 0.672166
2024-05-22 19:52:05 Epoch 4: lr=0.00028
2024-05-22 19:53:15 [Epoch: 4] loss: 0.006445, mae: 0.056834, r2: 0.691871, val_loss: 0.006478, val_mae: 0.056544, val_r2: 0.688592
2024-05-22 19:53:15 Epoch 5: lr=0.0001
2024-05-22 19:54:25 [Epoch: 5] loss: 0.006114, mae: 0.055312, r2: 0.706887, val_loss: 0.006339, val_mae: 0.055939, val_r2: 0.696040
2024-05-22 19:54:25 Epoch 6: lr=0.0001
2024-05-22 19:55:35 [Epoch: 6] loss: 0.006004, mae: 0.054811, r2: 0.712024, val_loss: 0.006305, val_mae: 0.056254, val_r2: 0.696318
2024-05-22 19:55:35 Epoch 7: lr=0.0001
2024-05-22 19:56:45 [Epoch: 7] loss: 0.005921, mae: 0.054400, r2: 0.715974, val_loss: 0.006249, val_mae: 0.055691, val_r2: 0.699512
2024-05-22 19:56:45 Epoch 8: lr=0.0001
2024-05-22 19:57:55 [Epoch: 8] loss: 0.005850, mae: 0.054122, r2: 0.719121, val_loss: 0.006270, val_mae: 0.056484, val_r2: 0.698185
2024-05-22 19:57:55 Epoch 9: lr=0.0001
2024-05-22 19:59:05 [Epoch: 9] loss: 0.005791, mae: 0.053829, r2: 0.721980, val_loss: 0.006199, val_mae: 0.055184, val_r2: 0.702441
2024-05-22 19:59:05 Epoch 10: lr=0.0001
2024-05-22 20:00:15 [Epoch: 10] loss: 0.005736, mae: 0.053573, r2: 0.724750, val_loss: 0.006200, val_mae: 0.055071, val_r2: 0.702453
2024-05-22 20:00:15 Epoch 11: lr=0.0001
2024-05-22 20:01:25 [Epoch: 11] loss: 0.005683, mae: 0.053340, r2: 0.726970, val_loss: 0.006164, val_mae: 0.054902, val_r2: 0.702793
2024-05-22 20:01:25 Epoch 12: lr=0.0001
2024-05-22 20:02:35 [Epoch: 12] loss: 0.005618, mae: 0.053037, r2: 0.730085, val_loss: 0.006180, val_mae: 0.054908, val_r2: 0.701911
2024-05-22 20:02:35 Epoch 13: lr=0.0001
2024-05-22 20:03:45 [Epoch: 13] loss: 0.005566, mae: 0.052818, r2: 0.732453, val_loss: 0.006149, val_mae: 0.054942, val_r2: 0.703782
2024-05-22 20:03:45 Epoch 14: lr=0.0001
2024-05-22 20:04:55 [Epoch: 14] loss: 0.005510, mae: 0.052540, r2: 0.735111, val_loss: 0.006133, val_mae: 0.055019, val_r2: 0.704218
2024-05-22 20:04:55 Epoch 15: lr=5e-05
2024-05-22 20:06:06 [Epoch: 15] loss: 0.005396, mae: 0.052010, r2: 0.740176, val_loss: 0.006106, val_mae: 0.054530, val_r2: 0.707388
2024-05-22 20:06:06 Epoch 16: lr=5e-05
2024-05-22 20:07:16 [Epoch: 16] loss: 0.005355, mae: 0.051821, r2: 0.742351, val_loss: 0.006114, val_mae: 0.054420, val_r2: 0.707124
2024-05-22 20:07:16 Epoch 17: lr=5e-05
2024-05-22 20:08:26 [Epoch: 17] loss: 0.005316, mae: 0.051662, r2: 0.744107, val_loss: 0.006074, val_mae: 0.054404, val_r2: 0.707814
2024-05-22 20:08:26 Epoch 18: lr=5e-05
2024-05-22 20:09:36 [Epoch: 18] loss: 0.005279, mae: 0.051518, r2: 0.745601, val_loss: 0.006072, val_mae: 0.054479, val_r2: 0.708598
2024-05-22 20:09:36 Epoch 19: lr=5e-05
2024-05-22 20:10:47 [Epoch: 19] loss: 0.005263, mae: 0.051382, r2: 0.746662, val_loss: 0.006100, val_mae: 0.054570, val_r2: 0.705568
2024-05-22 20:10:47 Epoch 20: lr=5e-05
2024-05-22 20:11:57 [Epoch: 20] loss: 0.005234, mae: 0.051274, r2: 0.748047, val_loss: 0.006066, val_mae: 0.054459, val_r2: 0.708278
2024-05-22 20:11:57 Epoch 21: lr=5e-05
2024-05-22 20:13:07 [Epoch: 21] loss: 0.005203, mae: 0.051138, r2: 0.749389, val_loss: 0.006072, val_mae: 0.054781, val_r2: 0.708220
2024-05-22 20:13:07 Epoch 22: lr=5e-05
2024-05-22 20:14:17 [Epoch: 22] loss: 0.005180, mae: 0.051035, r2: 0.750448, val_loss: 0.006068, val_mae: 0.054294, val_r2: 0.708426
2024-05-22 20:14:18 Epoch 23: lr=2.5e-05
2024-05-22 20:15:28 [Epoch: 23] loss: 0.005126, mae: 0.050776, r2: 0.752761, val_loss: 0.006060, val_mae: 0.054318, val_r2: 0.708838
2024-05-22 20:15:28 Epoch 24: lr=2.5e-05
2024-05-22 20:16:38 [Epoch: 24] loss: 0.005092, mae: 0.050635, r2: 0.754571, val_loss: 0.006066, val_mae: 0.054404, val_r2: 0.708637
2024-05-22 20:16:38 Epoch 25: lr=2.5e-05
2024-05-22 20:17:48 [Epoch: 25] loss: 0.005079, mae: 0.050550, r2: 0.754862, val_loss: 0.006060, val_mae: 0.054223, val_r2: 0.709163
2024-05-22 20:17:48 Epoch 26: lr=2.5e-05
2024-05-22 20:18:58 [Epoch: 26] loss: 0.005064, mae: 0.050457, r2: 0.755614, val_loss: 0.006074, val_mae: 0.054320, val_r2: 0.708189
2024-05-22 20:18:58 Epoch 27: lr=2.5e-05
2024-05-22 20:20:08 [Epoch: 27] loss: 0.005053, mae: 0.050433, r2: 0.756104, val_loss: 0.006068, val_mae: 0.054210, val_r2: 0.709032
2024-05-22 20:20:08 Epoch 28: lr=1.25e-05
2024-05-22 20:21:19 [Epoch: 28] loss: 0.005017, mae: 0.050290, r2: 0.757787, val_loss: 0.006080, val_mae: 0.054332, val_r2: 0.708154
2024-05-22 20:21:19 Epoch 29: lr=1.25e-05
2024-05-22 20:22:29 [Epoch: 29] loss: 0.005009, mae: 0.050221, r2: 0.758386, val_loss: 0.006084, val_mae: 0.054326, val_r2: 0.707852
2024-05-22 20:22:29 Epoch 30: lr=1.25e-05
2024-05-22 20:23:40 [Epoch: 30] loss: 0.005015, mae: 0.050245, r2: 0.757993, val_loss: 0.006048, val_mae: 0.054290, val_r2: 0.708951
2024-05-22 20:23:40 Epoch 31: lr=1.25e-05
2024-05-22 20:24:50 [Epoch: 31] loss: 0.004988, mae: 0.050157, r2: 0.759126, val_loss: 0.006062, val_mae: 0.054423, val_r2: 0.708383
2024-05-22 20:24:50 Epoch 32: lr=1.25e-05
2024-05-22 20:26:00 [Epoch: 32] loss: 0.004980, mae: 0.050076, r2: 0.759986, val_loss: 0.006074, val_mae: 0.054549, val_r2: 0.707724
2024-05-22 20:26:00 Epoch 33: lr=1e-05
2024-05-22 20:27:10 [Epoch: 33] loss: 0.004984, mae: 0.050075, r2: 0.759402, val_loss: 0.006066, val_mae: 0.054312, val_r2: 0.708285
2024-05-22 20:27:10 Epoch 34: lr=1e-05
2024-05-22 20:28:20 [Epoch: 34] loss: 0.004976, mae: 0.050058, r2: 0.759731, val_loss: 0.006053, val_mae: 0.054399, val_r2: 0.708416
2024-05-22 20:28:20 Epoch 35: lr=1e-05
2024-05-22 20:29:30 [Epoch: 35] loss: 0.004968, mae: 0.050013, r2: 0.759980, val_loss: 0.006061, val_mae: 0.054177, val_r2: 0.708503
2024-05-22 20:29:30 Epoch 36: lr=1e-05
2024-05-22 20:30:40 [Epoch: 36] loss: 0.004957, mae: 0.049996, r2: 0.760653, val_loss: 0.006075, val_mae: 0.054442, val_r2: 0.707922
2024-05-22 20:30:40 Epoch 37: lr=1e-05
2024-05-22 20:31:50 [Epoch: 37] loss: 0.004955, mae: 0.049959, r2: 0.760708, val_loss: 0.006068, val_mae: 0.054250, val_r2: 0.708604
2024-05-22 20:31:51 Epoch 38: lr=1e-05
2024-05-22 20:33:01 [Epoch: 38] loss: 0.004941, mae: 0.049919, r2: 0.761533, val_loss: 0.006045, val_mae: 0.054117, val_r2: 0.710242
2024-05-22 20:33:01 Epoch 39: lr=1e-05
2024-05-22 20:34:11 [Epoch: 39] loss: 0.004948, mae: 0.049919, r2: 0.760875, val_loss: 0.006077, val_mae: 0.054291, val_r2: 0.708730
2024-05-22 20:34:11 Epoch 40: lr=1e-05
2024-05-22 20:35:21 [Epoch: 40] loss: 0.004934, mae: 0.049847, r2: 0.761649, val_loss: 0.006070, val_mae: 0.054151, val_r2: 0.708725
2024-05-22 20:35:21 Epoch 41: lr=1e-05
2024-05-22 20:36:31 [Epoch: 41] loss: 0.004932, mae: 0.049859, r2: 0.761826, val_loss: 0.006061, val_mae: 0.054227, val_r2: 0.707916
2024-05-22 20:36:31 Epoch 42: lr=1e-05
2024-05-22 20:37:41 [Epoch: 42] loss: 0.004931, mae: 0.049839, r2: 0.761737, val_loss: 0.006067, val_mae: 0.054332, val_r2: 0.708218
2024-05-22 20:37:41 Epoch 43: lr=1e-05
2024-05-22 20:38:51 [Epoch: 43] loss: 0.004916, mae: 0.049778, r2: 0.762610, val_loss: 0.006061, val_mae: 0.054252, val_r2: 0.708415
2024-05-22 20:38:51 Epoch 44: lr=1e-05
2024-05-22 20:40:01 [Epoch: 44] loss: 0.004916, mae: 0.049784, r2: 0.762428, val_loss: 0.006097, val_mae: 0.054362, val_r2: 0.706701
2024-05-22 20:40:01 Epoch 45: lr=1e-05
2024-05-22 20:41:11 [Epoch: 45] loss: 0.004919, mae: 0.049816, r2: 0.762406, val_loss: 0.006061, val_mae: 0.054100, val_r2: 0.708978
2024-05-22 20:41:11 Epoch 46: lr=1e-05
2024-05-22 20:42:21 [Epoch: 46] loss: 0.004899, mae: 0.049730, r2: 0.763175, val_loss: 0.006068, val_mae: 0.054474, val_r2: 0.708545
2024-05-22 20:42:21 Epoch 47: lr=1e-05
2024-05-22 20:43:31 [Epoch: 47] loss: 0.004898, mae: 0.049708, r2: 0.763233, val_loss: 0.006088, val_mae: 0.054368, val_r2: 0.706913
2024-05-22 20:43:31 Epoch 48: lr=1e-05
2024-05-22 20:44:41 [Epoch: 48] loss: 0.004902, mae: 0.049737, r2: 0.763150, val_loss: 0.006058, val_mae: 0.054209, val_r2: 0.708883
2024-05-22 20:44:41 history_length: 49
2024-05-22 20:44:41 stopping: early
2024-05-22 20:44:41 Comparing y_true and y_pred:
2024-05-22 20:44:41   mse: 0.00527213
2024-05-22 20:44:41   mae: 0.06414485
2024-05-22 20:44:41   r2: -0.38386522
2024-05-22 20:44:41   corr: 0.34577404
