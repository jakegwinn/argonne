2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/143', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '143', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/143/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/143', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c7s7b0n0.143.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/143/5.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/143'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x1530806cd670>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/143/5.1.model.h5
2024-05-22 19:47:23 Between random pairs in y_val:
2024-05-22 19:47:23   mse: 0.04791233
2024-05-22 19:47:23   mae: 0.16045862
2024-05-22 19:47:23   r2: -0.99767509
2024-05-22 19:47:23   corr: 0.00116246
2024-05-22 19:47:23 Data points per epoch: train = 469638, val = 117410, test = 661
2024-05-22 19:47:23 Steps per epoch: train = 14676, val = 3669, test = 20
2024-05-22 19:47:23 Epoch 0: lr=0.001
2024-05-22 19:48:35 [Epoch: 0] loss: 0.020437, mae: 0.078482, r2: 0.128048, val_loss: 0.008512, val_mae: 0.066036, val_r2: 0.607593
2024-05-22 19:48:36 Epoch 1: lr=0.00082
2024-05-22 19:49:46 [Epoch: 1] loss: 0.007976, mae: 0.063862, r2: 0.621793, val_loss: 0.007594, val_mae: 0.063392, val_r2: 0.641359
2024-05-22 19:49:46 Epoch 2: lr=0.00064
2024-05-22 19:50:58 [Epoch: 2] loss: 0.007335, mae: 0.060927, r2: 0.651354, val_loss: 0.007174, val_mae: 0.060402, val_r2: 0.661701
2024-05-22 19:50:58 Epoch 3: lr=0.00046
2024-05-22 19:52:09 [Epoch: 3] loss: 0.006862, mae: 0.058706, r2: 0.673411, val_loss: 0.006874, val_mae: 0.059392, val_r2: 0.673516
2024-05-22 19:52:09 Epoch 4: lr=0.00028
2024-05-22 19:53:21 [Epoch: 4] loss: 0.006465, mae: 0.056880, r2: 0.691340, val_loss: 0.006566, val_mae: 0.057863, val_r2: 0.685880
2024-05-22 19:53:21 Epoch 5: lr=0.0001
2024-05-22 19:54:32 [Epoch: 5] loss: 0.006147, mae: 0.055405, r2: 0.706069, val_loss: 0.006454, val_mae: 0.056145, val_r2: 0.695038
2024-05-22 19:54:32 Epoch 6: lr=0.0001
2024-05-22 19:55:43 [Epoch: 6] loss: 0.006042, mae: 0.054963, r2: 0.710830, val_loss: 0.006365, val_mae: 0.056916, val_r2: 0.696627
2024-05-22 19:55:44 Epoch 7: lr=0.0001
2024-05-22 19:56:55 [Epoch: 7] loss: 0.005965, mae: 0.054608, r2: 0.714540, val_loss: 0.006317, val_mae: 0.055875, val_r2: 0.700787
2024-05-22 19:56:55 Epoch 8: lr=0.0001
2024-05-22 19:58:06 [Epoch: 8] loss: 0.005888, mae: 0.054300, r2: 0.717813, val_loss: 0.006288, val_mae: 0.055613, val_r2: 0.702758
2024-05-22 19:58:06 Epoch 9: lr=0.0001
2024-05-22 19:59:17 [Epoch: 9] loss: 0.005821, mae: 0.053983, r2: 0.721248, val_loss: 0.006256, val_mae: 0.056304, val_r2: 0.701378
2024-05-22 19:59:17 Epoch 10: lr=0.0001
2024-05-22 20:00:28 [Epoch: 10] loss: 0.005755, mae: 0.053691, r2: 0.724269, val_loss: 0.006183, val_mae: 0.055443, val_r2: 0.706210
2024-05-22 20:00:28 Epoch 11: lr=0.0001
2024-05-22 20:01:39 [Epoch: 11] loss: 0.005688, mae: 0.053345, r2: 0.727315, val_loss: 0.006194, val_mae: 0.055523, val_r2: 0.705818
2024-05-22 20:01:39 Epoch 12: lr=0.0001
2024-05-22 20:02:50 [Epoch: 12] loss: 0.005658, mae: 0.053230, r2: 0.728851, val_loss: 0.006203, val_mae: 0.055930, val_r2: 0.704070
2024-05-22 20:02:50 Epoch 13: lr=0.0001
2024-05-22 20:04:02 [Epoch: 13] loss: 0.005581, mae: 0.052898, r2: 0.732355, val_loss: 0.006193, val_mae: 0.055877, val_r2: 0.705248
2024-05-22 20:04:02 Epoch 14: lr=0.0001
2024-05-22 20:05:13 [Epoch: 14] loss: 0.005535, mae: 0.052687, r2: 0.734413, val_loss: 0.006150, val_mae: 0.055415, val_r2: 0.708085
2024-05-22 20:05:14 Epoch 15: lr=0.0001
2024-05-22 20:06:25 [Epoch: 15] loss: 0.005475, mae: 0.052428, r2: 0.736943, val_loss: 0.006168, val_mae: 0.054893, val_r2: 0.706126
2024-05-22 20:06:25 Epoch 16: lr=5e-05
2024-05-22 20:07:36 [Epoch: 16] loss: 0.005371, mae: 0.051924, r2: 0.742159, val_loss: 0.006147, val_mae: 0.055827, val_r2: 0.706856
2024-05-22 20:07:36 Epoch 17: lr=5e-05
2024-05-22 20:08:48 [Epoch: 17] loss: 0.005303, mae: 0.051619, r2: 0.744969, val_loss: 0.006099, val_mae: 0.054624, val_r2: 0.708822
2024-05-22 20:08:48 Epoch 18: lr=5e-05
2024-05-22 20:09:59 [Epoch: 18] loss: 0.005282, mae: 0.051532, r2: 0.746067, val_loss: 0.006103, val_mae: 0.054905, val_r2: 0.708492
2024-05-22 20:09:59 Epoch 19: lr=5e-05
2024-05-22 20:11:10 [Epoch: 19] loss: 0.005259, mae: 0.051371, r2: 0.747477, val_loss: 0.006134, val_mae: 0.054511, val_r2: 0.706874
2024-05-22 20:11:10 Epoch 20: lr=5e-05
2024-05-22 20:12:21 [Epoch: 20] loss: 0.005223, mae: 0.051244, r2: 0.748977, val_loss: 0.006062, val_mae: 0.054513, val_r2: 0.712392
2024-05-22 20:12:21 Epoch 21: lr=5e-05
2024-05-22 20:13:32 [Epoch: 21] loss: 0.005205, mae: 0.051175, r2: 0.749645, val_loss: 0.006111, val_mae: 0.054998, val_r2: 0.708883
2024-05-22 20:13:32 Epoch 22: lr=5e-05
2024-05-22 20:14:44 [Epoch: 22] loss: 0.005169, mae: 0.050994, r2: 0.751340, val_loss: 0.006076, val_mae: 0.054588, val_r2: 0.710255
2024-05-22 20:14:44 Epoch 23: lr=5e-05
2024-05-22 20:15:55 [Epoch: 23] loss: 0.005149, mae: 0.050910, r2: 0.752300, val_loss: 0.006103, val_mae: 0.054848, val_r2: 0.709356
2024-05-22 20:15:56 Epoch 24: lr=5e-05
2024-05-22 20:17:07 [Epoch: 24] loss: 0.005124, mae: 0.050796, r2: 0.753491, val_loss: 0.006099, val_mae: 0.054837, val_r2: 0.709748
2024-05-22 20:17:07 Epoch 25: lr=5e-05
2024-05-22 20:18:18 [Epoch: 25] loss: 0.005090, mae: 0.050600, r2: 0.755248, val_loss: 0.006096, val_mae: 0.054772, val_r2: 0.709723
2024-05-22 20:18:18 Epoch 26: lr=2.5e-05
2024-05-22 20:19:30 [Epoch: 26] loss: 0.005029, mae: 0.050361, r2: 0.757990, val_loss: 0.006099, val_mae: 0.054847, val_r2: 0.709065
2024-05-22 20:19:30 Epoch 27: lr=2.5e-05
2024-05-22 20:20:41 [Epoch: 27] loss: 0.005022, mae: 0.050280, r2: 0.758233, val_loss: 0.006075, val_mae: 0.054514, val_r2: 0.709462
2024-05-22 20:20:41 Epoch 28: lr=2.5e-05
2024-05-22 20:21:52 [Epoch: 28] loss: 0.004994, mae: 0.050186, r2: 0.759667, val_loss: 0.006089, val_mae: 0.054395, val_r2: 0.709337
2024-05-22 20:21:52 Epoch 29: lr=2.5e-05
2024-05-22 20:23:03 [Epoch: 29] loss: 0.004987, mae: 0.050129, r2: 0.759781, val_loss: 0.006088, val_mae: 0.054313, val_r2: 0.709955
2024-05-22 20:23:04 Epoch 30: lr=2.5e-05
2024-05-22 20:24:14 [Epoch: 30] loss: 0.004978, mae: 0.050078, r2: 0.760275, val_loss: 0.006062, val_mae: 0.054443, val_r2: 0.710902
2024-05-22 20:24:15 Epoch 31: lr=1.25e-05
2024-05-22 20:25:25 [Epoch: 31] loss: 0.004946, mae: 0.049917, r2: 0.761818, val_loss: 0.006080, val_mae: 0.054548, val_r2: 0.710421
2024-05-22 20:25:26 Epoch 32: lr=1.25e-05
2024-05-22 20:26:37 [Epoch: 32] loss: 0.004917, mae: 0.049804, r2: 0.763188, val_loss: 0.006086, val_mae: 0.054367, val_r2: 0.709865
2024-05-22 20:26:37 Epoch 33: lr=1.25e-05
2024-05-22 20:27:49 [Epoch: 33] loss: 0.004922, mae: 0.049808, r2: 0.762906, val_loss: 0.006102, val_mae: 0.054443, val_r2: 0.708563
2024-05-22 20:27:49 Epoch 34: lr=1.25e-05
2024-05-22 20:29:00 [Epoch: 34] loss: 0.004920, mae: 0.049798, r2: 0.762937, val_loss: 0.006053, val_mae: 0.054431, val_r2: 0.710701
2024-05-22 20:29:00 Epoch 35: lr=1.25e-05
2024-05-22 20:30:11 [Epoch: 35] loss: 0.004906, mae: 0.049749, r2: 0.763966, val_loss: 0.006063, val_mae: 0.054187, val_r2: 0.710799
2024-05-22 20:30:11 Epoch 36: lr=1e-05
2024-05-22 20:31:23 [Epoch: 36] loss: 0.004891, mae: 0.049675, r2: 0.764297, val_loss: 0.006065, val_mae: 0.054271, val_r2: 0.710633
2024-05-22 20:31:23 Epoch 37: lr=1e-05
2024-05-22 20:32:34 [Epoch: 37] loss: 0.004899, mae: 0.049715, r2: 0.764038, val_loss: 0.006060, val_mae: 0.054317, val_r2: 0.710731
2024-05-22 20:32:34 Epoch 38: lr=1e-05
2024-05-22 20:33:45 [Epoch: 38] loss: 0.004882, mae: 0.049617, r2: 0.764922, val_loss: 0.006090, val_mae: 0.054488, val_r2: 0.709038
2024-05-22 20:33:45 Epoch 39: lr=1e-05
2024-05-22 20:34:56 [Epoch: 39] loss: 0.004888, mae: 0.049621, r2: 0.764595, val_loss: 0.006045, val_mae: 0.054369, val_r2: 0.712254
2024-05-22 20:34:56 Epoch 40: lr=1e-05
2024-05-22 20:36:07 [Epoch: 40] loss: 0.004871, mae: 0.049565, r2: 0.765450, val_loss: 0.006074, val_mae: 0.054493, val_r2: 0.710341
2024-05-22 20:36:07 Epoch 41: lr=1e-05
2024-05-22 20:37:18 [Epoch: 41] loss: 0.004862, mae: 0.049536, r2: 0.765899, val_loss: 0.006059, val_mae: 0.054306, val_r2: 0.711646
2024-05-22 20:37:18 Epoch 42: lr=1e-05
2024-05-22 20:38:29 [Epoch: 42] loss: 0.004863, mae: 0.049542, r2: 0.765510, val_loss: 0.006057, val_mae: 0.054208, val_r2: 0.710361
2024-05-22 20:38:29 Epoch 43: lr=1e-05
2024-05-22 20:39:40 [Epoch: 43] loss: 0.004870, mae: 0.049516, r2: 0.765329, val_loss: 0.006063, val_mae: 0.054197, val_r2: 0.711015
2024-05-22 20:39:40 Epoch 44: lr=1e-05
2024-05-22 20:40:52 [Epoch: 44] loss: 0.004854, mae: 0.049496, r2: 0.766114, val_loss: 0.006074, val_mae: 0.054452, val_r2: 0.710015
2024-05-22 20:40:52 Epoch 45: lr=1e-05
2024-05-22 20:42:03 [Epoch: 45] loss: 0.004852, mae: 0.049478, r2: 0.766116, val_loss: 0.006062, val_mae: 0.054187, val_r2: 0.709842
2024-05-22 20:42:03 Epoch 46: lr=1e-05
2024-05-22 20:43:14 [Epoch: 46] loss: 0.004841, mae: 0.049451, r2: 0.766608, val_loss: 0.006071, val_mae: 0.054337, val_r2: 0.710321
2024-05-22 20:43:14 Epoch 47: lr=1e-05
2024-05-22 20:44:25 [Epoch: 47] loss: 0.004842, mae: 0.049442, r2: 0.766675, val_loss: 0.006096, val_mae: 0.054275, val_r2: 0.709145
2024-05-22 20:44:25 Epoch 48: lr=1e-05
2024-05-22 20:45:36 [Epoch: 48] loss: 0.004841, mae: 0.049452, r2: 0.766623, val_loss: 0.006077, val_mae: 0.054314, val_r2: 0.710258
2024-05-22 20:45:36 Epoch 49: lr=1e-05
2024-05-22 20:46:47 [Epoch: 49] loss: 0.004827, mae: 0.049351, r2: 0.767492, val_loss: 0.006084, val_mae: 0.054286, val_r2: 0.709891
2024-05-22 20:46:47 history_length: 50
2024-05-22 20:46:47 stopping: complete
2024-05-22 20:46:47 Comparing y_true and y_pred:
2024-05-22 20:46:47   mse: 0.00964261
2024-05-22 20:46:47   mae: 0.08791877
2024-05-22 20:46:47   r2: -2.50764624
2024-05-22 20:46:47   corr: 0.51183137
