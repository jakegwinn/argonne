2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/16', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '16', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/16/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/16', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s4b0n0.16.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/16/2.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/16'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x145461034670>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/16/2.0.model.h5
2024-05-22 19:47:23 Between random pairs in y_val:
2024-05-22 19:47:23   mse: 0.04827548
2024-05-22 19:47:23   mae: 0.16101701
2024-05-22 19:47:23   r2: -1.00392098
2024-05-22 19:47:23   corr: -0.00196049
2024-05-22 19:47:23 Data points per epoch: train = 469620, val = 117406, test = 683
2024-05-22 19:47:23 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-22 19:47:23 Epoch 0: lr=0.001
2024-05-22 19:48:36 [Epoch: 0] loss: 0.025221, mae: 0.079049, r2: -0.275954, val_loss: 0.008811, val_mae: 0.066917, val_r2: 0.582268
2024-05-22 19:48:36 Epoch 1: lr=0.00082
2024-05-22 19:49:47 [Epoch: 1] loss: 0.007996, mae: 0.063902, r2: 0.620648, val_loss: 0.008488, val_mae: 0.065166, val_r2: 0.611114
2024-05-22 19:49:47 Epoch 2: lr=0.00064
2024-05-22 19:50:59 [Epoch: 2] loss: 0.007326, mae: 0.060871, r2: 0.651206, val_loss: 0.007196, val_mae: 0.061095, val_r2: 0.662643
2024-05-22 19:50:59 Epoch 3: lr=0.00046
2024-05-22 19:52:10 [Epoch: 3] loss: 0.006834, mae: 0.058621, r2: 0.673754, val_loss: 0.006920, val_mae: 0.058274, val_r2: 0.677189
2024-05-22 19:52:10 Epoch 4: lr=0.00028
2024-05-22 19:53:22 [Epoch: 4] loss: 0.006450, mae: 0.056826, r2: 0.691313, val_loss: 0.006663, val_mae: 0.058262, val_r2: 0.685911
2024-05-22 19:53:22 Epoch 5: lr=0.0001
2024-05-22 19:54:33 [Epoch: 5] loss: 0.006123, mae: 0.055340, r2: 0.706361, val_loss: 0.006483, val_mae: 0.056725, val_r2: 0.695063
2024-05-22 19:54:33 Epoch 6: lr=0.0001
2024-05-22 19:55:45 [Epoch: 6] loss: 0.006010, mae: 0.054808, r2: 0.711729, val_loss: 0.006424, val_mae: 0.056021, val_r2: 0.698198
2024-05-22 19:55:45 Epoch 7: lr=0.0001
2024-05-22 19:56:56 [Epoch: 7] loss: 0.005932, mae: 0.054459, r2: 0.715377, val_loss: 0.006380, val_mae: 0.056128, val_r2: 0.699813
2024-05-22 19:56:56 Epoch 8: lr=0.0001
2024-05-22 19:58:08 [Epoch: 8] loss: 0.005860, mae: 0.054152, r2: 0.718678, val_loss: 0.006400, val_mae: 0.056811, val_r2: 0.698087
2024-05-22 19:58:08 Epoch 9: lr=0.0001
2024-05-22 19:59:19 [Epoch: 9] loss: 0.005806, mae: 0.053922, r2: 0.720974, val_loss: 0.006297, val_mae: 0.055831, val_r2: 0.702595
2024-05-22 19:59:19 Epoch 10: lr=0.0001
2024-05-22 20:00:30 [Epoch: 10] loss: 0.005747, mae: 0.053650, r2: 0.724064, val_loss: 0.006315, val_mae: 0.056260, val_r2: 0.702948
2024-05-22 20:00:30 Epoch 11: lr=0.0001
2024-05-22 20:01:42 [Epoch: 11] loss: 0.005678, mae: 0.053323, r2: 0.727104, val_loss: 0.006307, val_mae: 0.055406, val_r2: 0.703498
2024-05-22 20:01:42 Epoch 12: lr=0.0001
2024-05-22 20:02:54 [Epoch: 12] loss: 0.005635, mae: 0.053143, r2: 0.729042, val_loss: 0.006241, val_mae: 0.055238, val_r2: 0.705941
2024-05-22 20:02:54 Epoch 13: lr=0.0001
2024-05-22 20:04:05 [Epoch: 13] loss: 0.005558, mae: 0.052817, r2: 0.732672, val_loss: 0.006244, val_mae: 0.055209, val_r2: 0.706113
2024-05-22 20:04:05 Epoch 14: lr=0.0001
2024-05-22 20:05:17 [Epoch: 14] loss: 0.005512, mae: 0.052575, r2: 0.734698, val_loss: 0.006246, val_mae: 0.055279, val_r2: 0.706348
2024-05-22 20:05:17 Epoch 15: lr=0.0001
2024-05-22 20:06:28 [Epoch: 15] loss: 0.005465, mae: 0.052389, r2: 0.737158, val_loss: 0.006193, val_mae: 0.055282, val_r2: 0.709107
2024-05-22 20:06:28 Epoch 16: lr=0.0001
2024-05-22 20:07:39 [Epoch: 16] loss: 0.005413, mae: 0.052123, r2: 0.739553, val_loss: 0.006218, val_mae: 0.055131, val_r2: 0.707786
2024-05-22 20:07:39 Epoch 17: lr=0.0001
2024-05-22 20:08:51 [Epoch: 17] loss: 0.005364, mae: 0.051896, r2: 0.741789, val_loss: 0.006196, val_mae: 0.054800, val_r2: 0.708799
2024-05-22 20:08:51 Epoch 18: lr=5e-05
2024-05-22 20:10:02 [Epoch: 18] loss: 0.005246, mae: 0.051362, r2: 0.747326, val_loss: 0.006157, val_mae: 0.054777, val_r2: 0.709674
2024-05-22 20:10:03 Epoch 19: lr=5e-05
2024-05-22 20:11:14 [Epoch: 19] loss: 0.005217, mae: 0.051183, r2: 0.748537, val_loss: 0.006147, val_mae: 0.054728, val_r2: 0.710910
2024-05-22 20:11:14 Epoch 20: lr=5e-05
2024-05-22 20:12:26 [Epoch: 20] loss: 0.005172, mae: 0.050966, r2: 0.750520, val_loss: 0.006172, val_mae: 0.054617, val_r2: 0.709187
2024-05-22 20:12:26 Epoch 21: lr=5e-05
2024-05-22 20:13:38 [Epoch: 21] loss: 0.005143, mae: 0.050873, r2: 0.752039, val_loss: 0.006176, val_mae: 0.054874, val_r2: 0.708232
2024-05-22 20:13:38 Epoch 22: lr=5e-05
2024-05-22 20:14:50 [Epoch: 22] loss: 0.005128, mae: 0.050791, r2: 0.752627, val_loss: 0.006162, val_mae: 0.054838, val_r2: 0.708999
2024-05-22 20:14:50 Epoch 23: lr=2.5e-05
2024-05-22 20:16:02 [Epoch: 23] loss: 0.005065, mae: 0.050472, r2: 0.755738, val_loss: 0.006139, val_mae: 0.054770, val_r2: 0.709846
2024-05-22 20:16:02 Epoch 24: lr=2.5e-05
2024-05-22 20:17:14 [Epoch: 24] loss: 0.005040, mae: 0.050375, r2: 0.756557, val_loss: 0.006154, val_mae: 0.054391, val_r2: 0.709420
2024-05-22 20:17:14 Epoch 25: lr=2.5e-05
2024-05-22 20:18:26 [Epoch: 25] loss: 0.005027, mae: 0.050294, r2: 0.757539, val_loss: 0.006146, val_mae: 0.054543, val_r2: 0.710146
2024-05-22 20:18:26 Epoch 26: lr=2.5e-05
2024-05-22 20:19:38 [Epoch: 26] loss: 0.005020, mae: 0.050265, r2: 0.757893, val_loss: 0.006143, val_mae: 0.054344, val_r2: 0.710086
2024-05-22 20:19:38 Epoch 27: lr=2.5e-05
2024-05-22 20:20:50 [Epoch: 27] loss: 0.004995, mae: 0.050195, r2: 0.758971, val_loss: 0.006137, val_mae: 0.054455, val_r2: 0.710831
2024-05-22 20:20:50 Epoch 28: lr=2.5e-05
2024-05-22 20:22:03 [Epoch: 28] loss: 0.004977, mae: 0.050061, r2: 0.759784, val_loss: 0.006139, val_mae: 0.054356, val_r2: 0.710574
2024-05-22 20:22:03 Epoch 29: lr=1.25e-05
2024-05-22 20:23:14 [Epoch: 29] loss: 0.004957, mae: 0.049971, r2: 0.760640, val_loss: 0.006153, val_mae: 0.054707, val_r2: 0.709672
2024-05-22 20:23:14 Epoch 30: lr=1.25e-05
2024-05-22 20:24:27 [Epoch: 30] loss: 0.004939, mae: 0.049904, r2: 0.761373, val_loss: 0.006121, val_mae: 0.054553, val_r2: 0.711677
2024-05-22 20:24:27 Epoch 31: lr=1.25e-05
2024-05-22 20:25:39 [Epoch: 31] loss: 0.004927, mae: 0.049838, r2: 0.762021, val_loss: 0.006132, val_mae: 0.054514, val_r2: 0.710934
2024-05-22 20:25:39 Epoch 32: lr=1.25e-05
2024-05-22 20:26:50 [Epoch: 32] loss: 0.004921, mae: 0.049791, r2: 0.762214, val_loss: 0.006156, val_mae: 0.054687, val_r2: 0.709001
2024-05-22 20:26:50 Epoch 33: lr=1.25e-05
2024-05-22 20:28:03 [Epoch: 33] loss: 0.004919, mae: 0.049796, r2: 0.762339, val_loss: 0.006112, val_mae: 0.054659, val_r2: 0.711639
2024-05-22 20:28:03 Epoch 34: lr=1e-05
2024-05-22 20:29:14 [Epoch: 34] loss: 0.004906, mae: 0.049724, r2: 0.762929, val_loss: 0.006150, val_mae: 0.054400, val_r2: 0.710114
2024-05-22 20:29:14 Epoch 35: lr=1e-05
2024-05-22 20:30:26 [Epoch: 35] loss: 0.004907, mae: 0.049718, r2: 0.762920, val_loss: 0.006146, val_mae: 0.054582, val_r2: 0.709741
2024-05-22 20:30:26 Epoch 36: lr=1e-05
2024-05-22 20:31:37 [Epoch: 36] loss: 0.004906, mae: 0.049694, r2: 0.763090, val_loss: 0.006140, val_mae: 0.054631, val_r2: 0.710432
2024-05-22 20:31:38 Epoch 37: lr=1e-05
2024-05-22 20:32:49 [Epoch: 37] loss: 0.004895, mae: 0.049671, r2: 0.763542, val_loss: 0.006140, val_mae: 0.054456, val_r2: 0.710272
2024-05-22 20:32:50 Epoch 38: lr=1e-05
2024-05-22 20:34:01 [Epoch: 38] loss: 0.004878, mae: 0.049612, r2: 0.764487, val_loss: 0.006156, val_mae: 0.054718, val_r2: 0.709744
2024-05-22 20:34:01 Epoch 39: lr=1e-05
2024-05-22 20:35:13 [Epoch: 39] loss: 0.004879, mae: 0.049565, r2: 0.764246, val_loss: 0.006130, val_mae: 0.054342, val_r2: 0.710927
2024-05-22 20:35:13 Epoch 40: lr=1e-05
2024-05-22 20:36:24 [Epoch: 40] loss: 0.004867, mae: 0.049543, r2: 0.765029, val_loss: 0.006110, val_mae: 0.054322, val_r2: 0.711306
2024-05-22 20:36:24 Epoch 41: lr=1e-05
2024-05-22 20:37:36 [Epoch: 41] loss: 0.004866, mae: 0.049537, r2: 0.764909, val_loss: 0.006150, val_mae: 0.054500, val_r2: 0.709758
2024-05-22 20:37:36 Epoch 42: lr=1e-05
2024-05-22 20:38:47 [Epoch: 42] loss: 0.004861, mae: 0.049521, r2: 0.765286, val_loss: 0.006139, val_mae: 0.054377, val_r2: 0.710617
2024-05-22 20:38:47 Epoch 43: lr=1e-05
2024-05-22 20:39:58 [Epoch: 43] loss: 0.004858, mae: 0.049498, r2: 0.765171, val_loss: 0.006147, val_mae: 0.054483, val_r2: 0.710050
2024-05-22 20:39:58 Epoch 44: lr=1e-05
2024-05-22 20:41:09 [Epoch: 44] loss: 0.004854, mae: 0.049486, r2: 0.765264, val_loss: 0.006150, val_mae: 0.054476, val_r2: 0.708947
2024-05-22 20:41:10 Epoch 45: lr=1e-05
2024-05-22 20:42:21 [Epoch: 45] loss: 0.004843, mae: 0.049431, r2: 0.765815, val_loss: 0.006137, val_mae: 0.054603, val_r2: 0.710629
2024-05-22 20:42:21 Epoch 46: lr=1e-05
2024-05-22 20:43:32 [Epoch: 46] loss: 0.004833, mae: 0.049396, r2: 0.766529, val_loss: 0.006160, val_mae: 0.054322, val_r2: 0.709030
2024-05-22 20:43:32 Epoch 47: lr=1e-05
2024-05-22 20:44:43 [Epoch: 47] loss: 0.004832, mae: 0.049371, r2: 0.766432, val_loss: 0.006141, val_mae: 0.054476, val_r2: 0.710479
2024-05-22 20:44:44 Epoch 48: lr=1e-05
2024-05-22 20:45:55 [Epoch: 48] loss: 0.004829, mae: 0.049393, r2: 0.766793, val_loss: 0.006151, val_mae: 0.054522, val_r2: 0.709774
2024-05-22 20:45:55 Epoch 49: lr=1e-05
2024-05-22 20:47:06 [Epoch: 49] loss: 0.004824, mae: 0.049347, r2: 0.766782, val_loss: 0.006153, val_mae: 0.054500, val_r2: 0.709378
2024-05-22 20:47:07 history_length: 50
2024-05-22 20:47:07 stopping: complete
2024-05-22 20:47:07 Comparing y_true and y_pred:
2024-05-22 20:47:07   mse: 0.01669072
2024-05-22 20:47:07   mae: 0.11029673
2024-05-22 20:47:07   r2: -2.60508515
2024-05-22 20:47:07   corr: 0.05054803
