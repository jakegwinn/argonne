2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/53', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '53', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/53/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/53', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s3b0n0.53.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/53/2.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/53'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x154fdaf0cfd0>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/53/2.1.model.h5
2024-05-22 19:47:24 Between random pairs in y_val:
2024-05-22 19:47:24   mse: 0.04747429
2024-05-22 19:47:24   mae: 0.15948071
2024-05-22 19:47:24   r2: -1.00211732
2024-05-22 19:47:24   corr: -0.00105866
2024-05-22 19:47:24 Data points per epoch: train = 469285, val = 117322, test = 1102
2024-05-22 19:47:24 Steps per epoch: train = 14665, val = 3666, test = 34
2024-05-22 19:47:24 Epoch 0: lr=0.001
2024-05-22 19:48:39 [Epoch: 0] loss: 0.028987, mae: 0.079868, r2: -0.638722, val_loss: 0.008480, val_mae: 0.067217, val_r2: 0.597540
2024-05-22 19:48:40 Epoch 1: lr=0.00082
2024-05-22 19:49:55 [Epoch: 1] loss: 0.008009, mae: 0.064028, r2: 0.621329, val_loss: 0.007538, val_mae: 0.061943, val_r2: 0.639514
2024-05-22 19:49:55 Epoch 2: lr=0.00064
2024-05-22 19:51:10 [Epoch: 2] loss: 0.007344, mae: 0.060958, r2: 0.651665, val_loss: 0.007266, val_mae: 0.060012, val_r2: 0.653318
2024-05-22 19:51:10 Epoch 3: lr=0.00046
2024-05-22 19:52:24 [Epoch: 3] loss: 0.006861, mae: 0.058792, r2: 0.673502, val_loss: 0.006820, val_mae: 0.058536, val_r2: 0.674212
2024-05-22 19:52:25 Epoch 4: lr=0.00028
2024-05-22 19:53:39 [Epoch: 4] loss: 0.006486, mae: 0.057044, r2: 0.690970, val_loss: 0.006713, val_mae: 0.058811, val_r2: 0.675430
2024-05-22 19:53:39 Epoch 5: lr=0.0001
2024-05-22 19:54:54 [Epoch: 5] loss: 0.006154, mae: 0.055547, r2: 0.706136, val_loss: 0.006420, val_mae: 0.056377, val_r2: 0.693040
2024-05-22 19:54:54 Epoch 6: lr=0.0001
2024-05-22 19:56:08 [Epoch: 6] loss: 0.006046, mae: 0.055022, r2: 0.711117, val_loss: 0.006385, val_mae: 0.055920, val_r2: 0.694346
2024-05-22 19:56:08 Epoch 7: lr=0.0001
2024-05-22 19:57:23 [Epoch: 7] loss: 0.005969, mae: 0.054684, r2: 0.714573, val_loss: 0.006358, val_mae: 0.055835, val_r2: 0.695493
2024-05-22 19:57:23 Epoch 8: lr=0.0001
2024-05-22 19:58:38 [Epoch: 8] loss: 0.005909, mae: 0.054387, r2: 0.717477, val_loss: 0.006342, val_mae: 0.055447, val_r2: 0.697658
2024-05-22 19:58:38 Epoch 9: lr=0.0001
2024-05-22 19:59:53 [Epoch: 9] loss: 0.005841, mae: 0.054082, r2: 0.720917, val_loss: 0.006288, val_mae: 0.055472, val_r2: 0.699967
2024-05-22 19:59:53 Epoch 10: lr=0.0001
2024-05-22 20:01:07 [Epoch: 10] loss: 0.005764, mae: 0.053774, r2: 0.724318, val_loss: 0.006247, val_mae: 0.055058, val_r2: 0.700596
2024-05-22 20:01:08 Epoch 11: lr=0.0001
2024-05-22 20:02:22 [Epoch: 11] loss: 0.005716, mae: 0.053555, r2: 0.726841, val_loss: 0.006208, val_mae: 0.055177, val_r2: 0.702864
2024-05-22 20:02:22 Epoch 12: lr=0.0001
2024-05-22 20:03:37 [Epoch: 12] loss: 0.005661, mae: 0.053292, r2: 0.729405, val_loss: 0.006206, val_mae: 0.055200, val_r2: 0.702957
2024-05-22 20:03:37 Epoch 13: lr=0.0001
2024-05-22 20:04:51 [Epoch: 13] loss: 0.005603, mae: 0.052985, r2: 0.731869, val_loss: 0.006198, val_mae: 0.055040, val_r2: 0.703945
2024-05-22 20:04:51 Epoch 14: lr=0.0001
2024-05-22 20:06:06 [Epoch: 14] loss: 0.005551, mae: 0.052753, r2: 0.734365, val_loss: 0.006200, val_mae: 0.054993, val_r2: 0.701576
2024-05-22 20:06:06 Epoch 15: lr=5e-05
2024-05-22 20:07:21 [Epoch: 15] loss: 0.005418, mae: 0.052187, r2: 0.740328, val_loss: 0.006199, val_mae: 0.054668, val_r2: 0.702892
2024-05-22 20:07:21 Epoch 16: lr=5e-05
2024-05-22 20:08:36 [Epoch: 16] loss: 0.005390, mae: 0.052032, r2: 0.741705, val_loss: 0.006120, val_mae: 0.054984, val_r2: 0.706663
2024-05-22 20:08:36 Epoch 17: lr=5e-05
2024-05-22 20:09:50 [Epoch: 17] loss: 0.005343, mae: 0.051850, r2: 0.743821, val_loss: 0.006145, val_mae: 0.054802, val_r2: 0.706005
2024-05-22 20:09:50 Epoch 18: lr=5e-05
2024-05-22 20:11:05 [Epoch: 18] loss: 0.005329, mae: 0.051734, r2: 0.744719, val_loss: 0.006132, val_mae: 0.054926, val_r2: 0.705974
2024-05-22 20:11:05 Epoch 19: lr=5e-05
2024-05-22 20:12:19 [Epoch: 19] loss: 0.005298, mae: 0.051594, r2: 0.745815, val_loss: 0.006141, val_mae: 0.054714, val_r2: 0.706130
2024-05-22 20:12:20 Epoch 20: lr=5e-05
2024-05-22 20:13:34 [Epoch: 20] loss: 0.005266, mae: 0.051468, r2: 0.747335, val_loss: 0.006099, val_mae: 0.054654, val_r2: 0.707451
2024-05-22 20:13:34 Epoch 21: lr=5e-05
2024-05-22 20:14:48 [Epoch: 21] loss: 0.005250, mae: 0.051362, r2: 0.748155, val_loss: 0.006122, val_mae: 0.054498, val_r2: 0.706073
2024-05-22 20:14:48 Epoch 22: lr=2.5e-05
2024-05-22 20:16:03 [Epoch: 22] loss: 0.005182, mae: 0.051066, r2: 0.751238, val_loss: 0.006112, val_mae: 0.054465, val_r2: 0.706308
2024-05-22 20:16:03 Epoch 23: lr=2.5e-05
2024-05-22 20:17:18 [Epoch: 23] loss: 0.005160, mae: 0.050928, r2: 0.752240, val_loss: 0.006116, val_mae: 0.054488, val_r2: 0.706724
2024-05-22 20:17:18 Epoch 24: lr=2.5e-05
2024-05-22 20:18:32 [Epoch: 24] loss: 0.005145, mae: 0.050867, r2: 0.752994, val_loss: 0.006098, val_mae: 0.054306, val_r2: 0.708314
2024-05-22 20:18:32 Epoch 25: lr=2.5e-05
2024-05-22 20:19:47 [Epoch: 25] loss: 0.005132, mae: 0.050808, r2: 0.753637, val_loss: 0.006114, val_mae: 0.054387, val_r2: 0.707374
2024-05-22 20:19:47 Epoch 26: lr=2.5e-05
2024-05-22 20:21:01 [Epoch: 26] loss: 0.005120, mae: 0.050736, r2: 0.754199, val_loss: 0.006086, val_mae: 0.054504, val_r2: 0.707368
2024-05-22 20:21:02 Epoch 27: lr=1.25e-05
2024-05-22 20:22:17 [Epoch: 27] loss: 0.005079, mae: 0.050550, r2: 0.756001, val_loss: 0.006090, val_mae: 0.054444, val_r2: 0.707475
2024-05-22 20:22:17 Epoch 28: lr=1.25e-05
2024-05-22 20:23:31 [Epoch: 28] loss: 0.005072, mae: 0.050520, r2: 0.756501, val_loss: 0.006104, val_mae: 0.054266, val_r2: 0.707243
2024-05-22 20:23:31 Epoch 29: lr=1.25e-05
2024-05-22 20:24:46 [Epoch: 29] loss: 0.005078, mae: 0.050537, r2: 0.756164, val_loss: 0.006101, val_mae: 0.054450, val_r2: 0.707622
2024-05-22 20:24:46 Epoch 30: lr=1.25e-05
2024-05-22 20:26:01 [Epoch: 30] loss: 0.005068, mae: 0.050459, r2: 0.756469, val_loss: 0.006086, val_mae: 0.054532, val_r2: 0.707825
2024-05-22 20:26:01 Epoch 31: lr=1.25e-05
2024-05-22 20:27:16 [Epoch: 31] loss: 0.005052, mae: 0.050425, r2: 0.757506, val_loss: 0.006104, val_mae: 0.054406, val_r2: 0.707307
2024-05-22 20:27:16 Epoch 32: lr=1e-05
2024-05-22 20:28:30 [Epoch: 32] loss: 0.005046, mae: 0.050394, r2: 0.757606, val_loss: 0.006085, val_mae: 0.054426, val_r2: 0.708214
2024-05-22 20:28:30 Epoch 33: lr=1e-05
2024-05-22 20:29:45 [Epoch: 33] loss: 0.005037, mae: 0.050339, r2: 0.757968, val_loss: 0.006074, val_mae: 0.054329, val_r2: 0.708655
2024-05-22 20:29:45 Epoch 34: lr=1e-05
2024-05-22 20:31:00 [Epoch: 34] loss: 0.005024, mae: 0.050292, r2: 0.758698, val_loss: 0.006073, val_mae: 0.054391, val_r2: 0.708718
2024-05-22 20:31:00 Epoch 35: lr=1e-05
2024-05-22 20:32:15 [Epoch: 35] loss: 0.005021, mae: 0.050315, r2: 0.758828, val_loss: 0.006099, val_mae: 0.054364, val_r2: 0.707289
2024-05-22 20:32:15 Epoch 36: lr=1e-05
2024-05-22 20:33:30 [Epoch: 36] loss: 0.005027, mae: 0.050270, r2: 0.758393, val_loss: 0.006106, val_mae: 0.054382, val_r2: 0.706653
2024-05-22 20:33:30 Epoch 37: lr=1e-05
2024-05-22 20:34:44 [Epoch: 37] loss: 0.005000, mae: 0.050170, r2: 0.759720, val_loss: 0.006071, val_mae: 0.054350, val_r2: 0.708786
2024-05-22 20:34:44 Epoch 38: lr=1e-05
2024-05-22 20:35:59 [Epoch: 38] loss: 0.005010, mae: 0.050235, r2: 0.759316, val_loss: 0.006101, val_mae: 0.054345, val_r2: 0.707390
2024-05-22 20:35:59 Epoch 39: lr=1e-05
2024-05-22 20:37:13 [Epoch: 39] loss: 0.004991, mae: 0.050152, r2: 0.760360, val_loss: 0.006073, val_mae: 0.054355, val_r2: 0.708327
2024-05-22 20:37:13 Epoch 40: lr=1e-05
2024-05-22 20:38:28 [Epoch: 40] loss: 0.004993, mae: 0.050157, r2: 0.760075, val_loss: 0.006084, val_mae: 0.054359, val_r2: 0.707824
2024-05-22 20:38:28 Epoch 41: lr=1e-05
2024-05-22 20:39:43 [Epoch: 41] loss: 0.004986, mae: 0.050143, r2: 0.760500, val_loss: 0.006067, val_mae: 0.054261, val_r2: 0.709164
2024-05-22 20:39:43 Epoch 42: lr=1e-05
2024-05-22 20:40:58 [Epoch: 42] loss: 0.004979, mae: 0.050085, r2: 0.760719, val_loss: 0.006107, val_mae: 0.054512, val_r2: 0.707056
2024-05-22 20:40:58 Epoch 43: lr=1e-05
2024-05-22 20:42:12 [Epoch: 43] loss: 0.004981, mae: 0.050077, r2: 0.760782, val_loss: 0.006076, val_mae: 0.054327, val_r2: 0.708208
2024-05-22 20:42:12 Epoch 44: lr=1e-05
2024-05-22 20:43:27 [Epoch: 44] loss: 0.004966, mae: 0.050031, r2: 0.761432, val_loss: 0.006102, val_mae: 0.054430, val_r2: 0.707362
2024-05-22 20:43:27 Epoch 45: lr=1e-05
2024-05-22 20:44:41 [Epoch: 45] loss: 0.004971, mae: 0.050021, r2: 0.761023, val_loss: 0.006082, val_mae: 0.054354, val_r2: 0.708860
2024-05-22 20:44:41 Epoch 46: lr=1e-05
2024-05-22 20:45:55 [Epoch: 46] loss: 0.004962, mae: 0.049996, r2: 0.761625, val_loss: 0.006102, val_mae: 0.054319, val_r2: 0.707508
2024-05-22 20:45:55 Epoch 47: lr=1e-05
2024-05-22 20:47:10 [Epoch: 47] loss: 0.004968, mae: 0.050041, r2: 0.761389, val_loss: 0.006112, val_mae: 0.054444, val_r2: 0.707106
2024-05-22 20:47:10 Epoch 48: lr=1e-05
2024-05-22 20:48:25 [Epoch: 48] loss: 0.004950, mae: 0.049932, r2: 0.762054, val_loss: 0.006086, val_mae: 0.054250, val_r2: 0.707926
2024-05-22 20:48:25 Epoch 49: lr=1e-05
2024-05-22 20:49:39 [Epoch: 49] loss: 0.004945, mae: 0.049935, r2: 0.761959, val_loss: 0.006086, val_mae: 0.054317, val_r2: 0.707961
2024-05-22 20:49:39 history_length: 50
2024-05-22 20:49:39 stopping: complete
2024-05-22 20:49:39 Comparing y_true and y_pred:
2024-05-22 20:49:39   mse: 0.01088201
2024-05-22 20:49:39   mae: 0.09154660
2024-05-22 20:49:39   r2: -4.64668318
2024-05-22 20:49:39   corr: 0.27486519
