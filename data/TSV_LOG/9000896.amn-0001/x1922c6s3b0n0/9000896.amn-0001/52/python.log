2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/52', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '52', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/52/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/52', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s3b0n0.52.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/52/2.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/52'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x14f2870e4610>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/52/2.0.model.h5
2024-05-22 19:47:23 Between random pairs in y_val:
2024-05-22 19:47:23   mse: 0.04776370
2024-05-22 19:47:23   mae: 0.16008132
2024-05-22 19:47:23   r2: -0.99744362
2024-05-22 19:47:23   corr: 0.00127819
2024-05-22 19:47:23 Data points per epoch: train = 469237, val = 117310, test = 1162
2024-05-22 19:47:23 Steps per epoch: train = 14663, val = 3665, test = 36
2024-05-22 19:47:23 Epoch 0: lr=0.001
2024-05-22 19:48:36 [Epoch: 0] loss: 0.025540, mae: 0.079226, r2: -0.809396, val_loss: 0.008714, val_mae: 0.066253, val_r2: 0.594738
2024-05-22 19:48:36 Epoch 1: lr=0.00082
2024-05-22 19:49:47 [Epoch: 1] loss: 0.007982, mae: 0.063864, r2: 0.620921, val_loss: 0.007662, val_mae: 0.061673, val_r2: 0.641393
2024-05-22 19:49:47 Epoch 2: lr=0.00064
2024-05-22 19:50:58 [Epoch: 2] loss: 0.007304, mae: 0.060792, r2: 0.652086, val_loss: 0.007247, val_mae: 0.061214, val_r2: 0.657996
2024-05-22 19:50:58 Epoch 3: lr=0.00046
2024-05-22 19:52:10 [Epoch: 3] loss: 0.006827, mae: 0.058595, r2: 0.673663, val_loss: 0.007075, val_mae: 0.061202, val_r2: 0.658638
2024-05-22 19:52:10 Epoch 4: lr=0.00028
2024-05-22 19:53:21 [Epoch: 4] loss: 0.006412, mae: 0.056753, r2: 0.692872, val_loss: 0.006658, val_mae: 0.058856, val_r2: 0.683315
2024-05-22 19:53:21 Epoch 5: lr=0.0001
2024-05-22 19:54:33 [Epoch: 5] loss: 0.006074, mae: 0.055146, r2: 0.708645, val_loss: 0.006440, val_mae: 0.056234, val_r2: 0.693766
2024-05-22 19:54:33 Epoch 6: lr=0.0001
2024-05-22 19:55:44 [Epoch: 6] loss: 0.005962, mae: 0.054621, r2: 0.713863, val_loss: 0.006445, val_mae: 0.055783, val_r2: 0.692536
2024-05-22 19:55:44 Epoch 7: lr=0.0001
2024-05-22 19:56:56 [Epoch: 7] loss: 0.005885, mae: 0.054279, r2: 0.717629, val_loss: 0.006357, val_mae: 0.055922, val_r2: 0.696384
2024-05-22 19:56:56 Epoch 8: lr=0.0001
2024-05-22 19:58:07 [Epoch: 8] loss: 0.005806, mae: 0.053947, r2: 0.721086, val_loss: 0.006355, val_mae: 0.056026, val_r2: 0.695485
2024-05-22 19:58:07 Epoch 9: lr=0.0001
2024-05-22 19:59:18 [Epoch: 9] loss: 0.005743, mae: 0.053648, r2: 0.724226, val_loss: 0.006286, val_mae: 0.055703, val_r2: 0.699323
2024-05-22 19:59:18 Epoch 10: lr=0.0001
2024-05-22 20:00:29 [Epoch: 10] loss: 0.005687, mae: 0.053398, r2: 0.726595, val_loss: 0.006269, val_mae: 0.055739, val_r2: 0.700048
2024-05-22 20:00:29 Epoch 11: lr=0.0001
2024-05-22 20:01:41 [Epoch: 11] loss: 0.005627, mae: 0.053110, r2: 0.729418, val_loss: 0.006243, val_mae: 0.055433, val_r2: 0.700189
2024-05-22 20:01:41 Epoch 12: lr=0.0001
2024-05-22 20:02:52 [Epoch: 12] loss: 0.005569, mae: 0.052849, r2: 0.732105, val_loss: 0.006239, val_mae: 0.055395, val_r2: 0.701188
2024-05-22 20:02:52 Epoch 13: lr=0.0001
2024-05-22 20:04:04 [Epoch: 13] loss: 0.005507, mae: 0.052560, r2: 0.735121, val_loss: 0.006187, val_mae: 0.055211, val_r2: 0.704145
2024-05-22 20:04:04 Epoch 14: lr=0.0001
2024-05-22 20:05:15 [Epoch: 14] loss: 0.005452, mae: 0.052322, r2: 0.737641, val_loss: 0.006196, val_mae: 0.055109, val_r2: 0.703836
2024-05-22 20:05:15 Epoch 15: lr=5e-05
2024-05-22 20:06:27 [Epoch: 15] loss: 0.005338, mae: 0.051756, r2: 0.742795, val_loss: 0.006172, val_mae: 0.055064, val_r2: 0.705044
2024-05-22 20:06:27 Epoch 16: lr=5e-05
2024-05-22 20:07:38 [Epoch: 16] loss: 0.005295, mae: 0.051571, r2: 0.744909, val_loss: 0.006183, val_mae: 0.054615, val_r2: 0.704580
2024-05-22 20:07:38 Epoch 17: lr=5e-05
2024-05-22 20:08:49 [Epoch: 17] loss: 0.005248, mae: 0.051344, r2: 0.747252, val_loss: 0.006171, val_mae: 0.054802, val_r2: 0.704538
2024-05-22 20:08:49 Epoch 18: lr=5e-05
2024-05-22 20:10:00 [Epoch: 18] loss: 0.005220, mae: 0.051254, r2: 0.748591, val_loss: 0.006157, val_mae: 0.054910, val_r2: 0.704954
2024-05-22 20:10:01 Epoch 19: lr=5e-05
2024-05-22 20:11:12 [Epoch: 19] loss: 0.005200, mae: 0.051086, r2: 0.749284, val_loss: 0.006157, val_mae: 0.054621, val_r2: 0.705110
2024-05-22 20:11:12 Epoch 20: lr=5e-05
2024-05-22 20:12:23 [Epoch: 20] loss: 0.005170, mae: 0.051005, r2: 0.750828, val_loss: 0.006183, val_mae: 0.054469, val_r2: 0.703354
2024-05-22 20:12:23 Epoch 21: lr=2.5e-05
2024-05-22 20:13:34 [Epoch: 21] loss: 0.005101, mae: 0.050658, r2: 0.753790, val_loss: 0.006147, val_mae: 0.054739, val_r2: 0.705470
2024-05-22 20:13:34 Epoch 22: lr=2.5e-05
2024-05-22 20:14:45 [Epoch: 22] loss: 0.005087, mae: 0.050588, r2: 0.754678, val_loss: 0.006120, val_mae: 0.054575, val_r2: 0.706267
2024-05-22 20:14:45 Epoch 23: lr=2.5e-05
2024-05-22 20:15:57 [Epoch: 23] loss: 0.005076, mae: 0.050498, r2: 0.755146, val_loss: 0.006123, val_mae: 0.054332, val_r2: 0.707181
2024-05-22 20:15:57 Epoch 24: lr=2.5e-05
2024-05-22 20:17:08 [Epoch: 24] loss: 0.005055, mae: 0.050440, r2: 0.755993, val_loss: 0.006140, val_mae: 0.054534, val_r2: 0.706331
2024-05-22 20:17:08 Epoch 25: lr=2.5e-05
2024-05-22 20:18:20 [Epoch: 25] loss: 0.005038, mae: 0.050359, r2: 0.756864, val_loss: 0.006144, val_mae: 0.054536, val_r2: 0.706641
2024-05-22 20:18:20 Epoch 26: lr=1.25e-05
2024-05-22 20:19:31 [Epoch: 26] loss: 0.005011, mae: 0.050232, r2: 0.758282, val_loss: 0.006123, val_mae: 0.054455, val_r2: 0.707290
2024-05-22 20:19:31 Epoch 27: lr=1.25e-05
2024-05-22 20:20:43 [Epoch: 27] loss: 0.004996, mae: 0.050171, r2: 0.758817, val_loss: 0.006126, val_mae: 0.054301, val_r2: 0.707009
2024-05-22 20:20:43 Epoch 28: lr=1.25e-05
2024-05-22 20:21:54 [Epoch: 28] loss: 0.004988, mae: 0.050121, r2: 0.759063, val_loss: 0.006113, val_mae: 0.054326, val_r2: 0.707201
2024-05-22 20:21:54 Epoch 29: lr=1.25e-05
2024-05-22 20:23:05 [Epoch: 29] loss: 0.004986, mae: 0.050106, r2: 0.759298, val_loss: 0.006121, val_mae: 0.054626, val_r2: 0.707100
2024-05-22 20:23:06 Epoch 30: lr=1.25e-05
2024-05-22 20:24:17 [Epoch: 30] loss: 0.004980, mae: 0.050078, r2: 0.759732, val_loss: 0.006120, val_mae: 0.054594, val_r2: 0.706675
2024-05-22 20:24:17 Epoch 31: lr=1e-05
2024-05-22 20:25:28 [Epoch: 31] loss: 0.004963, mae: 0.049991, r2: 0.760455, val_loss: 0.006117, val_mae: 0.054585, val_r2: 0.706997
2024-05-22 20:25:28 Epoch 32: lr=1e-05
2024-05-22 20:26:40 [Epoch: 32] loss: 0.004960, mae: 0.049982, r2: 0.760665, val_loss: 0.006106, val_mae: 0.054497, val_r2: 0.706960
2024-05-22 20:26:40 Epoch 33: lr=1e-05
2024-05-22 20:27:51 [Epoch: 33] loss: 0.004955, mae: 0.049928, r2: 0.760867, val_loss: 0.006156, val_mae: 0.054408, val_r2: 0.705412
2024-05-22 20:27:51 Epoch 34: lr=1e-05
2024-05-22 20:29:03 [Epoch: 34] loss: 0.004942, mae: 0.049874, r2: 0.761389, val_loss: 0.006112, val_mae: 0.054377, val_r2: 0.707159
2024-05-22 20:29:03 Epoch 35: lr=1e-05
2024-05-22 20:30:14 [Epoch: 35] loss: 0.004943, mae: 0.049891, r2: 0.761504, val_loss: 0.006124, val_mae: 0.054440, val_r2: 0.706477
2024-05-22 20:30:14 Epoch 36: lr=1e-05
2024-05-22 20:31:26 [Epoch: 36] loss: 0.004935, mae: 0.049844, r2: 0.761732, val_loss: 0.006136, val_mae: 0.054459, val_r2: 0.706006
2024-05-22 20:31:26 Epoch 37: lr=1e-05
2024-05-22 20:32:37 [Epoch: 37] loss: 0.004921, mae: 0.049776, r2: 0.762427, val_loss: 0.006111, val_mae: 0.054401, val_r2: 0.707000
2024-05-22 20:32:37 Epoch 38: lr=1e-05
2024-05-22 20:33:48 [Epoch: 38] loss: 0.004907, mae: 0.049727, r2: 0.762991, val_loss: 0.006101, val_mae: 0.054517, val_r2: 0.708095
2024-05-22 20:33:48 Epoch 39: lr=1e-05
2024-05-22 20:35:00 [Epoch: 39] loss: 0.004915, mae: 0.049762, r2: 0.762778, val_loss: 0.006132, val_mae: 0.054475, val_r2: 0.706721
2024-05-22 20:35:00 Epoch 40: lr=1e-05
2024-05-22 20:36:11 [Epoch: 40] loss: 0.004916, mae: 0.049763, r2: 0.762666, val_loss: 0.006130, val_mae: 0.054377, val_r2: 0.706544
2024-05-22 20:36:11 Epoch 41: lr=1e-05
2024-05-22 20:37:22 [Epoch: 41] loss: 0.004898, mae: 0.049692, r2: 0.763448, val_loss: 0.006103, val_mae: 0.054298, val_r2: 0.707626
2024-05-22 20:37:22 Epoch 42: lr=1e-05
2024-05-22 20:38:33 [Epoch: 42] loss: 0.004899, mae: 0.049659, r2: 0.763342, val_loss: 0.006107, val_mae: 0.054308, val_r2: 0.707486
2024-05-22 20:38:33 Epoch 43: lr=1e-05
2024-05-22 20:39:45 [Epoch: 43] loss: 0.004884, mae: 0.049627, r2: 0.764102, val_loss: 0.006110, val_mae: 0.054283, val_r2: 0.707238
2024-05-22 20:39:45 Epoch 44: lr=1e-05
2024-05-22 20:40:56 [Epoch: 44] loss: 0.004891, mae: 0.049612, r2: 0.763877, val_loss: 0.006136, val_mae: 0.054225, val_r2: 0.706707
2024-05-22 20:40:56 Epoch 45: lr=1e-05
2024-05-22 20:42:07 [Epoch: 45] loss: 0.004884, mae: 0.049582, r2: 0.763981, val_loss: 0.006118, val_mae: 0.054439, val_r2: 0.706450
2024-05-22 20:42:07 Epoch 46: lr=1e-05
2024-05-22 20:43:18 [Epoch: 46] loss: 0.004876, mae: 0.049567, r2: 0.764289, val_loss: 0.006092, val_mae: 0.054431, val_r2: 0.708157
2024-05-22 20:43:18 Epoch 47: lr=1e-05
2024-05-22 20:44:30 [Epoch: 47] loss: 0.004861, mae: 0.049496, r2: 0.765178, val_loss: 0.006122, val_mae: 0.054486, val_r2: 0.706676
2024-05-22 20:44:30 Epoch 48: lr=1e-05
2024-05-22 20:45:41 [Epoch: 48] loss: 0.004860, mae: 0.049477, r2: 0.765185, val_loss: 0.006114, val_mae: 0.054419, val_r2: 0.706280
2024-05-22 20:45:41 Epoch 49: lr=1e-05
2024-05-22 20:46:52 [Epoch: 49] loss: 0.004872, mae: 0.049524, r2: 0.764847, val_loss: 0.006115, val_mae: 0.054422, val_r2: 0.707394
2024-05-22 20:46:53 history_length: 50
2024-05-22 20:46:53 stopping: complete
2024-05-22 20:46:53 Comparing y_true and y_pred:
2024-05-22 20:46:53   mse: 0.01270143
2024-05-22 20:46:53   mae: 0.09513083
2024-05-22 20:46:53   r2: -1.17249256
2024-05-22 20:46:53   corr: 0.34558631
