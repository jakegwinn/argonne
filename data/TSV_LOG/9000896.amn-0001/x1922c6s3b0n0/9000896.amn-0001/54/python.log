2024-05-22 19:47:05 UNO RUN ...
2024-05-22 19:47:05 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000896.amn-0001/54', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000896.amn-0001', 'run_id': '54', 'logfile': '/dev/shm/Uno/save/9000896.amn-0001/54/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000896.amn-0001/54', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s3b0n0.54.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000896.amn-0001/54/3.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000896.amn-0001/54'}
2024-05-22 19:47:05 Feature encoding submodel for cell.rnaseq:
2024-05-22 19:47:05 Model: "cell.rnaseq"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense (Dense)               (None, 1000)              959000    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 19:47:05  ntDropout)                                                      
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Trainable params: 2961000 (11.30 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Feature encoding submodel for drug.descriptors:
2024-05-22 19:47:05 Model: "drug.descriptors"
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape              Param #   
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 19:47:05  nentDropout)                                                    
2024-05-22 19:47:05                                                                  
2024-05-22 19:47:05 =================================================================
2024-05-22 19:47:05 Total params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Trainable params: 3616000 (13.79 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 _________________________________________________________________
2024-05-22 19:47:05 Combined model:
2024-05-22 19:47:05 Model: "model"
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 19:47:05  yer)                                                                                             
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 19:47:05  nputLayer)                                                                                       
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 19:47:05  al)                                                                ]']                           
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 19:47:05                                                                      'drug.descriptors[0][0]']    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 19:47:05  nentDropout)                                                                                     
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 19:47:05  anentDropout)                                                                                    
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 19:47:05                                                                                                   
2024-05-22 19:47:05 ==================================================================================================
2024-05-22 19:47:05 Total params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Trainable params: 12583001 (48.00 MB)
2024-05-22 19:47:05 Non-trainable params: 0 (0.00 Byte)
2024-05-22 19:47:05 __________________________________________________________________________________________________
2024-05-22 19:47:05 CKPT CONSTRUCT...
2024-05-22 19:47:05 CKPT CONSTRUCT OK.
2024-05-22 19:47:05 template model: <keras.src.engine.functional.Functional object at 0x147d1b410be0>
2024-05-22 19:47:07 COMPILE
2024-05-22 19:47:07 Will save weights to: /dev/shm/Uno/save/9000896.amn-0001/54/3.0.model.h5
2024-05-22 19:47:23 Between random pairs in y_val:
2024-05-22 19:47:23   mse: 0.04711322
2024-05-22 19:47:23   mae: 0.15896718
2024-05-22 19:47:23   r2: -0.99093004
2024-05-22 19:47:23   corr: 0.00453498
2024-05-22 19:47:23 Data points per epoch: train = 469653, val = 117414, test = 642
2024-05-22 19:47:23 Steps per epoch: train = 14676, val = 3669, test = 20
2024-05-22 19:47:24 Epoch 0: lr=0.001
2024-05-22 19:48:36 [Epoch: 0] loss: 0.025815, mae: 0.079575, r2: -0.064086, val_loss: 0.008482, val_mae: 0.065521, val_r2: 0.597574
2024-05-22 19:48:36 Epoch 1: lr=0.00082
2024-05-22 19:49:47 [Epoch: 1] loss: 0.008038, mae: 0.064162, r2: 0.618652, val_loss: 0.007754, val_mae: 0.061650, val_r2: 0.630956
2024-05-22 19:49:47 Epoch 2: lr=0.00064
2024-05-22 19:50:58 [Epoch: 2] loss: 0.007343, mae: 0.060958, r2: 0.650549, val_loss: 0.007311, val_mae: 0.060833, val_r2: 0.646489
2024-05-22 19:50:58 Epoch 3: lr=0.00046
2024-05-22 19:52:08 [Epoch: 3] loss: 0.006868, mae: 0.058791, r2: 0.672300, val_loss: 0.007169, val_mae: 0.059292, val_r2: 0.652653
2024-05-22 19:52:09 Epoch 4: lr=0.00028
2024-05-22 19:53:19 [Epoch: 4] loss: 0.006480, mae: 0.056962, r2: 0.690201, val_loss: 0.006566, val_mae: 0.057189, val_r2: 0.686220
2024-05-22 19:53:20 Epoch 5: lr=0.0001
2024-05-22 19:54:30 [Epoch: 5] loss: 0.006144, mae: 0.055429, r2: 0.705503, val_loss: 0.006425, val_mae: 0.056628, val_r2: 0.690613
2024-05-22 19:54:30 Epoch 6: lr=0.0001
2024-05-22 19:55:41 [Epoch: 6] loss: 0.006035, mae: 0.054949, r2: 0.710472, val_loss: 0.006378, val_mae: 0.056145, val_r2: 0.691305
2024-05-22 19:55:41 Epoch 7: lr=0.0001
2024-05-22 19:56:52 [Epoch: 7] loss: 0.005948, mae: 0.054565, r2: 0.714621, val_loss: 0.006374, val_mae: 0.056438, val_r2: 0.690404
2024-05-22 19:56:52 Epoch 8: lr=0.0001
2024-05-22 19:58:03 [Epoch: 8] loss: 0.005879, mae: 0.054233, r2: 0.717906, val_loss: 0.006292, val_mae: 0.055952, val_r2: 0.696950
2024-05-22 19:58:03 Epoch 9: lr=0.0001
2024-05-22 19:59:14 [Epoch: 9] loss: 0.005801, mae: 0.053906, r2: 0.721404, val_loss: 0.006278, val_mae: 0.055744, val_r2: 0.697517
2024-05-22 19:59:14 Epoch 10: lr=0.0001
2024-05-22 20:00:25 [Epoch: 10] loss: 0.005745, mae: 0.053659, r2: 0.723939, val_loss: 0.006292, val_mae: 0.055874, val_r2: 0.695747
2024-05-22 20:00:25 Epoch 11: lr=0.0001
2024-05-22 20:01:36 [Epoch: 11] loss: 0.005699, mae: 0.053413, r2: 0.726233, val_loss: 0.006269, val_mae: 0.055643, val_r2: 0.696416
2024-05-22 20:01:36 Epoch 12: lr=0.0001
2024-05-22 20:02:47 [Epoch: 12] loss: 0.005633, mae: 0.053183, r2: 0.728985, val_loss: 0.006206, val_mae: 0.055611, val_r2: 0.699687
2024-05-22 20:02:47 Epoch 13: lr=0.0001
2024-05-22 20:03:58 [Epoch: 13] loss: 0.005572, mae: 0.052845, r2: 0.732043, val_loss: 0.006180, val_mae: 0.055031, val_r2: 0.701056
2024-05-22 20:03:58 Epoch 14: lr=0.0001
2024-05-22 20:05:09 [Epoch: 14] loss: 0.005516, mae: 0.052626, r2: 0.735029, val_loss: 0.006170, val_mae: 0.054836, val_r2: 0.700998
2024-05-22 20:05:09 Epoch 15: lr=0.0001
2024-05-22 20:06:20 [Epoch: 15] loss: 0.005473, mae: 0.052409, r2: 0.736789, val_loss: 0.006149, val_mae: 0.055022, val_r2: 0.703404
2024-05-22 20:06:20 Epoch 16: lr=0.0001
2024-05-22 20:07:31 [Epoch: 16] loss: 0.005417, mae: 0.052144, r2: 0.739178, val_loss: 0.006148, val_mae: 0.055075, val_r2: 0.703761
2024-05-22 20:07:31 Epoch 17: lr=0.0001
2024-05-22 20:08:42 [Epoch: 17] loss: 0.005363, mae: 0.051921, r2: 0.741982, val_loss: 0.006137, val_mae: 0.054458, val_r2: 0.703482
2024-05-22 20:08:42 Epoch 18: lr=0.0001
2024-05-22 20:09:53 [Epoch: 18] loss: 0.005316, mae: 0.051697, r2: 0.744117, val_loss: 0.006108, val_mae: 0.054900, val_r2: 0.704523
2024-05-22 20:09:53 Epoch 19: lr=5e-05
2024-05-22 20:11:04 [Epoch: 19] loss: 0.005211, mae: 0.051178, r2: 0.749263, val_loss: 0.006081, val_mae: 0.054392, val_r2: 0.706090
2024-05-22 20:11:04 Epoch 20: lr=5e-05
2024-05-22 20:12:15 [Epoch: 20] loss: 0.005169, mae: 0.050992, r2: 0.750914, val_loss: 0.006085, val_mae: 0.054576, val_r2: 0.705367
2024-05-22 20:12:15 Epoch 21: lr=5e-05
2024-05-22 20:13:26 [Epoch: 21] loss: 0.005130, mae: 0.050779, r2: 0.752628, val_loss: 0.006074, val_mae: 0.054371, val_r2: 0.705688
2024-05-22 20:13:26 Epoch 22: lr=5e-05
2024-05-22 20:14:37 [Epoch: 22] loss: 0.005113, mae: 0.050676, r2: 0.753690, val_loss: 0.006079, val_mae: 0.054501, val_r2: 0.705089
2024-05-22 20:14:37 Epoch 23: lr=5e-05
2024-05-22 20:15:48 [Epoch: 23] loss: 0.005084, mae: 0.050543, r2: 0.754945, val_loss: 0.006058, val_mae: 0.054517, val_r2: 0.705681
2024-05-22 20:15:48 Epoch 24: lr=5e-05
2024-05-22 20:16:59 [Epoch: 24] loss: 0.005053, mae: 0.050413, r2: 0.756208, val_loss: 0.006047, val_mae: 0.054288, val_r2: 0.706954
2024-05-22 20:16:59 Epoch 25: lr=5e-05
2024-05-22 20:18:09 [Epoch: 25] loss: 0.005036, mae: 0.050328, r2: 0.757064, val_loss: 0.006063, val_mae: 0.054262, val_r2: 0.706928
2024-05-22 20:18:09 Epoch 26: lr=5e-05
2024-05-22 20:19:20 [Epoch: 26] loss: 0.005012, mae: 0.050213, r2: 0.758296, val_loss: 0.006079, val_mae: 0.054387, val_r2: 0.705037
2024-05-22 20:19:21 Epoch 27: lr=2.5e-05
2024-05-22 20:20:31 [Epoch: 27] loss: 0.004950, mae: 0.049894, r2: 0.761250, val_loss: 0.006068, val_mae: 0.054495, val_r2: 0.705074
2024-05-22 20:20:31 Epoch 28: lr=2.5e-05
2024-05-22 20:21:42 [Epoch: 28] loss: 0.004944, mae: 0.049868, r2: 0.761560, val_loss: 0.006066, val_mae: 0.054140, val_r2: 0.705225
2024-05-22 20:21:43 Epoch 29: lr=2.5e-05
2024-05-22 20:22:54 [Epoch: 29] loss: 0.004922, mae: 0.049752, r2: 0.762464, val_loss: 0.006053, val_mae: 0.054361, val_r2: 0.706598
2024-05-22 20:22:54 Epoch 30: lr=2.5e-05
2024-05-22 20:24:04 [Epoch: 30] loss: 0.004902, mae: 0.049660, r2: 0.763398, val_loss: 0.006049, val_mae: 0.054222, val_r2: 0.705789
2024-05-22 20:24:05 Epoch 31: lr=2.5e-05
2024-05-22 20:25:15 [Epoch: 31] loss: 0.004894, mae: 0.049641, r2: 0.764015, val_loss: 0.006049, val_mae: 0.054236, val_r2: 0.706507
2024-05-22 20:25:16 Epoch 32: lr=1.25e-05
2024-05-22 20:26:26 [Epoch: 32] loss: 0.004856, mae: 0.049454, r2: 0.765673, val_loss: 0.006063, val_mae: 0.054213, val_r2: 0.706249
2024-05-22 20:26:26 Epoch 33: lr=1.25e-05
2024-05-22 20:27:37 [Epoch: 33] loss: 0.004839, mae: 0.049383, r2: 0.766333, val_loss: 0.006046, val_mae: 0.054097, val_r2: 0.706337
2024-05-22 20:27:37 Epoch 34: lr=1.25e-05
2024-05-22 20:28:48 [Epoch: 34] loss: 0.004830, mae: 0.049342, r2: 0.766542, val_loss: 0.006042, val_mae: 0.054226, val_r2: 0.707104
2024-05-22 20:28:48 Epoch 35: lr=1.25e-05
2024-05-22 20:29:59 [Epoch: 35] loss: 0.004832, mae: 0.049354, r2: 0.766769, val_loss: 0.006080, val_mae: 0.054277, val_r2: 0.705341
2024-05-22 20:29:59 Epoch 36: lr=1.25e-05
2024-05-22 20:31:10 [Epoch: 36] loss: 0.004830, mae: 0.049340, r2: 0.766856, val_loss: 0.006048, val_mae: 0.054185, val_r2: 0.706553
2024-05-22 20:31:10 Epoch 37: lr=1e-05
2024-05-22 20:32:21 [Epoch: 37] loss: 0.004820, mae: 0.049269, r2: 0.767187, val_loss: 0.006052, val_mae: 0.054309, val_r2: 0.706248
2024-05-22 20:32:21 Epoch 38: lr=1e-05
2024-05-22 20:33:32 [Epoch: 38] loss: 0.004821, mae: 0.049295, r2: 0.767171, val_loss: 0.006042, val_mae: 0.054122, val_r2: 0.707220
2024-05-22 20:33:32 Epoch 39: lr=1e-05
2024-05-22 20:34:43 [Epoch: 39] loss: 0.004811, mae: 0.049251, r2: 0.767591, val_loss: 0.006029, val_mae: 0.054027, val_r2: 0.707372
2024-05-22 20:34:43 Epoch 40: lr=1e-05
2024-05-22 20:35:54 [Epoch: 40] loss: 0.004786, mae: 0.049114, r2: 0.768764, val_loss: 0.006064, val_mae: 0.054203, val_r2: 0.706290
2024-05-22 20:35:54 Epoch 41: lr=1e-05
2024-05-22 20:37:05 [Epoch: 41] loss: 0.004791, mae: 0.049169, r2: 0.768580, val_loss: 0.006039, val_mae: 0.054125, val_r2: 0.706301
2024-05-22 20:37:05 Epoch 42: lr=1e-05
2024-05-22 20:38:15 [Epoch: 42] loss: 0.004789, mae: 0.049160, r2: 0.768528, val_loss: 0.006058, val_mae: 0.054135, val_r2: 0.706266
2024-05-22 20:38:15 Epoch 43: lr=1e-05
2024-05-22 20:39:26 [Epoch: 43] loss: 0.004780, mae: 0.049105, r2: 0.768943, val_loss: 0.006031, val_mae: 0.054182, val_r2: 0.707194
2024-05-22 20:39:26 Epoch 44: lr=1e-05
2024-05-22 20:40:37 [Epoch: 44] loss: 0.004777, mae: 0.049048, r2: 0.769313, val_loss: 0.006065, val_mae: 0.054302, val_r2: 0.705761
2024-05-22 20:40:37 Epoch 45: lr=1e-05
2024-05-22 20:41:47 [Epoch: 45] loss: 0.004781, mae: 0.049096, r2: 0.769266, val_loss: 0.006044, val_mae: 0.054125, val_r2: 0.706876
2024-05-22 20:41:48 Epoch 46: lr=1e-05
2024-05-22 20:42:58 [Epoch: 46] loss: 0.004762, mae: 0.049025, r2: 0.769915, val_loss: 0.006033, val_mae: 0.054102, val_r2: 0.707214
2024-05-22 20:42:58 Epoch 47: lr=1e-05
2024-05-22 20:44:09 [Epoch: 47] loss: 0.004756, mae: 0.048964, r2: 0.769990, val_loss: 0.006078, val_mae: 0.054070, val_r2: 0.704991
2024-05-22 20:44:09 Epoch 48: lr=1e-05
2024-05-22 20:45:20 [Epoch: 48] loss: 0.004747, mae: 0.048948, r2: 0.770569, val_loss: 0.006083, val_mae: 0.054273, val_r2: 0.704614
2024-05-22 20:45:20 Epoch 49: lr=1e-05
2024-05-22 20:46:31 [Epoch: 49] loss: 0.004755, mae: 0.048993, r2: 0.770287, val_loss: 0.006085, val_mae: 0.054130, val_r2: 0.705102
2024-05-22 20:46:31 history_length: 50
2024-05-22 20:46:31 stopping: complete
2024-05-22 20:46:31 Comparing y_true and y_pred:
2024-05-22 20:46:31   mse: 0.00416218
2024-05-22 20:46:31   mae: 0.05324845
2024-05-22 20:46:31   r2: -0.69616160
2024-05-22 20:46:31   corr: 0.12872396
