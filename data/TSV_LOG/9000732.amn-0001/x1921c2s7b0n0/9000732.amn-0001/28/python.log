2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/28', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '28', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/28/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/28', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c2s7b0n0.28.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/28/2.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/28'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x14f0bc0b5b80>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/28/2.0.model.h5
2024-05-22 13:29:54 Between random pairs in y_val:
2024-05-22 13:29:54   mse: 0.04788257
2024-05-22 13:29:54   mae: 0.16024738
2024-05-22 13:29:54   r2: -0.99558674
2024-05-22 13:29:54   corr: 0.00220663
2024-05-22 13:29:54 Data points per epoch: train = 469316, val = 117330, test = 1063
2024-05-22 13:29:54 Steps per epoch: train = 14666, val = 3666, test = 33
2024-05-22 13:29:54 Epoch 0: lr=0.001
2024-05-22 13:31:07 [Epoch: 0] loss: 0.024989, mae: 0.079607, r2: -0.524357, val_loss: 0.008733, val_mae: 0.065529, val_r2: 0.584089
2024-05-22 13:31:07 Epoch 1: lr=0.00082
2024-05-22 13:32:19 [Epoch: 1] loss: 0.008013, mae: 0.064051, r2: 0.621148, val_loss: 0.007652, val_mae: 0.062086, val_r2: 0.642987
2024-05-22 13:32:19 Epoch 2: lr=0.00064
2024-05-22 13:33:30 [Epoch: 2] loss: 0.007330, mae: 0.060882, r2: 0.652962, val_loss: 0.007221, val_mae: 0.060120, val_r2: 0.654568
2024-05-22 13:33:30 Epoch 3: lr=0.00046
2024-05-22 13:34:42 [Epoch: 3] loss: 0.006854, mae: 0.058742, r2: 0.674794, val_loss: 0.006872, val_mae: 0.058356, val_r2: 0.673801
2024-05-22 13:34:42 Epoch 4: lr=0.00028
2024-05-22 13:35:53 [Epoch: 4] loss: 0.006442, mae: 0.056834, r2: 0.693680, val_loss: 0.006668, val_mae: 0.057100, val_r2: 0.681696
2024-05-22 13:35:53 Epoch 5: lr=0.0001
2024-05-22 13:37:05 [Epoch: 5] loss: 0.006113, mae: 0.055353, r2: 0.708377, val_loss: 0.006465, val_mae: 0.056245, val_r2: 0.691056
2024-05-22 13:37:05 Epoch 6: lr=0.0001
2024-05-22 13:38:16 [Epoch: 6] loss: 0.006004, mae: 0.054811, r2: 0.713619, val_loss: 0.006403, val_mae: 0.056128, val_r2: 0.695105
2024-05-22 13:38:16 Epoch 7: lr=0.0001
2024-05-22 13:39:28 [Epoch: 7] loss: 0.005925, mae: 0.054466, r2: 0.716865, val_loss: 0.006375, val_mae: 0.056092, val_r2: 0.695633
2024-05-22 13:39:28 Epoch 8: lr=0.0001
2024-05-22 13:40:40 [Epoch: 8] loss: 0.005849, mae: 0.054088, r2: 0.720687, val_loss: 0.006335, val_mae: 0.055736, val_r2: 0.699004
2024-05-22 13:40:40 Epoch 9: lr=0.0001
2024-05-22 13:41:51 [Epoch: 9] loss: 0.005789, mae: 0.053826, r2: 0.723717, val_loss: 0.006347, val_mae: 0.055610, val_r2: 0.696948
2024-05-22 13:41:52 Epoch 10: lr=0.0001
2024-05-22 13:43:03 [Epoch: 10] loss: 0.005726, mae: 0.053574, r2: 0.726365, val_loss: 0.006310, val_mae: 0.055351, val_r2: 0.698751
2024-05-22 13:43:03 Epoch 11: lr=0.0001
2024-05-22 13:44:15 [Epoch: 11] loss: 0.005664, mae: 0.053282, r2: 0.729287, val_loss: 0.006276, val_mae: 0.056067, val_r2: 0.701225
2024-05-22 13:44:15 Epoch 12: lr=0.0001
2024-05-22 13:45:26 [Epoch: 12] loss: 0.005600, mae: 0.052995, r2: 0.732151, val_loss: 0.006268, val_mae: 0.056061, val_r2: 0.700705
2024-05-22 13:45:26 Epoch 13: lr=0.0001
2024-05-22 13:46:37 [Epoch: 13] loss: 0.005539, mae: 0.052732, r2: 0.734946, val_loss: 0.006245, val_mae: 0.056023, val_r2: 0.701851
2024-05-22 13:46:38 Epoch 14: lr=5e-05
2024-05-22 13:47:49 [Epoch: 14] loss: 0.005420, mae: 0.052156, r2: 0.740729, val_loss: 0.006207, val_mae: 0.054940, val_r2: 0.704160
2024-05-22 13:47:49 Epoch 15: lr=5e-05
2024-05-22 13:49:00 [Epoch: 15] loss: 0.005374, mae: 0.051928, r2: 0.742664, val_loss: 0.006216, val_mae: 0.054979, val_r2: 0.703073
2024-05-22 13:49:01 Epoch 16: lr=5e-05
2024-05-22 13:50:12 [Epoch: 16] loss: 0.005343, mae: 0.051781, r2: 0.744242, val_loss: 0.006192, val_mae: 0.054958, val_r2: 0.704405
2024-05-22 13:50:12 Epoch 17: lr=5e-05
2024-05-22 13:51:24 [Epoch: 17] loss: 0.005317, mae: 0.051680, r2: 0.745447, val_loss: 0.006187, val_mae: 0.054994, val_r2: 0.704322
2024-05-22 13:51:24 Epoch 18: lr=5e-05
2024-05-22 13:52:36 [Epoch: 18] loss: 0.005275, mae: 0.051509, r2: 0.747466, val_loss: 0.006206, val_mae: 0.054894, val_r2: 0.703005
2024-05-22 13:52:36 Epoch 19: lr=5e-05
2024-05-22 13:53:47 [Epoch: 19] loss: 0.005261, mae: 0.051427, r2: 0.747935, val_loss: 0.006185, val_mae: 0.055445, val_r2: 0.704109
2024-05-22 13:53:47 Epoch 20: lr=2.5e-05
2024-05-22 13:54:59 [Epoch: 20] loss: 0.005194, mae: 0.051111, r2: 0.751092, val_loss: 0.006173, val_mae: 0.054785, val_r2: 0.705219
2024-05-22 13:54:59 Epoch 21: lr=2.5e-05
2024-05-22 13:56:10 [Epoch: 21] loss: 0.005163, mae: 0.050964, r2: 0.752530, val_loss: 0.006170, val_mae: 0.054953, val_r2: 0.705897
2024-05-22 13:56:11 Epoch 22: lr=2.5e-05
2024-05-22 13:57:22 [Epoch: 22] loss: 0.005152, mae: 0.050889, r2: 0.752974, val_loss: 0.006163, val_mae: 0.055140, val_r2: 0.705891
2024-05-22 13:57:22 Epoch 23: lr=2.5e-05
2024-05-22 13:58:33 [Epoch: 23] loss: 0.005133, mae: 0.050824, r2: 0.753764, val_loss: 0.006184, val_mae: 0.054807, val_r2: 0.704571
2024-05-22 13:58:33 Epoch 24: lr=2.5e-05
2024-05-22 13:59:45 [Epoch: 24] loss: 0.005123, mae: 0.050783, r2: 0.754480, val_loss: 0.006180, val_mae: 0.054678, val_r2: 0.704596
2024-05-22 13:59:45 Epoch 25: lr=1.25e-05
2024-05-22 14:00:57 [Epoch: 25] loss: 0.005095, mae: 0.050640, r2: 0.755623, val_loss: 0.006149, val_mae: 0.054807, val_r2: 0.706396
2024-05-22 14:00:57 Epoch 26: lr=1.25e-05
2024-05-22 14:02:09 [Epoch: 26] loss: 0.005084, mae: 0.050596, r2: 0.756131, val_loss: 0.006160, val_mae: 0.054617, val_r2: 0.706283
2024-05-22 14:02:09 Epoch 27: lr=1.25e-05
2024-05-22 14:03:20 [Epoch: 27] loss: 0.005079, mae: 0.050571, r2: 0.756372, val_loss: 0.006193, val_mae: 0.054793, val_r2: 0.704274
2024-05-22 14:03:20 Epoch 28: lr=1.25e-05
2024-05-22 14:04:31 [Epoch: 28] loss: 0.005057, mae: 0.050455, r2: 0.757458, val_loss: 0.006181, val_mae: 0.054917, val_r2: 0.705014
2024-05-22 14:04:31 Epoch 29: lr=1.25e-05
2024-05-22 14:05:43 [Epoch: 29] loss: 0.005059, mae: 0.050473, r2: 0.757387, val_loss: 0.006170, val_mae: 0.054949, val_r2: 0.705564
2024-05-22 14:05:43 Epoch 30: lr=1e-05
2024-05-22 14:06:54 [Epoch: 30] loss: 0.005039, mae: 0.050369, r2: 0.758227, val_loss: 0.006176, val_mae: 0.054851, val_r2: 0.704822
2024-05-22 14:06:54 Epoch 31: lr=1e-05
2024-05-22 14:08:06 [Epoch: 31] loss: 0.005032, mae: 0.050352, r2: 0.758490, val_loss: 0.006162, val_mae: 0.054816, val_r2: 0.705746
2024-05-22 14:08:06 Epoch 32: lr=1e-05
2024-05-22 14:09:17 [Epoch: 32] loss: 0.005026, mae: 0.050323, r2: 0.759043, val_loss: 0.006163, val_mae: 0.054731, val_r2: 0.705821
2024-05-22 14:09:17 Epoch 33: lr=1e-05
2024-05-22 14:10:28 [Epoch: 33] loss: 0.005030, mae: 0.050344, r2: 0.758830, val_loss: 0.006160, val_mae: 0.054628, val_r2: 0.705669
2024-05-22 14:10:29 Epoch 34: lr=1e-05
2024-05-22 14:11:40 [Epoch: 34] loss: 0.005016, mae: 0.050261, r2: 0.759397, val_loss: 0.006171, val_mae: 0.054797, val_r2: 0.705322
2024-05-22 14:11:40 Epoch 35: lr=1e-05
2024-05-22 14:12:52 [Epoch: 35] loss: 0.005015, mae: 0.050267, r2: 0.759429, val_loss: 0.006148, val_mae: 0.054721, val_r2: 0.705792
2024-05-22 14:12:52 Epoch 36: lr=1e-05
2024-05-22 14:14:03 [Epoch: 36] loss: 0.005000, mae: 0.050224, r2: 0.760044, val_loss: 0.006144, val_mae: 0.054756, val_r2: 0.706297
2024-05-22 14:14:03 Epoch 37: lr=1e-05
2024-05-22 14:15:15 [Epoch: 37] loss: 0.005003, mae: 0.050217, r2: 0.760090, val_loss: 0.006152, val_mae: 0.054705, val_r2: 0.705950
2024-05-22 14:15:15 Epoch 38: lr=1e-05
2024-05-22 14:16:26 [Epoch: 38] loss: 0.004986, mae: 0.050121, r2: 0.760627, val_loss: 0.006163, val_mae: 0.054517, val_r2: 0.706018
2024-05-22 14:16:26 Epoch 39: lr=1e-05
2024-05-22 14:17:38 [Epoch: 39] loss: 0.004992, mae: 0.050147, r2: 0.760468, val_loss: 0.006151, val_mae: 0.054547, val_r2: 0.706832
2024-05-22 14:17:38 Epoch 40: lr=1e-05
2024-05-22 14:18:49 [Epoch: 40] loss: 0.004976, mae: 0.050092, r2: 0.761222, val_loss: 0.006159, val_mae: 0.054775, val_r2: 0.706287
2024-05-22 14:18:49 Epoch 41: lr=1e-05
2024-05-22 14:20:00 [Epoch: 41] loss: 0.004985, mae: 0.050092, r2: 0.760673, val_loss: 0.006154, val_mae: 0.054575, val_r2: 0.706205
2024-05-22 14:20:01 Epoch 42: lr=1e-05
2024-05-22 14:21:12 [Epoch: 42] loss: 0.004972, mae: 0.050091, r2: 0.761256, val_loss: 0.006147, val_mae: 0.054602, val_r2: 0.706486
2024-05-22 14:21:12 Epoch 43: lr=1e-05
2024-05-22 14:22:23 [Epoch: 43] loss: 0.004974, mae: 0.050059, r2: 0.761313, val_loss: 0.006181, val_mae: 0.054598, val_r2: 0.705133
2024-05-22 14:22:23 Epoch 44: lr=1e-05
2024-05-22 14:23:35 [Epoch: 44] loss: 0.004964, mae: 0.050012, r2: 0.761689, val_loss: 0.006165, val_mae: 0.054561, val_r2: 0.705471
2024-05-22 14:23:35 Epoch 45: lr=1e-05
2024-05-22 14:24:47 [Epoch: 45] loss: 0.004958, mae: 0.050000, r2: 0.762100, val_loss: 0.006141, val_mae: 0.054518, val_r2: 0.706720
2024-05-22 14:24:47 Epoch 46: lr=1e-05
2024-05-22 14:25:58 [Epoch: 46] loss: 0.004950, mae: 0.049933, r2: 0.762408, val_loss: 0.006162, val_mae: 0.054860, val_r2: 0.706049
2024-05-22 14:25:58 Epoch 47: lr=1e-05
2024-05-22 14:27:10 [Epoch: 47] loss: 0.004937, mae: 0.049913, r2: 0.763132, val_loss: 0.006145, val_mae: 0.054587, val_r2: 0.707048
2024-05-22 14:27:10 Epoch 48: lr=1e-05
2024-05-22 14:28:21 [Epoch: 48] loss: 0.004940, mae: 0.049893, r2: 0.762864, val_loss: 0.006151, val_mae: 0.054651, val_r2: 0.706268
2024-05-22 14:28:21 Epoch 49: lr=1e-05
2024-05-22 14:29:32 [Epoch: 49] loss: 0.004940, mae: 0.049909, r2: 0.762887, val_loss: 0.006155, val_mae: 0.054608, val_r2: 0.706540
2024-05-22 14:29:33 history_length: 50
2024-05-22 14:29:33 stopping: complete
2024-05-22 14:29:33 Comparing y_true and y_pred:
2024-05-22 14:29:33   mse: 0.00275740
2024-05-22 14:29:33   mae: 0.03958896
2024-05-22 14:29:33   r2: -0.10871092
2024-05-22 14:29:33   corr: 0.10586364
