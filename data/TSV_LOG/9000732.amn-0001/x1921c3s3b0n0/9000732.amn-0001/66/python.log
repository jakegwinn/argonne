2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/66', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '66', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/66/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/66', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c3s3b0n0.66.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/66/3.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/66'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x14dbbec7af40>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/66/3.0.model.h5
2024-05-22 13:29:55 Between random pairs in y_val:
2024-05-22 13:29:55   mse: 0.04782175
2024-05-22 13:29:55   mae: 0.16011374
2024-05-22 13:29:55   r2: -1.01222665
2024-05-22 13:29:55   corr: -0.00611332
2024-05-22 13:29:55 Data points per epoch: train = 469906, val = 117477, test = 326
2024-05-22 13:29:55 Steps per epoch: train = 14684, val = 3671, test = 10
2024-05-22 13:29:55 Epoch 0: lr=0.001
2024-05-22 13:31:07 [Epoch: 0] loss: 0.026017, mae: 0.079669, r2: -1.025923, val_loss: 0.008868, val_mae: 0.066795, val_r2: 0.583167
2024-05-22 13:31:07 Epoch 1: lr=0.00082
2024-05-22 13:32:18 [Epoch: 1] loss: 0.008001, mae: 0.064013, r2: 0.621321, val_loss: 0.007722, val_mae: 0.063077, val_r2: 0.630608
2024-05-22 13:32:18 Epoch 2: lr=0.00064
2024-05-22 13:33:28 [Epoch: 2] loss: 0.007316, mae: 0.060823, r2: 0.652844, val_loss: 0.007353, val_mae: 0.060787, val_r2: 0.647572
2024-05-22 13:33:28 Epoch 3: lr=0.00046
2024-05-22 13:34:39 [Epoch: 3] loss: 0.006824, mae: 0.058671, r2: 0.675427, val_loss: 0.006923, val_mae: 0.058569, val_r2: 0.669068
2024-05-22 13:34:39 Epoch 4: lr=0.00028
2024-05-22 13:35:49 [Epoch: 4] loss: 0.006426, mae: 0.056818, r2: 0.693490, val_loss: 0.006726, val_mae: 0.057154, val_r2: 0.676635
2024-05-22 13:35:49 Epoch 5: lr=0.0001
2024-05-22 13:37:00 [Epoch: 5] loss: 0.006086, mae: 0.055256, r2: 0.708891, val_loss: 0.006541, val_mae: 0.057109, val_r2: 0.685955
2024-05-22 13:37:00 Epoch 6: lr=0.0001
2024-05-22 13:38:10 [Epoch: 6] loss: 0.005973, mae: 0.054752, r2: 0.714096, val_loss: 0.006500, val_mae: 0.056626, val_r2: 0.688403
2024-05-22 13:38:10 Epoch 7: lr=0.0001
2024-05-22 13:39:20 [Epoch: 7] loss: 0.005903, mae: 0.054393, r2: 0.717621, val_loss: 0.006451, val_mae: 0.056296, val_r2: 0.690333
2024-05-22 13:39:20 Epoch 8: lr=0.0001
2024-05-22 13:40:30 [Epoch: 8] loss: 0.005828, mae: 0.054067, r2: 0.721068, val_loss: 0.006443, val_mae: 0.055823, val_r2: 0.690342
2024-05-22 13:40:30 Epoch 9: lr=0.0001
2024-05-22 13:41:41 [Epoch: 9] loss: 0.005768, mae: 0.053797, r2: 0.723596, val_loss: 0.006381, val_mae: 0.055938, val_r2: 0.695006
2024-05-22 13:41:41 Epoch 10: lr=0.0001
2024-05-22 13:42:51 [Epoch: 10] loss: 0.005704, mae: 0.053500, r2: 0.726587, val_loss: 0.006367, val_mae: 0.055513, val_r2: 0.695286
2024-05-22 13:42:51 Epoch 11: lr=0.0001
2024-05-22 13:44:02 [Epoch: 11] loss: 0.005651, mae: 0.053247, r2: 0.728978, val_loss: 0.006335, val_mae: 0.056098, val_r2: 0.697149
2024-05-22 13:44:02 Epoch 12: lr=0.0001
2024-05-22 13:45:13 [Epoch: 12] loss: 0.005594, mae: 0.052995, r2: 0.731609, val_loss: 0.006330, val_mae: 0.055586, val_r2: 0.696682
2024-05-22 13:45:13 Epoch 13: lr=0.0001
2024-05-22 13:46:23 [Epoch: 13] loss: 0.005534, mae: 0.052708, r2: 0.734359, val_loss: 0.006321, val_mae: 0.055693, val_r2: 0.697417
2024-05-22 13:46:23 Epoch 14: lr=0.0001
2024-05-22 13:47:33 [Epoch: 14] loss: 0.005489, mae: 0.052499, r2: 0.736542, val_loss: 0.006287, val_mae: 0.055179, val_r2: 0.699776
2024-05-22 13:47:33 Epoch 15: lr=5e-05
2024-05-22 13:48:44 [Epoch: 15] loss: 0.005359, mae: 0.051932, r2: 0.742807, val_loss: 0.006278, val_mae: 0.054947, val_r2: 0.698946
2024-05-22 13:48:44 Epoch 16: lr=5e-05
2024-05-22 13:49:54 [Epoch: 16] loss: 0.005323, mae: 0.051776, r2: 0.744387, val_loss: 0.006281, val_mae: 0.055382, val_r2: 0.698491
2024-05-22 13:49:55 Epoch 17: lr=5e-05
2024-05-22 13:51:05 [Epoch: 17] loss: 0.005284, mae: 0.051565, r2: 0.746337, val_loss: 0.006246, val_mae: 0.054829, val_r2: 0.700727
2024-05-22 13:51:05 Epoch 18: lr=5e-05
2024-05-22 13:52:15 [Epoch: 18] loss: 0.005252, mae: 0.051451, r2: 0.747574, val_loss: 0.006246, val_mae: 0.054829, val_r2: 0.700712
2024-05-22 13:52:15 Epoch 19: lr=5e-05
2024-05-22 13:53:25 [Epoch: 19] loss: 0.005216, mae: 0.051277, r2: 0.749117, val_loss: 0.006244, val_mae: 0.055189, val_r2: 0.700395
2024-05-22 13:53:25 Epoch 20: lr=5e-05
2024-05-22 13:54:35 [Epoch: 20] loss: 0.005199, mae: 0.051164, r2: 0.750282, val_loss: 0.006240, val_mae: 0.055216, val_r2: 0.700891
2024-05-22 13:54:36 Epoch 21: lr=2.5e-05
2024-05-22 13:55:46 [Epoch: 21] loss: 0.005126, mae: 0.050838, r2: 0.753514, val_loss: 0.006199, val_mae: 0.054880, val_r2: 0.702779
2024-05-22 13:55:46 Epoch 22: lr=2.5e-05
2024-05-22 13:56:56 [Epoch: 22] loss: 0.005115, mae: 0.050769, r2: 0.754076, val_loss: 0.006238, val_mae: 0.054591, val_r2: 0.700603
2024-05-22 13:56:56 Epoch 23: lr=2.5e-05
2024-05-22 13:58:06 [Epoch: 23] loss: 0.005085, mae: 0.050657, r2: 0.755473, val_loss: 0.006228, val_mae: 0.054829, val_r2: 0.701029
2024-05-22 13:58:06 Epoch 24: lr=2.5e-05
2024-05-22 13:59:17 [Epoch: 24] loss: 0.005072, mae: 0.050555, r2: 0.755986, val_loss: 0.006207, val_mae: 0.055095, val_r2: 0.701752
2024-05-22 13:59:17 Epoch 25: lr=2.5e-05
2024-05-22 14:00:27 [Epoch: 25] loss: 0.005064, mae: 0.050527, r2: 0.756333, val_loss: 0.006212, val_mae: 0.054920, val_r2: 0.701302
2024-05-22 14:00:27 Epoch 26: lr=1.25e-05
2024-05-22 14:01:37 [Epoch: 26] loss: 0.005027, mae: 0.050388, r2: 0.757904, val_loss: 0.006224, val_mae: 0.054597, val_r2: 0.701750
2024-05-22 14:01:37 Epoch 27: lr=1.25e-05
2024-05-22 14:02:48 [Epoch: 27] loss: 0.005025, mae: 0.050317, r2: 0.758308, val_loss: 0.006222, val_mae: 0.054583, val_r2: 0.701352
2024-05-22 14:02:48 Epoch 28: lr=1.25e-05
2024-05-22 14:03:59 [Epoch: 28] loss: 0.005016, mae: 0.050322, r2: 0.758457, val_loss: 0.006208, val_mae: 0.054796, val_r2: 0.701352
2024-05-22 14:03:59 Epoch 29: lr=1.25e-05
2024-05-22 14:05:09 [Epoch: 29] loss: 0.005010, mae: 0.050289, r2: 0.758919, val_loss: 0.006230, val_mae: 0.054858, val_r2: 0.700989
2024-05-22 14:05:09 Epoch 30: lr=1.25e-05
2024-05-22 14:06:19 [Epoch: 30] loss: 0.005005, mae: 0.050260, r2: 0.759168, val_loss: 0.006192, val_mae: 0.054682, val_r2: 0.702929
2024-05-22 14:06:19 Epoch 31: lr=1e-05
2024-05-22 14:07:29 [Epoch: 31] loss: 0.004987, mae: 0.050175, r2: 0.759818, val_loss: 0.006216, val_mae: 0.054870, val_r2: 0.701847
2024-05-22 14:07:29 Epoch 32: lr=1e-05
2024-05-22 14:08:40 [Epoch: 32] loss: 0.004993, mae: 0.050214, r2: 0.759506, val_loss: 0.006203, val_mae: 0.054869, val_r2: 0.701606
2024-05-22 14:08:40 Epoch 33: lr=1e-05
2024-05-22 14:09:50 [Epoch: 33] loss: 0.004977, mae: 0.050106, r2: 0.760311, val_loss: 0.006208, val_mae: 0.054713, val_r2: 0.701679
2024-05-22 14:09:50 Epoch 34: lr=1e-05
2024-05-22 14:11:01 [Epoch: 34] loss: 0.004976, mae: 0.050109, r2: 0.760307, val_loss: 0.006201, val_mae: 0.054798, val_r2: 0.702253
2024-05-22 14:11:01 Epoch 35: lr=1e-05
2024-05-22 14:12:11 [Epoch: 35] loss: 0.004960, mae: 0.050072, r2: 0.761324, val_loss: 0.006224, val_mae: 0.054828, val_r2: 0.700906
2024-05-22 14:12:11 Epoch 36: lr=1e-05
2024-05-22 14:13:22 [Epoch: 36] loss: 0.004971, mae: 0.050108, r2: 0.760480, val_loss: 0.006193, val_mae: 0.054671, val_r2: 0.703164
2024-05-22 14:13:22 Epoch 37: lr=1e-05
2024-05-22 14:14:32 [Epoch: 37] loss: 0.004951, mae: 0.050028, r2: 0.761598, val_loss: 0.006201, val_mae: 0.054431, val_r2: 0.701937
2024-05-22 14:14:32 Epoch 38: lr=1e-05
2024-05-22 14:15:42 [Epoch: 38] loss: 0.004942, mae: 0.049978, r2: 0.761965, val_loss: 0.006196, val_mae: 0.054619, val_r2: 0.702628
2024-05-22 14:15:42 Epoch 39: lr=1e-05
2024-05-22 14:16:52 [Epoch: 39] loss: 0.004939, mae: 0.049955, r2: 0.762066, val_loss: 0.006177, val_mae: 0.054587, val_r2: 0.703152
2024-05-22 14:16:52 Epoch 40: lr=1e-05
2024-05-22 14:18:02 [Epoch: 40] loss: 0.004933, mae: 0.049911, r2: 0.762583, val_loss: 0.006224, val_mae: 0.054591, val_r2: 0.701146
2024-05-22 14:18:03 Epoch 41: lr=1e-05
2024-05-22 14:19:13 [Epoch: 41] loss: 0.004927, mae: 0.049868, r2: 0.762492, val_loss: 0.006189, val_mae: 0.054641, val_r2: 0.703222
2024-05-22 14:19:13 Epoch 42: lr=1e-05
2024-05-22 14:20:23 [Epoch: 42] loss: 0.004919, mae: 0.049858, r2: 0.763074, val_loss: 0.006195, val_mae: 0.054518, val_r2: 0.702303
2024-05-22 14:20:23 Epoch 43: lr=1e-05
2024-05-22 14:21:33 [Epoch: 43] loss: 0.004921, mae: 0.049875, r2: 0.762840, val_loss: 0.006205, val_mae: 0.054754, val_r2: 0.702194
2024-05-22 14:21:33 Epoch 44: lr=1e-05
2024-05-22 14:22:43 [Epoch: 44] loss: 0.004916, mae: 0.049818, r2: 0.763078, val_loss: 0.006194, val_mae: 0.054530, val_r2: 0.702528
2024-05-22 14:22:43 Epoch 45: lr=1e-05
2024-05-22 14:23:53 [Epoch: 45] loss: 0.004908, mae: 0.049803, r2: 0.763586, val_loss: 0.006207, val_mae: 0.054711, val_r2: 0.701593
2024-05-22 14:23:53 Epoch 46: lr=1e-05
2024-05-22 14:25:03 [Epoch: 46] loss: 0.004915, mae: 0.049800, r2: 0.763174, val_loss: 0.006227, val_mae: 0.054713, val_r2: 0.701116
2024-05-22 14:25:03 Epoch 47: lr=1e-05
2024-05-22 14:26:13 [Epoch: 47] loss: 0.004896, mae: 0.049747, r2: 0.764080, val_loss: 0.006206, val_mae: 0.054731, val_r2: 0.702419
2024-05-22 14:26:13 Epoch 48: lr=1e-05
2024-05-22 14:27:23 [Epoch: 48] loss: 0.004890, mae: 0.049696, r2: 0.764541, val_loss: 0.006203, val_mae: 0.054616, val_r2: 0.702216
2024-05-22 14:27:23 Epoch 49: lr=1e-05
2024-05-22 14:28:33 [Epoch: 49] loss: 0.004887, mae: 0.049680, r2: 0.764614, val_loss: 0.006190, val_mae: 0.054642, val_r2: 0.702479
2024-05-22 14:28:33 history_length: 50
2024-05-22 14:28:33 stopping: complete
2024-05-22 14:28:33 Comparing y_true and y_pred:
2024-05-22 14:28:33   mse: 0.00784635
2024-05-22 14:28:33   mae: 0.08023947
2024-05-22 14:28:33   r2: -5.51310490
2024-05-22 14:28:33   corr: 0.20641518
