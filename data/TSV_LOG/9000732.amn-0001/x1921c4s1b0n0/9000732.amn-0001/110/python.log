2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/110', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '110', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/110/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/110', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c4s1b0n0.110.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/110/1.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/110'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x14618d7e1700>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/110/1.0.model.h5
2024-05-22 13:29:54 Between random pairs in y_val:
2024-05-22 13:29:54   mse: 0.04749105
2024-05-22 13:29:54   mae: 0.15966867
2024-05-22 13:29:54   r2: -0.99278224
2024-05-22 13:29:54   corr: 0.00360888
2024-05-22 13:29:54 Data points per epoch: train = 469608, val = 117403, test = 698
2024-05-22 13:29:54 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-22 13:29:54 Epoch 0: lr=0.001
2024-05-22 13:31:07 [Epoch: 0] loss: 0.024703, mae: 0.079333, r2: -0.169690, val_loss: 0.008834, val_mae: 0.070921, val_r2: 0.580131
2024-05-22 13:31:08 Epoch 1: lr=0.00082
2024-05-22 13:32:19 [Epoch: 1] loss: 0.008029, mae: 0.064041, r2: 0.619305, val_loss: 0.007753, val_mae: 0.063193, val_r2: 0.631488
2024-05-22 13:32:19 Epoch 2: lr=0.00064
2024-05-22 13:33:31 [Epoch: 2] loss: 0.007335, mae: 0.060910, r2: 0.650895, val_loss: 0.007254, val_mae: 0.059937, val_r2: 0.655078
2024-05-22 13:33:31 Epoch 3: lr=0.00046
2024-05-22 13:34:42 [Epoch: 3] loss: 0.006879, mae: 0.058796, r2: 0.672184, val_loss: 0.006972, val_mae: 0.058397, val_r2: 0.664451
2024-05-22 13:34:43 Epoch 4: lr=0.00028
2024-05-22 13:35:55 [Epoch: 4] loss: 0.006469, mae: 0.056922, r2: 0.690936, val_loss: 0.006566, val_mae: 0.057056, val_r2: 0.686920
2024-05-22 13:35:55 Epoch 5: lr=0.0001
2024-05-22 13:37:07 [Epoch: 5] loss: 0.006152, mae: 0.055481, r2: 0.705322, val_loss: 0.006421, val_mae: 0.056293, val_r2: 0.692243
2024-05-22 13:37:07 Epoch 6: lr=0.0001
2024-05-22 13:38:18 [Epoch: 6] loss: 0.006032, mae: 0.054948, r2: 0.710862, val_loss: 0.006391, val_mae: 0.057204, val_r2: 0.692279
2024-05-22 13:38:18 Epoch 7: lr=0.0001
2024-05-22 13:39:30 [Epoch: 7] loss: 0.005964, mae: 0.054633, r2: 0.714010, val_loss: 0.006339, val_mae: 0.056589, val_r2: 0.695424
2024-05-22 13:39:30 Epoch 8: lr=0.0001
2024-05-22 13:40:41 [Epoch: 8] loss: 0.005889, mae: 0.054289, r2: 0.717254, val_loss: 0.006317, val_mae: 0.055795, val_r2: 0.696780
2024-05-22 13:40:41 Epoch 9: lr=0.0001
2024-05-22 13:41:53 [Epoch: 9] loss: 0.005834, mae: 0.054053, r2: 0.719995, val_loss: 0.006286, val_mae: 0.056144, val_r2: 0.698520
2024-05-22 13:41:53 Epoch 10: lr=0.0001
2024-05-22 13:43:04 [Epoch: 10] loss: 0.005770, mae: 0.053770, r2: 0.722940, val_loss: 0.006244, val_mae: 0.055595, val_r2: 0.700918
2024-05-22 13:43:04 Epoch 11: lr=0.0001
2024-05-22 13:44:16 [Epoch: 11] loss: 0.005707, mae: 0.053512, r2: 0.725929, val_loss: 0.006230, val_mae: 0.055719, val_r2: 0.700442
2024-05-22 13:44:16 Epoch 12: lr=0.0001
2024-05-22 13:45:28 [Epoch: 12] loss: 0.005648, mae: 0.053213, r2: 0.728281, val_loss: 0.006184, val_mae: 0.055400, val_r2: 0.704377
2024-05-22 13:45:28 Epoch 13: lr=0.0001
2024-05-22 13:46:40 [Epoch: 13] loss: 0.005586, mae: 0.052945, r2: 0.731468, val_loss: 0.006197, val_mae: 0.055084, val_r2: 0.702328
2024-05-22 13:46:40 Epoch 14: lr=0.0001
2024-05-22 13:47:52 [Epoch: 14] loss: 0.005540, mae: 0.052679, r2: 0.733907, val_loss: 0.006167, val_mae: 0.055719, val_r2: 0.703394
2024-05-22 13:47:52 Epoch 15: lr=0.0001
2024-05-22 13:49:04 [Epoch: 15] loss: 0.005492, mae: 0.052498, r2: 0.735982, val_loss: 0.006173, val_mae: 0.055157, val_r2: 0.704772
2024-05-22 13:49:04 Epoch 16: lr=0.0001
2024-05-22 13:50:16 [Epoch: 16] loss: 0.005447, mae: 0.052265, r2: 0.738099, val_loss: 0.006131, val_mae: 0.055316, val_r2: 0.705388
2024-05-22 13:50:16 Epoch 17: lr=0.0001
2024-05-22 13:51:28 [Epoch: 17] loss: 0.005395, mae: 0.052016, r2: 0.740576, val_loss: 0.006124, val_mae: 0.054904, val_r2: 0.707216
2024-05-22 13:51:28 Epoch 18: lr=5e-05
2024-05-22 13:52:39 [Epoch: 18] loss: 0.005279, mae: 0.051475, r2: 0.745888, val_loss: 0.006087, val_mae: 0.054670, val_r2: 0.708150
2024-05-22 13:52:39 Epoch 19: lr=5e-05
2024-05-22 13:53:51 [Epoch: 19] loss: 0.005240, mae: 0.051327, r2: 0.747596, val_loss: 0.006078, val_mae: 0.054574, val_r2: 0.708839
2024-05-22 13:53:51 Epoch 20: lr=5e-05
2024-05-22 13:55:02 [Epoch: 20] loss: 0.005205, mae: 0.051123, r2: 0.749277, val_loss: 0.006087, val_mae: 0.054798, val_r2: 0.708424
2024-05-22 13:55:02 Epoch 21: lr=5e-05
2024-05-22 13:56:14 [Epoch: 21] loss: 0.005184, mae: 0.051022, r2: 0.750190, val_loss: 0.006082, val_mae: 0.055006, val_r2: 0.708571
2024-05-22 13:56:14 Epoch 22: lr=5e-05
2024-05-22 13:57:25 [Epoch: 22] loss: 0.005154, mae: 0.050891, r2: 0.751601, val_loss: 0.006065, val_mae: 0.054789, val_r2: 0.709762
2024-05-22 13:57:25 Epoch 23: lr=5e-05
2024-05-22 13:58:37 [Epoch: 23] loss: 0.005124, mae: 0.050742, r2: 0.753317, val_loss: 0.006084, val_mae: 0.054550, val_r2: 0.707346
2024-05-22 13:58:37 Epoch 24: lr=5e-05
2024-05-22 13:59:49 [Epoch: 24] loss: 0.005106, mae: 0.050643, r2: 0.753863, val_loss: 0.006073, val_mae: 0.054472, val_r2: 0.707982
2024-05-22 13:59:49 Epoch 25: lr=2.5e-05
2024-05-22 14:01:01 [Epoch: 25] loss: 0.005048, mae: 0.050382, r2: 0.756470, val_loss: 0.006070, val_mae: 0.054523, val_r2: 0.709069
2024-05-22 14:01:01 Epoch 26: lr=2.5e-05
2024-05-22 14:02:13 [Epoch: 26] loss: 0.005017, mae: 0.050248, r2: 0.758045, val_loss: 0.006068, val_mae: 0.054394, val_r2: 0.709082
2024-05-22 14:02:13 Epoch 27: lr=2.5e-05
2024-05-22 14:03:25 [Epoch: 27] loss: 0.005010, mae: 0.050202, r2: 0.758209, val_loss: 0.006097, val_mae: 0.054476, val_r2: 0.707665
2024-05-22 14:03:25 Epoch 28: lr=2.5e-05
2024-05-22 14:04:37 [Epoch: 28] loss: 0.004997, mae: 0.050166, r2: 0.758998, val_loss: 0.006079, val_mae: 0.054423, val_r2: 0.709018
2024-05-22 14:04:37 Epoch 29: lr=2.5e-05
2024-05-22 14:05:48 [Epoch: 29] loss: 0.004980, mae: 0.050065, r2: 0.759501, val_loss: 0.006102, val_mae: 0.054495, val_r2: 0.707669
2024-05-22 14:05:49 Epoch 30: lr=1.25e-05
2024-05-22 14:07:00 [Epoch: 30] loss: 0.004953, mae: 0.049930, r2: 0.761059, val_loss: 0.006060, val_mae: 0.054508, val_r2: 0.709747
2024-05-22 14:07:00 Epoch 31: lr=1.25e-05
2024-05-22 14:08:12 [Epoch: 31] loss: 0.004935, mae: 0.049878, r2: 0.762060, val_loss: 0.006066, val_mae: 0.054585, val_r2: 0.708557
2024-05-22 14:08:12 Epoch 32: lr=1.25e-05
2024-05-22 14:09:23 [Epoch: 32] loss: 0.004933, mae: 0.049801, r2: 0.761865, val_loss: 0.006068, val_mae: 0.054421, val_r2: 0.708641
2024-05-22 14:09:24 Epoch 33: lr=1.25e-05
2024-05-22 14:10:35 [Epoch: 33] loss: 0.004923, mae: 0.049799, r2: 0.762435, val_loss: 0.006057, val_mae: 0.054453, val_r2: 0.709787
2024-05-22 14:10:35 Epoch 34: lr=1.25e-05
2024-05-22 14:11:47 [Epoch: 34] loss: 0.004917, mae: 0.049753, r2: 0.762672, val_loss: 0.006072, val_mae: 0.054586, val_r2: 0.708377
2024-05-22 14:11:47 Epoch 35: lr=1e-05
2024-05-22 14:12:59 [Epoch: 35] loss: 0.004907, mae: 0.049707, r2: 0.763196, val_loss: 0.006046, val_mae: 0.054367, val_r2: 0.710382
2024-05-22 14:12:59 Epoch 36: lr=1e-05
2024-05-22 14:14:11 [Epoch: 36] loss: 0.004894, mae: 0.049647, r2: 0.763808, val_loss: 0.006071, val_mae: 0.054468, val_r2: 0.709093
2024-05-22 14:14:11 Epoch 37: lr=1e-05
2024-05-22 14:15:22 [Epoch: 37] loss: 0.004893, mae: 0.049693, r2: 0.763771, val_loss: 0.006078, val_mae: 0.054298, val_r2: 0.708702
2024-05-22 14:15:23 Epoch 38: lr=1e-05
2024-05-22 14:16:35 [Epoch: 38] loss: 0.004893, mae: 0.049649, r2: 0.763742, val_loss: 0.006051, val_mae: 0.054203, val_r2: 0.710223
2024-05-22 14:16:35 Epoch 39: lr=1e-05
2024-05-22 14:17:46 [Epoch: 39] loss: 0.004895, mae: 0.049635, r2: 0.763622, val_loss: 0.006054, val_mae: 0.054230, val_r2: 0.710186
2024-05-22 14:17:47 Epoch 40: lr=1e-05
2024-05-22 14:18:58 [Epoch: 40] loss: 0.004875, mae: 0.049553, r2: 0.764525, val_loss: 0.006070, val_mae: 0.054467, val_r2: 0.708515
2024-05-22 14:18:58 Epoch 41: lr=1e-05
2024-05-22 14:20:10 [Epoch: 41] loss: 0.004868, mae: 0.049509, r2: 0.764665, val_loss: 0.006036, val_mae: 0.054293, val_r2: 0.710346
2024-05-22 14:20:10 Epoch 42: lr=1e-05
2024-05-22 14:21:22 [Epoch: 42] loss: 0.004863, mae: 0.049521, r2: 0.765239, val_loss: 0.006051, val_mae: 0.054374, val_r2: 0.710014
2024-05-22 14:21:22 Epoch 43: lr=1e-05
2024-05-22 14:22:34 [Epoch: 43] loss: 0.004869, mae: 0.049537, r2: 0.764893, val_loss: 0.006058, val_mae: 0.054459, val_r2: 0.710020
2024-05-22 14:22:34 Epoch 44: lr=1e-05
2024-05-22 14:23:45 [Epoch: 44] loss: 0.004858, mae: 0.049468, r2: 0.765367, val_loss: 0.006075, val_mae: 0.054394, val_r2: 0.709009
2024-05-22 14:23:45 Epoch 45: lr=1e-05
2024-05-22 14:24:57 [Epoch: 45] loss: 0.004852, mae: 0.049436, r2: 0.765762, val_loss: 0.006063, val_mae: 0.054316, val_r2: 0.709470
2024-05-22 14:24:57 Epoch 46: lr=1e-05
2024-05-22 14:26:09 [Epoch: 46] loss: 0.004847, mae: 0.049386, r2: 0.766198, val_loss: 0.006059, val_mae: 0.054238, val_r2: 0.709930
2024-05-22 14:26:09 Epoch 47: lr=1e-05
2024-05-22 14:27:20 [Epoch: 47] loss: 0.004846, mae: 0.049407, r2: 0.766020, val_loss: 0.006058, val_mae: 0.054351, val_r2: 0.709260
2024-05-22 14:27:21 Epoch 48: lr=1e-05
2024-05-22 14:28:32 [Epoch: 48] loss: 0.004833, mae: 0.049372, r2: 0.766415, val_loss: 0.006084, val_mae: 0.054594, val_r2: 0.708111
2024-05-22 14:28:33 Epoch 49: lr=1e-05
2024-05-22 14:29:44 [Epoch: 49] loss: 0.004841, mae: 0.049394, r2: 0.766433, val_loss: 0.006068, val_mae: 0.054185, val_r2: 0.709144
2024-05-22 14:29:44 history_length: 50
2024-05-22 14:29:44 stopping: complete
2024-05-22 14:29:44 Comparing y_true and y_pred:
2024-05-22 14:29:44   mse: 0.00507561
2024-05-22 14:29:44   mae: 0.06066143
2024-05-22 14:29:44   r2: -2.03811501
2024-05-22 14:29:44   corr: 0.16457583
