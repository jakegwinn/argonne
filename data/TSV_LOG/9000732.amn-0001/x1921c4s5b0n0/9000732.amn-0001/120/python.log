2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/120', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '120', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/120/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/120', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c4s5b0n0.120.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/120/0.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/120'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:37 Combined model:
2024-05-22 13:29:37 Model: "model"
2024-05-22 13:29:37 __________________________________________________________________________________________________
2024-05-22 13:29:37  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:37 ==================================================================================================
2024-05-22 13:29:37  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:37  yer)                                                                                             
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:37  nputLayer)                                                                                       
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:37  al)                                                                ]']                           
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:37                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:37  nentDropout)                                                                                     
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:37  nentDropout)                                                                                     
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:37  nentDropout)                                                                                     
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:37  nentDropout)                                                                                     
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:37  anentDropout)                                                                                    
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:37                                                                                                   
2024-05-22 13:29:37 ==================================================================================================
2024-05-22 13:29:37 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:37 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:37 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:37 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x1532443ccd60>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:39 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/120/0.0.model.h5
2024-05-22 13:29:56 Between random pairs in y_val:
2024-05-22 13:29:56   mse: 0.04780304
2024-05-22 13:29:56   mae: 0.16036976
2024-05-22 13:29:56   r2: -0.99547514
2024-05-22 13:29:56   corr: 0.00226243
2024-05-22 13:29:56 Data points per epoch: train = 469613, val = 117404, test = 692
2024-05-22 13:29:56 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-22 13:29:56 Epoch 0: lr=0.001
2024-05-22 13:31:09 [Epoch: 0] loss: 0.023652, mae: 0.079010, r2: -0.272032, val_loss: 0.008412, val_mae: 0.066111, val_r2: 0.603199
2024-05-22 13:31:10 Epoch 1: lr=0.00082
2024-05-22 13:32:22 [Epoch: 1] loss: 0.007986, mae: 0.063917, r2: 0.619559, val_loss: 0.007741, val_mae: 0.063418, val_r2: 0.629800
2024-05-22 13:32:22 Epoch 2: lr=0.00064
2024-05-22 13:33:35 [Epoch: 2] loss: 0.007346, mae: 0.060969, r2: 0.649369, val_loss: 0.007297, val_mae: 0.060134, val_r2: 0.650152
2024-05-22 13:33:35 Epoch 3: lr=0.00046
2024-05-22 13:34:47 [Epoch: 3] loss: 0.006844, mae: 0.058671, r2: 0.672476, val_loss: 0.006945, val_mae: 0.060049, val_r2: 0.672282
2024-05-22 13:34:47 Epoch 4: lr=0.00028
2024-05-22 13:35:59 [Epoch: 4] loss: 0.006448, mae: 0.056856, r2: 0.690711, val_loss: 0.006677, val_mae: 0.057201, val_r2: 0.681871
2024-05-22 13:36:00 Epoch 5: lr=0.0001
2024-05-22 13:37:12 [Epoch: 5] loss: 0.006123, mae: 0.055336, r2: 0.705866, val_loss: 0.006479, val_mae: 0.056593, val_r2: 0.691687
2024-05-22 13:37:12 Epoch 6: lr=0.0001
2024-05-22 13:38:24 [Epoch: 6] loss: 0.006013, mae: 0.054863, r2: 0.710750, val_loss: 0.006445, val_mae: 0.056616, val_r2: 0.692308
2024-05-22 13:38:25 Epoch 7: lr=0.0001
2024-05-22 13:39:37 [Epoch: 7] loss: 0.005939, mae: 0.054488, r2: 0.713986, val_loss: 0.006426, val_mae: 0.056383, val_r2: 0.695105
2024-05-22 13:39:37 Epoch 8: lr=0.0001
2024-05-22 13:40:49 [Epoch: 8] loss: 0.005875, mae: 0.054228, r2: 0.717183, val_loss: 0.006395, val_mae: 0.056359, val_r2: 0.694448
2024-05-22 13:40:49 Epoch 9: lr=0.0001
2024-05-22 13:42:02 [Epoch: 9] loss: 0.005805, mae: 0.053901, r2: 0.720520, val_loss: 0.006424, val_mae: 0.056946, val_r2: 0.691959
2024-05-22 13:42:02 Epoch 10: lr=0.0001
2024-05-22 13:43:14 [Epoch: 10] loss: 0.005753, mae: 0.053674, r2: 0.723026, val_loss: 0.006316, val_mae: 0.055877, val_r2: 0.697137
2024-05-22 13:43:14 Epoch 11: lr=0.0001
2024-05-22 13:44:27 [Epoch: 11] loss: 0.005691, mae: 0.053372, r2: 0.725963, val_loss: 0.006288, val_mae: 0.056026, val_r2: 0.699813
2024-05-22 13:44:27 Epoch 12: lr=0.0001
2024-05-22 13:45:39 [Epoch: 12] loss: 0.005622, mae: 0.053092, r2: 0.729034, val_loss: 0.006259, val_mae: 0.055656, val_r2: 0.701281
2024-05-22 13:45:39 Epoch 13: lr=0.0001
2024-05-22 13:46:52 [Epoch: 13] loss: 0.005570, mae: 0.052814, r2: 0.731642, val_loss: 0.006343, val_mae: 0.057310, val_r2: 0.697472
2024-05-22 13:46:52 Epoch 14: lr=0.0001
2024-05-22 13:48:04 [Epoch: 14] loss: 0.005526, mae: 0.052631, r2: 0.733540, val_loss: 0.006213, val_mae: 0.055593, val_r2: 0.703378
2024-05-22 13:48:04 Epoch 15: lr=0.0001
2024-05-22 13:49:17 [Epoch: 15] loss: 0.005470, mae: 0.052403, r2: 0.736313, val_loss: 0.006244, val_mae: 0.055775, val_r2: 0.701312
2024-05-22 13:49:17 Epoch 16: lr=0.0001
2024-05-22 13:50:29 [Epoch: 16] loss: 0.005424, mae: 0.052139, r2: 0.738514, val_loss: 0.006207, val_mae: 0.055055, val_r2: 0.703661
2024-05-22 13:50:29 Epoch 17: lr=0.0001
2024-05-22 13:51:42 [Epoch: 17] loss: 0.005360, mae: 0.051881, r2: 0.741313, val_loss: 0.006218, val_mae: 0.055579, val_r2: 0.702807
2024-05-22 13:51:42 Epoch 18: lr=0.0001
2024-05-22 13:52:54 [Epoch: 18] loss: 0.005325, mae: 0.051670, r2: 0.743051, val_loss: 0.006197, val_mae: 0.055242, val_r2: 0.703318
2024-05-22 13:52:54 Epoch 19: lr=0.0001
2024-05-22 13:54:07 [Epoch: 19] loss: 0.005268, mae: 0.051437, r2: 0.745633, val_loss: 0.006207, val_mae: 0.054894, val_r2: 0.702090
2024-05-22 13:54:07 Epoch 20: lr=5e-05
2024-05-22 13:55:19 [Epoch: 20] loss: 0.005156, mae: 0.050890, r2: 0.751011, val_loss: 0.006193, val_mae: 0.055309, val_r2: 0.703247
2024-05-22 13:55:19 Epoch 21: lr=5e-05
2024-05-22 13:56:32 [Epoch: 21] loss: 0.005099, mae: 0.050631, r2: 0.753646, val_loss: 0.006170, val_mae: 0.054852, val_r2: 0.703724
2024-05-22 13:56:32 Epoch 22: lr=5e-05
2024-05-22 13:57:44 [Epoch: 22] loss: 0.005080, mae: 0.050529, r2: 0.754387, val_loss: 0.006174, val_mae: 0.054930, val_r2: 0.705002
2024-05-22 13:57:44 Epoch 23: lr=5e-05
2024-05-22 13:58:57 [Epoch: 23] loss: 0.005056, mae: 0.050419, r2: 0.755749, val_loss: 0.006171, val_mae: 0.055297, val_r2: 0.704673
2024-05-22 13:58:57 Epoch 24: lr=5e-05
2024-05-22 14:00:09 [Epoch: 24] loss: 0.005038, mae: 0.050355, r2: 0.756565, val_loss: 0.006188, val_mae: 0.055120, val_r2: 0.703894
2024-05-22 14:00:09 Epoch 25: lr=2.5e-05
2024-05-22 14:01:22 [Epoch: 25] loss: 0.004970, mae: 0.050011, r2: 0.759710, val_loss: 0.006188, val_mae: 0.054699, val_r2: 0.704643
2024-05-22 14:01:22 Epoch 26: lr=2.5e-05
2024-05-22 14:02:34 [Epoch: 26] loss: 0.004949, mae: 0.049931, r2: 0.760817, val_loss: 0.006181, val_mae: 0.054885, val_r2: 0.704732
2024-05-22 14:02:34 Epoch 27: lr=2.5e-05
2024-05-22 14:03:47 [Epoch: 27] loss: 0.004941, mae: 0.049868, r2: 0.761213, val_loss: 0.006146, val_mae: 0.054778, val_r2: 0.706065
2024-05-22 14:03:47 Epoch 28: lr=2.5e-05
2024-05-22 14:04:59 [Epoch: 28] loss: 0.004922, mae: 0.049768, r2: 0.762100, val_loss: 0.006150, val_mae: 0.054704, val_r2: 0.705938
2024-05-22 14:04:59 Epoch 29: lr=2.5e-05
2024-05-22 14:06:12 [Epoch: 29] loss: 0.004914, mae: 0.049727, r2: 0.762036, val_loss: 0.006158, val_mae: 0.054866, val_r2: 0.705812
2024-05-22 14:06:12 Epoch 30: lr=1.25e-05
2024-05-22 14:07:24 [Epoch: 30] loss: 0.004886, mae: 0.049583, r2: 0.763659, val_loss: 0.006165, val_mae: 0.054703, val_r2: 0.705695
2024-05-22 14:07:24 Epoch 31: lr=1.25e-05
2024-05-22 14:08:37 [Epoch: 31] loss: 0.004870, mae: 0.049539, r2: 0.764359, val_loss: 0.006144, val_mae: 0.054527, val_r2: 0.706584
2024-05-22 14:08:37 Epoch 32: lr=1.25e-05
2024-05-22 14:09:49 [Epoch: 32] loss: 0.004864, mae: 0.049501, r2: 0.764863, val_loss: 0.006145, val_mae: 0.054714, val_r2: 0.706525
2024-05-22 14:09:49 Epoch 33: lr=1.25e-05
2024-05-22 14:11:01 [Epoch: 33] loss: 0.004848, mae: 0.049407, r2: 0.765485, val_loss: 0.006189, val_mae: 0.054764, val_r2: 0.704046
2024-05-22 14:11:01 Epoch 34: lr=1.25e-05
2024-05-22 14:12:13 [Epoch: 34] loss: 0.004841, mae: 0.049397, r2: 0.765699, val_loss: 0.006132, val_mae: 0.054778, val_r2: 0.706464
2024-05-22 14:12:14 Epoch 35: lr=1e-05
2024-05-22 14:13:26 [Epoch: 35] loss: 0.004839, mae: 0.049384, r2: 0.765749, val_loss: 0.006152, val_mae: 0.054805, val_r2: 0.706246
2024-05-22 14:13:26 Epoch 36: lr=1e-05
2024-05-22 14:14:38 [Epoch: 36] loss: 0.004824, mae: 0.049351, r2: 0.766712, val_loss: 0.006166, val_mae: 0.054721, val_r2: 0.704788
2024-05-22 14:14:38 Epoch 37: lr=1e-05
2024-05-22 14:15:50 [Epoch: 37] loss: 0.004816, mae: 0.049294, r2: 0.766898, val_loss: 0.006172, val_mae: 0.054778, val_r2: 0.705390
2024-05-22 14:15:50 Epoch 38: lr=1e-05
2024-05-22 14:17:02 [Epoch: 38] loss: 0.004813, mae: 0.049293, r2: 0.766906, val_loss: 0.006132, val_mae: 0.054504, val_r2: 0.706774
2024-05-22 14:17:02 Epoch 39: lr=1e-05
2024-05-22 14:18:14 [Epoch: 39] loss: 0.004817, mae: 0.049246, r2: 0.767085, val_loss: 0.006147, val_mae: 0.054773, val_r2: 0.706001
2024-05-22 14:18:14 Epoch 40: lr=1e-05
2024-05-22 14:19:25 [Epoch: 40] loss: 0.004796, mae: 0.049187, r2: 0.767824, val_loss: 0.006170, val_mae: 0.054540, val_r2: 0.705645
2024-05-22 14:19:25 Epoch 41: lr=1e-05
2024-05-22 14:20:37 [Epoch: 41] loss: 0.004796, mae: 0.049178, r2: 0.767754, val_loss: 0.006163, val_mae: 0.054539, val_r2: 0.705784
2024-05-22 14:20:37 Epoch 42: lr=1e-05
2024-05-22 14:21:48 [Epoch: 42] loss: 0.004797, mae: 0.049138, r2: 0.767901, val_loss: 0.006163, val_mae: 0.054731, val_r2: 0.705580
2024-05-22 14:21:48 Epoch 43: lr=1e-05
2024-05-22 14:23:00 [Epoch: 43] loss: 0.004786, mae: 0.049126, r2: 0.768444, val_loss: 0.006148, val_mae: 0.054478, val_r2: 0.706340
2024-05-22 14:23:00 Epoch 44: lr=1e-05
2024-05-22 14:24:11 [Epoch: 44] loss: 0.004799, mae: 0.049205, r2: 0.767667, val_loss: 0.006178, val_mae: 0.054686, val_r2: 0.704233
2024-05-22 14:24:11 Epoch 45: lr=1e-05
2024-05-22 14:25:22 [Epoch: 45] loss: 0.004782, mae: 0.049135, r2: 0.768417, val_loss: 0.006160, val_mae: 0.054702, val_r2: 0.706249
2024-05-22 14:25:23 Epoch 46: lr=1e-05
2024-05-22 14:26:34 [Epoch: 46] loss: 0.004783, mae: 0.049117, r2: 0.768283, val_loss: 0.006149, val_mae: 0.054676, val_r2: 0.706398
2024-05-22 14:26:34 Epoch 47: lr=1e-05
2024-05-22 14:27:45 [Epoch: 47] loss: 0.004775, mae: 0.049050, r2: 0.768785, val_loss: 0.006167, val_mae: 0.054730, val_r2: 0.705365
2024-05-22 14:27:45 Epoch 48: lr=1e-05
2024-05-22 14:28:56 [Epoch: 48] loss: 0.004762, mae: 0.049000, r2: 0.769452, val_loss: 0.006181, val_mae: 0.054711, val_r2: 0.704821
2024-05-22 14:28:56 history_length: 49
2024-05-22 14:28:56 stopping: early
2024-05-22 14:28:56 Comparing y_true and y_pred:
2024-05-22 14:28:56   mse: 0.02933227
2024-05-22 14:28:56   mae: 0.15270989
2024-05-22 14:28:56   r2: -17.65484966
2024-05-22 14:28:56   corr: 0.15528816
