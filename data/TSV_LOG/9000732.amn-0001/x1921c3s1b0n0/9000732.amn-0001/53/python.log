2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/53', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '53', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/53/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/53', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c3s1b0n0.53.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/53/2.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/53'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x1545721cfa00>
2024-05-22 13:29:39 COMPILE
2024-05-22 13:29:39 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/53/2.1.model.h5
2024-05-22 13:29:55 Between random pairs in y_val:
2024-05-22 13:29:55   mse: 0.04778970
2024-05-22 13:29:55   mae: 0.15995010
2024-05-22 13:29:55   r2: -0.99997967
2024-05-22 13:29:55   corr: 0.00001017
2024-05-22 13:29:55 Data points per epoch: train = 469285, val = 117322, test = 1102
2024-05-22 13:29:55 Steps per epoch: train = 14665, val = 3666, test = 34
2024-05-22 13:29:55 Epoch 0: lr=0.001
2024-05-22 13:31:09 [Epoch: 0] loss: 0.025278, mae: 0.079427, r2: -0.099775, val_loss: 0.008539, val_mae: 0.065882, val_r2: 0.599947
2024-05-22 13:31:10 Epoch 1: lr=0.00082
2024-05-22 13:32:23 [Epoch: 1] loss: 0.008016, mae: 0.064020, r2: 0.618685, val_loss: 0.007653, val_mae: 0.062395, val_r2: 0.632743
2024-05-22 13:32:23 Epoch 2: lr=0.00064
2024-05-22 13:33:35 [Epoch: 2] loss: 0.007325, mae: 0.060947, r2: 0.650444, val_loss: 0.007204, val_mae: 0.060965, val_r2: 0.659037
2024-05-22 13:33:35 Epoch 3: lr=0.00046
2024-05-22 13:34:49 [Epoch: 3] loss: 0.006842, mae: 0.058783, r2: 0.672617, val_loss: 0.006872, val_mae: 0.058746, val_r2: 0.671779
2024-05-22 13:34:49 Epoch 4: lr=0.00028
2024-05-22 13:36:02 [Epoch: 4] loss: 0.006449, mae: 0.056930, r2: 0.690581, val_loss: 0.006679, val_mae: 0.057960, val_r2: 0.684229
2024-05-22 13:36:02 Epoch 5: lr=0.0001
2024-05-22 13:37:14 [Epoch: 5] loss: 0.006118, mae: 0.055381, r2: 0.706058, val_loss: 0.006460, val_mae: 0.056559, val_r2: 0.691965
2024-05-22 13:37:14 Epoch 6: lr=0.0001
2024-05-22 13:38:27 [Epoch: 6] loss: 0.006016, mae: 0.054871, r2: 0.710688, val_loss: 0.006443, val_mae: 0.056256, val_r2: 0.693466
2024-05-22 13:38:27 Epoch 7: lr=0.0001
2024-05-22 13:39:41 [Epoch: 7] loss: 0.005938, mae: 0.054542, r2: 0.714378, val_loss: 0.006412, val_mae: 0.055950, val_r2: 0.693308
2024-05-22 13:39:41 Epoch 8: lr=0.0001
2024-05-22 13:40:54 [Epoch: 8] loss: 0.005872, mae: 0.054271, r2: 0.717521, val_loss: 0.006376, val_mae: 0.055637, val_r2: 0.695694
2024-05-22 13:40:54 Epoch 9: lr=0.0001
2024-05-22 13:42:07 [Epoch: 9] loss: 0.005806, mae: 0.053956, r2: 0.720266, val_loss: 0.006361, val_mae: 0.056631, val_r2: 0.696816
2024-05-22 13:42:07 Epoch 10: lr=0.0001
2024-05-22 13:43:21 [Epoch: 10] loss: 0.005741, mae: 0.053685, r2: 0.723360, val_loss: 0.006325, val_mae: 0.056182, val_r2: 0.698450
2024-05-22 13:43:21 Epoch 11: lr=0.0001
2024-05-22 13:44:34 [Epoch: 11] loss: 0.005686, mae: 0.053402, r2: 0.726146, val_loss: 0.006292, val_mae: 0.055278, val_r2: 0.701660
2024-05-22 13:44:34 Epoch 12: lr=0.0001
2024-05-22 13:45:47 [Epoch: 12] loss: 0.005629, mae: 0.053124, r2: 0.728786, val_loss: 0.006271, val_mae: 0.055257, val_r2: 0.701282
2024-05-22 13:45:47 Epoch 13: lr=0.0001
2024-05-22 13:47:00 [Epoch: 13] loss: 0.005569, mae: 0.052863, r2: 0.731614, val_loss: 0.006252, val_mae: 0.055012, val_r2: 0.702850
2024-05-22 13:47:00 Epoch 14: lr=0.0001
2024-05-22 13:48:13 [Epoch: 14] loss: 0.005494, mae: 0.052540, r2: 0.734958, val_loss: 0.006238, val_mae: 0.054872, val_r2: 0.703347
2024-05-22 13:48:13 Epoch 15: lr=0.0001
2024-05-22 13:49:26 [Epoch: 15] loss: 0.005451, mae: 0.052355, r2: 0.737192, val_loss: 0.006209, val_mae: 0.055025, val_r2: 0.703099
2024-05-22 13:49:26 Epoch 16: lr=0.0001
2024-05-22 13:50:40 [Epoch: 16] loss: 0.005411, mae: 0.052133, r2: 0.739104, val_loss: 0.006205, val_mae: 0.055607, val_r2: 0.704093
2024-05-22 13:50:40 Epoch 17: lr=0.0001
2024-05-22 13:51:53 [Epoch: 17] loss: 0.005350, mae: 0.051916, r2: 0.741851, val_loss: 0.006201, val_mae: 0.054792, val_r2: 0.704460
2024-05-22 13:51:53 Epoch 18: lr=0.0001
2024-05-22 13:53:07 [Epoch: 18] loss: 0.005303, mae: 0.051633, r2: 0.743984, val_loss: 0.006179, val_mae: 0.054602, val_r2: 0.705523
2024-05-22 13:53:07 Epoch 19: lr=0.0001
2024-05-22 13:54:20 [Epoch: 19] loss: 0.005263, mae: 0.051438, r2: 0.746056, val_loss: 0.006168, val_mae: 0.054809, val_r2: 0.706566
2024-05-22 13:54:20 Epoch 20: lr=0.0001
2024-05-22 13:55:33 [Epoch: 20] loss: 0.005213, mae: 0.051211, r2: 0.748215, val_loss: 0.006171, val_mae: 0.054699, val_r2: 0.705954
2024-05-22 13:55:33 Epoch 21: lr=5e-05
2024-05-22 13:56:46 [Epoch: 21] loss: 0.005088, mae: 0.050624, r2: 0.753803, val_loss: 0.006146, val_mae: 0.054858, val_r2: 0.707284
2024-05-22 13:56:46 Epoch 22: lr=5e-05
2024-05-22 13:58:00 [Epoch: 22] loss: 0.005062, mae: 0.050487, r2: 0.755241, val_loss: 0.006150, val_mae: 0.055107, val_r2: 0.706220
2024-05-22 13:58:00 Epoch 23: lr=5e-05
2024-05-22 13:59:12 [Epoch: 23] loss: 0.005023, mae: 0.050318, r2: 0.757039, val_loss: 0.006153, val_mae: 0.055127, val_r2: 0.705937
2024-05-22 13:59:13 Epoch 24: lr=5e-05
2024-05-22 14:00:26 [Epoch: 24] loss: 0.004992, mae: 0.050158, r2: 0.758591, val_loss: 0.006132, val_mae: 0.054361, val_r2: 0.707016
2024-05-22 14:00:26 Epoch 25: lr=5e-05
2024-05-22 14:01:39 [Epoch: 25] loss: 0.004973, mae: 0.050079, r2: 0.759502, val_loss: 0.006136, val_mae: 0.054497, val_r2: 0.706490
2024-05-22 14:01:39 Epoch 26: lr=2.5e-05
2024-05-22 14:02:52 [Epoch: 26] loss: 0.004932, mae: 0.049878, r2: 0.761317, val_loss: 0.006109, val_mae: 0.054444, val_r2: 0.708520
2024-05-22 14:02:52 Epoch 27: lr=2.5e-05
2024-05-22 14:04:06 [Epoch: 27] loss: 0.004892, mae: 0.049633, r2: 0.763315, val_loss: 0.006105, val_mae: 0.054428, val_r2: 0.708903
2024-05-22 14:04:06 Epoch 28: lr=2.5e-05
2024-05-22 14:05:19 [Epoch: 28] loss: 0.004876, mae: 0.049571, r2: 0.764146, val_loss: 0.006104, val_mae: 0.054187, val_r2: 0.709182
2024-05-22 14:05:19 Epoch 29: lr=2.5e-05
2024-05-22 14:06:32 [Epoch: 29] loss: 0.004866, mae: 0.049555, r2: 0.764457, val_loss: 0.006104, val_mae: 0.054319, val_r2: 0.710265
2024-05-22 14:06:32 Epoch 30: lr=2.5e-05
2024-05-22 14:07:45 [Epoch: 30] loss: 0.004854, mae: 0.049498, r2: 0.764840, val_loss: 0.006122, val_mae: 0.054337, val_r2: 0.708119
2024-05-22 14:07:45 Epoch 31: lr=2.5e-05
2024-05-22 14:08:58 [Epoch: 31] loss: 0.004840, mae: 0.049451, r2: 0.765564, val_loss: 0.006131, val_mae: 0.054702, val_r2: 0.707325
2024-05-22 14:08:58 Epoch 32: lr=1.25e-05
2024-05-22 14:10:11 [Epoch: 32] loss: 0.004818, mae: 0.049323, r2: 0.766517, val_loss: 0.006130, val_mae: 0.054278, val_r2: 0.707805
2024-05-22 14:10:11 Epoch 33: lr=1.25e-05
2024-05-22 14:11:24 [Epoch: 33] loss: 0.004805, mae: 0.049264, r2: 0.767325, val_loss: 0.006138, val_mae: 0.054448, val_r2: 0.707488
2024-05-22 14:11:24 Epoch 34: lr=1.25e-05
2024-05-22 14:12:37 [Epoch: 34] loss: 0.004792, mae: 0.049209, r2: 0.767869, val_loss: 0.006112, val_mae: 0.054352, val_r2: 0.708365
2024-05-22 14:12:37 Epoch 35: lr=1.25e-05
2024-05-22 14:13:50 [Epoch: 35] loss: 0.004780, mae: 0.049148, r2: 0.768336, val_loss: 0.006121, val_mae: 0.054499, val_r2: 0.707848
2024-05-22 14:13:50 Epoch 36: lr=1.25e-05
2024-05-22 14:15:03 [Epoch: 36] loss: 0.004771, mae: 0.049108, r2: 0.768866, val_loss: 0.006132, val_mae: 0.054225, val_r2: 0.708171
2024-05-22 14:15:03 Epoch 37: lr=1e-05
2024-05-22 14:16:15 [Epoch: 37] loss: 0.004751, mae: 0.049020, r2: 0.769513, val_loss: 0.006127, val_mae: 0.054587, val_r2: 0.707602
2024-05-22 14:16:15 Epoch 38: lr=1e-05
2024-05-22 14:17:28 [Epoch: 38] loss: 0.004759, mae: 0.049039, r2: 0.769544, val_loss: 0.006107, val_mae: 0.054288, val_r2: 0.708816
2024-05-22 14:17:28 Epoch 39: lr=1e-05
2024-05-22 14:18:41 [Epoch: 39] loss: 0.004751, mae: 0.048985, r2: 0.769832, val_loss: 0.006101, val_mae: 0.054211, val_r2: 0.709456
2024-05-22 14:18:41 Epoch 40: lr=1e-05
2024-05-22 14:19:54 [Epoch: 40] loss: 0.004756, mae: 0.049026, r2: 0.769438, val_loss: 0.006130, val_mae: 0.054254, val_r2: 0.707561
2024-05-22 14:19:54 Epoch 41: lr=1e-05
2024-05-22 14:21:06 [Epoch: 41] loss: 0.004738, mae: 0.048940, r2: 0.770512, val_loss: 0.006138, val_mae: 0.054243, val_r2: 0.706711
2024-05-22 14:21:07 Epoch 42: lr=1e-05
2024-05-22 14:22:20 [Epoch: 42] loss: 0.004741, mae: 0.048921, r2: 0.770350, val_loss: 0.006129, val_mae: 0.054483, val_r2: 0.707384
2024-05-22 14:22:20 Epoch 43: lr=1e-05
2024-05-22 14:23:32 [Epoch: 43] loss: 0.004739, mae: 0.048935, r2: 0.770488, val_loss: 0.006145, val_mae: 0.054225, val_r2: 0.706766
2024-05-22 14:23:33 Epoch 44: lr=1e-05
2024-05-22 14:24:46 [Epoch: 44] loss: 0.004735, mae: 0.048923, r2: 0.770526, val_loss: 0.006140, val_mae: 0.054198, val_r2: 0.706974
2024-05-22 14:24:46 Epoch 45: lr=1e-05
2024-05-22 14:25:59 [Epoch: 45] loss: 0.004709, mae: 0.048809, r2: 0.771636, val_loss: 0.006114, val_mae: 0.054319, val_r2: 0.707765
2024-05-22 14:25:59 Epoch 46: lr=1e-05
2024-05-22 14:27:12 [Epoch: 46] loss: 0.004718, mae: 0.048794, r2: 0.771312, val_loss: 0.006135, val_mae: 0.054266, val_r2: 0.707448
2024-05-22 14:27:12 Epoch 47: lr=1e-05
2024-05-22 14:28:25 [Epoch: 47] loss: 0.004714, mae: 0.048826, r2: 0.771578, val_loss: 0.006131, val_mae: 0.054219, val_r2: 0.707638
2024-05-22 14:28:25 Epoch 48: lr=1e-05
2024-05-22 14:29:38 [Epoch: 48] loss: 0.004699, mae: 0.048756, r2: 0.772354, val_loss: 0.006118, val_mae: 0.054306, val_r2: 0.707759
2024-05-22 14:29:38 Epoch 49: lr=1e-05
2024-05-22 14:30:51 [Epoch: 49] loss: 0.004709, mae: 0.048780, r2: 0.771603, val_loss: 0.006115, val_mae: 0.054242, val_r2: 0.707938
2024-05-22 14:30:51 history_length: 50
2024-05-22 14:30:51 stopping: complete
2024-05-22 14:30:51 Comparing y_true and y_pred:
2024-05-22 14:30:51   mse: 0.01235322
2024-05-22 14:30:51   mae: 0.10048815
2024-05-22 14:30:51   r2: -5.41009810
2024-05-22 14:30:51   corr: 0.24841019
