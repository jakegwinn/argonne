2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/106', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '106', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/106/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/106', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c3s6b0n0.106.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/106/5.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/106'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x14ac90afe670>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/106/5.0.model.h5
2024-05-22 13:29:55 Between random pairs in y_val:
2024-05-22 13:29:55   mse: 0.04772003
2024-05-22 13:29:55   mae: 0.15998458
2024-05-22 13:29:55   r2: -0.99745059
2024-05-22 13:29:55   corr: 0.00127471
2024-05-22 13:29:55 Data points per epoch: train = 469633, val = 117409, test = 667
2024-05-22 13:29:55 Steps per epoch: train = 14676, val = 3669, test = 20
2024-05-22 13:29:55 Epoch 0: lr=0.001
2024-05-22 13:31:07 [Epoch: 0] loss: 0.025582, mae: 0.079433, r2: -0.351737, val_loss: 0.008470, val_mae: 0.065024, val_r2: 0.598102
2024-05-22 13:31:08 Epoch 1: lr=0.00082
2024-05-22 13:32:19 [Epoch: 1] loss: 0.007993, mae: 0.064011, r2: 0.620723, val_loss: 0.007646, val_mae: 0.061473, val_r2: 0.643083
2024-05-22 13:32:19 Epoch 2: lr=0.00064
2024-05-22 13:33:31 [Epoch: 2] loss: 0.007329, mae: 0.060944, r2: 0.652194, val_loss: 0.007251, val_mae: 0.059972, val_r2: 0.658799
2024-05-22 13:33:31 Epoch 3: lr=0.00046
2024-05-22 13:34:43 [Epoch: 3] loss: 0.006855, mae: 0.058783, r2: 0.673386, val_loss: 0.006946, val_mae: 0.058202, val_r2: 0.676400
2024-05-22 13:34:43 Epoch 4: lr=0.00028
2024-05-22 13:35:54 [Epoch: 4] loss: 0.006466, mae: 0.057020, r2: 0.691359, val_loss: 0.006647, val_mae: 0.058177, val_r2: 0.685072
2024-05-22 13:35:54 Epoch 5: lr=0.0001
2024-05-22 13:37:05 [Epoch: 5] loss: 0.006141, mae: 0.055500, r2: 0.706171, val_loss: 0.006448, val_mae: 0.056135, val_r2: 0.696043
2024-05-22 13:37:05 Epoch 6: lr=0.0001
2024-05-22 13:38:17 [Epoch: 6] loss: 0.006021, mae: 0.054937, r2: 0.711766, val_loss: 0.006413, val_mae: 0.055749, val_r2: 0.696363
2024-05-22 13:38:17 Epoch 7: lr=0.0001
2024-05-22 13:39:28 [Epoch: 7] loss: 0.005951, mae: 0.054626, r2: 0.715097, val_loss: 0.006373, val_mae: 0.055697, val_r2: 0.698277
2024-05-22 13:39:28 Epoch 8: lr=0.0001
2024-05-22 13:40:39 [Epoch: 8] loss: 0.005886, mae: 0.054319, r2: 0.718119, val_loss: 0.006368, val_mae: 0.056296, val_r2: 0.698100
2024-05-22 13:40:39 Epoch 9: lr=0.0001
2024-05-22 13:41:51 [Epoch: 9] loss: 0.005830, mae: 0.054063, r2: 0.720578, val_loss: 0.006322, val_mae: 0.055686, val_r2: 0.700857
2024-05-22 13:41:51 Epoch 10: lr=0.0001
2024-05-22 13:43:02 [Epoch: 10] loss: 0.005750, mae: 0.053735, r2: 0.724392, val_loss: 0.006279, val_mae: 0.055550, val_r2: 0.703116
2024-05-22 13:43:02 Epoch 11: lr=0.0001
2024-05-22 13:44:14 [Epoch: 11] loss: 0.005690, mae: 0.053470, r2: 0.727145, val_loss: 0.006256, val_mae: 0.055222, val_r2: 0.702729
2024-05-22 13:44:14 Epoch 12: lr=0.0001
2024-05-22 13:45:25 [Epoch: 12] loss: 0.005622, mae: 0.053188, r2: 0.730336, val_loss: 0.006286, val_mae: 0.055959, val_r2: 0.701550
2024-05-22 13:45:25 Epoch 13: lr=0.0001
2024-05-22 13:46:36 [Epoch: 13] loss: 0.005574, mae: 0.052930, r2: 0.732715, val_loss: 0.006239, val_mae: 0.055002, val_r2: 0.704640
2024-05-22 13:46:36 Epoch 14: lr=0.0001
2024-05-22 13:47:48 [Epoch: 14] loss: 0.005519, mae: 0.052690, r2: 0.735134, val_loss: 0.006226, val_mae: 0.055269, val_r2: 0.705506
2024-05-22 13:47:48 Epoch 15: lr=5e-05
2024-05-22 13:48:59 [Epoch: 15] loss: 0.005401, mae: 0.052119, r2: 0.740681, val_loss: 0.006218, val_mae: 0.055082, val_r2: 0.704985
2024-05-22 13:48:59 Epoch 16: lr=5e-05
2024-05-22 13:50:10 [Epoch: 16] loss: 0.005366, mae: 0.051955, r2: 0.742290, val_loss: 0.006188, val_mae: 0.055000, val_r2: 0.706203
2024-05-22 13:50:10 Epoch 17: lr=5e-05
2024-05-22 13:51:21 [Epoch: 17] loss: 0.005329, mae: 0.051799, r2: 0.743856, val_loss: 0.006180, val_mae: 0.054891, val_r2: 0.707443
2024-05-22 13:51:21 Epoch 18: lr=5e-05
2024-05-22 13:52:32 [Epoch: 18] loss: 0.005300, mae: 0.051690, r2: 0.745008, val_loss: 0.006201, val_mae: 0.054889, val_r2: 0.706427
2024-05-22 13:52:32 Epoch 19: lr=5e-05
2024-05-22 13:53:44 [Epoch: 19] loss: 0.005268, mae: 0.051553, r2: 0.746574, val_loss: 0.006170, val_mae: 0.054706, val_r2: 0.707515
2024-05-22 13:53:44 Epoch 20: lr=5e-05
2024-05-22 13:54:55 [Epoch: 20] loss: 0.005245, mae: 0.051429, r2: 0.747744, val_loss: 0.006173, val_mae: 0.054609, val_r2: 0.707084
2024-05-22 13:54:55 Epoch 21: lr=2.5e-05
2024-05-22 13:56:07 [Epoch: 21] loss: 0.005178, mae: 0.051104, r2: 0.750732, val_loss: 0.006173, val_mae: 0.054657, val_r2: 0.707629
2024-05-22 13:56:07 Epoch 22: lr=2.5e-05
2024-05-22 13:57:18 [Epoch: 22] loss: 0.005154, mae: 0.050966, r2: 0.751818, val_loss: 0.006156, val_mae: 0.054823, val_r2: 0.708110
2024-05-22 13:57:18 Epoch 23: lr=2.5e-05
2024-05-22 13:58:30 [Epoch: 23] loss: 0.005139, mae: 0.050894, r2: 0.752943, val_loss: 0.006170, val_mae: 0.054655, val_r2: 0.707778
2024-05-22 13:58:30 Epoch 24: lr=2.5e-05
2024-05-22 13:59:41 [Epoch: 24] loss: 0.005124, mae: 0.050827, r2: 0.753513, val_loss: 0.006154, val_mae: 0.054534, val_r2: 0.708466
2024-05-22 13:59:41 Epoch 25: lr=2.5e-05
2024-05-22 14:00:52 [Epoch: 25] loss: 0.005116, mae: 0.050759, r2: 0.753872, val_loss: 0.006159, val_mae: 0.054865, val_r2: 0.708409
2024-05-22 14:00:52 Epoch 26: lr=1.25e-05
2024-05-22 14:02:04 [Epoch: 26] loss: 0.005076, mae: 0.050641, r2: 0.755609, val_loss: 0.006158, val_mae: 0.054787, val_r2: 0.708577
2024-05-22 14:02:04 Epoch 27: lr=1.25e-05
2024-05-22 14:03:15 [Epoch: 27] loss: 0.005056, mae: 0.050512, r2: 0.756683, val_loss: 0.006170, val_mae: 0.054619, val_r2: 0.707463
2024-05-22 14:03:15 Epoch 28: lr=1.25e-05
2024-05-22 14:04:26 [Epoch: 28] loss: 0.005058, mae: 0.050534, r2: 0.756374, val_loss: 0.006147, val_mae: 0.054332, val_r2: 0.708130
2024-05-22 14:04:26 Epoch 29: lr=1.25e-05
2024-05-22 14:05:37 [Epoch: 29] loss: 0.005059, mae: 0.050506, r2: 0.756490, val_loss: 0.006169, val_mae: 0.054718, val_r2: 0.706976
2024-05-22 14:05:37 Epoch 30: lr=1.25e-05
2024-05-22 14:06:49 [Epoch: 30] loss: 0.005038, mae: 0.050394, r2: 0.757522, val_loss: 0.006179, val_mae: 0.054826, val_r2: 0.706546
2024-05-22 14:06:49 Epoch 31: lr=1e-05
2024-05-22 14:08:00 [Epoch: 31] loss: 0.005031, mae: 0.050389, r2: 0.757744, val_loss: 0.006172, val_mae: 0.054579, val_r2: 0.707490
2024-05-22 14:08:01 Epoch 32: lr=1e-05
2024-05-22 14:09:12 [Epoch: 32] loss: 0.005024, mae: 0.050345, r2: 0.758256, val_loss: 0.006150, val_mae: 0.054488, val_r2: 0.708622
2024-05-22 14:09:12 Epoch 33: lr=1e-05
2024-05-22 14:10:23 [Epoch: 33] loss: 0.005015, mae: 0.050336, r2: 0.758492, val_loss: 0.006153, val_mae: 0.054635, val_r2: 0.708588
2024-05-22 14:10:23 Epoch 34: lr=1e-05
2024-05-22 14:11:35 [Epoch: 34] loss: 0.005014, mae: 0.050313, r2: 0.758463, val_loss: 0.006152, val_mae: 0.054590, val_r2: 0.707498
2024-05-22 14:11:35 Epoch 35: lr=1e-05
2024-05-22 14:12:46 [Epoch: 35] loss: 0.005009, mae: 0.050291, r2: 0.758803, val_loss: 0.006162, val_mae: 0.054494, val_r2: 0.707532
2024-05-22 14:12:46 Epoch 36: lr=1e-05
2024-05-22 14:13:57 [Epoch: 36] loss: 0.005005, mae: 0.050274, r2: 0.758952, val_loss: 0.006134, val_mae: 0.054485, val_r2: 0.708921
2024-05-22 14:13:57 Epoch 37: lr=1e-05
2024-05-22 14:15:08 [Epoch: 37] loss: 0.004992, mae: 0.050196, r2: 0.759556, val_loss: 0.006136, val_mae: 0.054655, val_r2: 0.708707
2024-05-22 14:15:08 Epoch 38: lr=1e-05
2024-05-22 14:16:20 [Epoch: 38] loss: 0.004991, mae: 0.050190, r2: 0.759360, val_loss: 0.006173, val_mae: 0.054689, val_r2: 0.706430
2024-05-22 14:16:20 Epoch 39: lr=1e-05
2024-05-22 14:17:31 [Epoch: 39] loss: 0.004981, mae: 0.050150, r2: 0.760099, val_loss: 0.006160, val_mae: 0.054455, val_r2: 0.707488
2024-05-22 14:17:32 Epoch 40: lr=1e-05
2024-05-22 14:18:43 [Epoch: 40] loss: 0.004979, mae: 0.050139, r2: 0.760327, val_loss: 0.006150, val_mae: 0.054408, val_r2: 0.708405
2024-05-22 14:18:43 Epoch 41: lr=1e-05
2024-05-22 14:19:55 [Epoch: 41] loss: 0.004969, mae: 0.050117, r2: 0.760786, val_loss: 0.006168, val_mae: 0.054404, val_r2: 0.707318
2024-05-22 14:19:55 Epoch 42: lr=1e-05
2024-05-22 14:21:06 [Epoch: 42] loss: 0.004972, mae: 0.050128, r2: 0.760436, val_loss: 0.006139, val_mae: 0.054584, val_r2: 0.708203
2024-05-22 14:21:06 Epoch 43: lr=1e-05
2024-05-22 14:22:17 [Epoch: 43] loss: 0.004965, mae: 0.050087, r2: 0.760608, val_loss: 0.006157, val_mae: 0.054402, val_r2: 0.707383
2024-05-22 14:22:17 Epoch 44: lr=1e-05
2024-05-22 14:23:28 [Epoch: 44] loss: 0.004957, mae: 0.050024, r2: 0.761156, val_loss: 0.006157, val_mae: 0.054506, val_r2: 0.707654
2024-05-22 14:23:29 Epoch 45: lr=1e-05
2024-05-22 14:24:40 [Epoch: 45] loss: 0.004948, mae: 0.049967, r2: 0.761458, val_loss: 0.006155, val_mae: 0.054503, val_r2: 0.708290
2024-05-22 14:24:40 Epoch 46: lr=1e-05
2024-05-22 14:25:51 [Epoch: 46] loss: 0.004956, mae: 0.050065, r2: 0.761140, val_loss: 0.006130, val_mae: 0.054382, val_r2: 0.708880
2024-05-22 14:25:51 Epoch 47: lr=1e-05
2024-05-22 14:27:02 [Epoch: 47] loss: 0.004943, mae: 0.049993, r2: 0.761876, val_loss: 0.006147, val_mae: 0.054373, val_r2: 0.708484
2024-05-22 14:27:02 Epoch 48: lr=1e-05
2024-05-22 14:28:13 [Epoch: 48] loss: 0.004949, mae: 0.049987, r2: 0.761328, val_loss: 0.006163, val_mae: 0.054539, val_r2: 0.707820
2024-05-22 14:28:14 Epoch 49: lr=1e-05
2024-05-22 14:29:24 [Epoch: 49] loss: 0.004946, mae: 0.049969, r2: 0.761814, val_loss: 0.006159, val_mae: 0.054599, val_r2: 0.707577
2024-05-22 14:29:25 history_length: 50
2024-05-22 14:29:25 stopping: complete
2024-05-22 14:29:25 Comparing y_true and y_pred:
2024-05-22 14:29:25   mse: 0.00296078
2024-05-22 14:29:25   mae: 0.04211108
2024-05-22 14:29:25   r2: -0.25820876
2024-05-22 14:29:25   corr: 0.46522003
