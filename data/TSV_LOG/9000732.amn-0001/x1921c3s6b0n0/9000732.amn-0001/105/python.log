2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/105', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '105', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/105/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/105', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c3s6b0n0.105.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/105/4.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/105'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x14f519540f40>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/105/4.1.model.h5
2024-05-22 13:29:54 Between random pairs in y_val:
2024-05-22 13:29:54   mse: 0.04732318
2024-05-22 13:29:54   mae: 0.15938122
2024-05-22 13:29:54   r2: -1.00186861
2024-05-22 13:29:54   corr: -0.00093431
2024-05-22 13:29:54 Data points per epoch: train = 469286, val = 117322, test = 1101
2024-05-22 13:29:54 Steps per epoch: train = 14665, val = 3666, test = 34
2024-05-22 13:29:54 Epoch 0: lr=0.001
2024-05-22 13:31:08 [Epoch: 0] loss: 0.021407, mae: 0.078480, r2: -0.084983, val_loss: 0.008360, val_mae: 0.066337, val_r2: 0.599300
2024-05-22 13:31:09 Epoch 1: lr=0.00082
2024-05-22 13:32:21 [Epoch: 1] loss: 0.007859, mae: 0.063519, r2: 0.622842, val_loss: 0.007536, val_mae: 0.061252, val_r2: 0.644072
2024-05-22 13:32:21 Epoch 2: lr=0.00064
2024-05-22 13:33:34 [Epoch: 2] loss: 0.007197, mae: 0.060470, r2: 0.653360, val_loss: 0.007156, val_mae: 0.060495, val_r2: 0.654759
2024-05-22 13:33:35 Epoch 3: lr=0.00046
2024-05-22 13:34:47 [Epoch: 3] loss: 0.006712, mae: 0.058284, r2: 0.675402, val_loss: 0.006857, val_mae: 0.058855, val_r2: 0.671338
2024-05-22 13:34:47 Epoch 4: lr=0.00028
2024-05-22 13:36:00 [Epoch: 4] loss: 0.006341, mae: 0.056544, r2: 0.693185, val_loss: 0.006490, val_mae: 0.056915, val_r2: 0.687935
2024-05-22 13:36:00 Epoch 5: lr=0.0001
2024-05-22 13:37:13 [Epoch: 5] loss: 0.006010, mae: 0.055015, r2: 0.708480, val_loss: 0.006359, val_mae: 0.055981, val_r2: 0.695931
2024-05-22 13:37:13 Epoch 6: lr=0.0001
2024-05-22 13:38:25 [Epoch: 6] loss: 0.005913, mae: 0.054499, r2: 0.713043, val_loss: 0.006328, val_mae: 0.056290, val_r2: 0.694927
2024-05-22 13:38:25 Epoch 7: lr=0.0001
2024-05-22 13:39:38 [Epoch: 7] loss: 0.005840, mae: 0.054201, r2: 0.716392, val_loss: 0.006267, val_mae: 0.055392, val_r2: 0.698134
2024-05-22 13:39:38 Epoch 8: lr=0.0001
2024-05-22 13:40:51 [Epoch: 8] loss: 0.005764, mae: 0.053829, r2: 0.720245, val_loss: 0.006257, val_mae: 0.055561, val_r2: 0.697589
2024-05-22 13:40:51 Epoch 9: lr=0.0001
2024-05-22 13:42:04 [Epoch: 9] loss: 0.005703, mae: 0.053592, r2: 0.722925, val_loss: 0.006198, val_mae: 0.055541, val_r2: 0.701617
2024-05-22 13:42:04 Epoch 10: lr=0.0001
2024-05-22 13:43:17 [Epoch: 10] loss: 0.005640, mae: 0.053302, r2: 0.725915, val_loss: 0.006171, val_mae: 0.055390, val_r2: 0.703568
2024-05-22 13:43:17 Epoch 11: lr=0.0001
2024-05-22 13:44:30 [Epoch: 11] loss: 0.005582, mae: 0.052981, r2: 0.728715, val_loss: 0.006172, val_mae: 0.055084, val_r2: 0.704254
2024-05-22 13:44:30 Epoch 12: lr=0.0001
2024-05-22 13:45:43 [Epoch: 12] loss: 0.005524, mae: 0.052780, r2: 0.731666, val_loss: 0.006137, val_mae: 0.054904, val_r2: 0.704664
2024-05-22 13:45:43 Epoch 13: lr=0.0001
2024-05-22 13:46:56 [Epoch: 13] loss: 0.005472, mae: 0.052495, r2: 0.733879, val_loss: 0.006127, val_mae: 0.054820, val_r2: 0.705377
2024-05-22 13:46:56 Epoch 14: lr=0.0001
2024-05-22 13:48:08 [Epoch: 14] loss: 0.005424, mae: 0.052281, r2: 0.735973, val_loss: 0.006114, val_mae: 0.054947, val_r2: 0.705053
2024-05-22 13:48:08 Epoch 15: lr=0.0001
2024-05-22 13:49:21 [Epoch: 15] loss: 0.005366, mae: 0.052025, r2: 0.738697, val_loss: 0.006080, val_mae: 0.054694, val_r2: 0.707351
2024-05-22 13:49:21 Epoch 16: lr=0.0001
2024-05-22 13:50:34 [Epoch: 16] loss: 0.005320, mae: 0.051813, r2: 0.741161, val_loss: 0.006073, val_mae: 0.054685, val_r2: 0.706479
2024-05-22 13:50:35 Epoch 17: lr=0.0001
2024-05-22 13:51:47 [Epoch: 17] loss: 0.005266, mae: 0.051550, r2: 0.743629, val_loss: 0.006099, val_mae: 0.054294, val_r2: 0.705837
2024-05-22 13:51:47 Epoch 18: lr=5e-05
2024-05-22 13:53:00 [Epoch: 18] loss: 0.005149, mae: 0.050957, r2: 0.749241, val_loss: 0.006049, val_mae: 0.054581, val_r2: 0.707494
2024-05-22 13:53:00 Epoch 19: lr=5e-05
2024-05-22 13:54:13 [Epoch: 19] loss: 0.005119, mae: 0.050827, r2: 0.750490, val_loss: 0.006034, val_mae: 0.054336, val_r2: 0.708680
2024-05-22 13:54:13 Epoch 20: lr=5e-05
2024-05-22 13:55:26 [Epoch: 20] loss: 0.005085, mae: 0.050685, r2: 0.752008, val_loss: 0.006058, val_mae: 0.054167, val_r2: 0.708301
2024-05-22 13:55:26 Epoch 21: lr=5e-05
2024-05-22 13:56:39 [Epoch: 21] loss: 0.005066, mae: 0.050573, r2: 0.753086, val_loss: 0.006046, val_mae: 0.054218, val_r2: 0.707500
2024-05-22 13:56:39 Epoch 22: lr=5e-05
2024-05-22 13:57:51 [Epoch: 22] loss: 0.005033, mae: 0.050456, r2: 0.754677, val_loss: 0.006032, val_mae: 0.054346, val_r2: 0.709065
2024-05-22 13:57:52 Epoch 23: lr=5e-05
2024-05-22 13:59:05 [Epoch: 23] loss: 0.005010, mae: 0.050322, r2: 0.755522, val_loss: 0.006016, val_mae: 0.054201, val_r2: 0.709826
2024-05-22 13:59:05 Epoch 24: lr=5e-05
2024-05-22 14:00:18 [Epoch: 24] loss: 0.004984, mae: 0.050176, r2: 0.757066, val_loss: 0.006002, val_mae: 0.054196, val_r2: 0.709809
2024-05-22 14:00:18 Epoch 25: lr=2.5e-05
2024-05-22 14:01:31 [Epoch: 25] loss: 0.004924, mae: 0.049903, r2: 0.759750, val_loss: 0.006014, val_mae: 0.054219, val_r2: 0.710056
2024-05-22 14:01:31 Epoch 26: lr=2.5e-05
2024-05-22 14:02:43 [Epoch: 26] loss: 0.004916, mae: 0.049860, r2: 0.760272, val_loss: 0.006004, val_mae: 0.054214, val_r2: 0.710406
2024-05-22 14:02:44 Epoch 27: lr=2.5e-05
2024-05-22 14:03:56 [Epoch: 27] loss: 0.004898, mae: 0.049739, r2: 0.760808, val_loss: 0.006008, val_mae: 0.054007, val_r2: 0.710178
2024-05-22 14:03:56 Epoch 28: lr=2.5e-05
2024-05-22 14:05:09 [Epoch: 28] loss: 0.004882, mae: 0.049655, r2: 0.761812, val_loss: 0.005997, val_mae: 0.054517, val_r2: 0.710279
2024-05-22 14:05:09 Epoch 29: lr=2.5e-05
2024-05-22 14:06:22 [Epoch: 29] loss: 0.004864, mae: 0.049599, r2: 0.762825, val_loss: 0.006006, val_mae: 0.053997, val_r2: 0.710783
2024-05-22 14:06:22 Epoch 30: lr=1.25e-05
2024-05-22 14:07:35 [Epoch: 30] loss: 0.004824, mae: 0.049406, r2: 0.764494, val_loss: 0.005998, val_mae: 0.053948, val_r2: 0.710675
2024-05-22 14:07:35 Epoch 31: lr=1.25e-05
2024-05-22 14:08:47 [Epoch: 31] loss: 0.004820, mae: 0.049412, r2: 0.764840, val_loss: 0.006006, val_mae: 0.054422, val_r2: 0.709098
2024-05-22 14:08:47 Epoch 32: lr=1.25e-05
2024-05-22 14:10:00 [Epoch: 32] loss: 0.004819, mae: 0.049358, r2: 0.764734, val_loss: 0.005996, val_mae: 0.054038, val_r2: 0.710293
2024-05-22 14:10:01 Epoch 33: lr=1.25e-05
2024-05-22 14:11:13 [Epoch: 33] loss: 0.004812, mae: 0.049352, r2: 0.765068, val_loss: 0.005998, val_mae: 0.054167, val_r2: 0.710372
2024-05-22 14:11:14 Epoch 34: lr=1.25e-05
2024-05-22 14:12:26 [Epoch: 34] loss: 0.004806, mae: 0.049331, r2: 0.765619, val_loss: 0.006029, val_mae: 0.054001, val_r2: 0.708489
2024-05-22 14:12:27 Epoch 35: lr=1e-05
2024-05-22 14:13:39 [Epoch: 35] loss: 0.004801, mae: 0.049291, r2: 0.765765, val_loss: 0.006020, val_mae: 0.054138, val_r2: 0.709453
2024-05-22 14:13:39 Epoch 36: lr=1e-05
2024-05-22 14:14:52 [Epoch: 36] loss: 0.004790, mae: 0.049249, r2: 0.766118, val_loss: 0.006003, val_mae: 0.053998, val_r2: 0.710255
2024-05-22 14:14:52 Epoch 37: lr=1e-05
2024-05-22 14:16:05 [Epoch: 37] loss: 0.004781, mae: 0.049185, r2: 0.766620, val_loss: 0.005996, val_mae: 0.054144, val_r2: 0.710518
2024-05-22 14:16:05 Epoch 38: lr=1e-05
2024-05-22 14:17:17 [Epoch: 38] loss: 0.004773, mae: 0.049159, r2: 0.767017, val_loss: 0.005999, val_mae: 0.054011, val_r2: 0.709708
2024-05-22 14:17:18 Epoch 39: lr=1e-05
2024-05-22 14:18:31 [Epoch: 39] loss: 0.004770, mae: 0.049147, r2: 0.767074, val_loss: 0.006011, val_mae: 0.054030, val_r2: 0.710096
2024-05-22 14:18:31 Epoch 40: lr=1e-05
2024-05-22 14:19:44 [Epoch: 40] loss: 0.004761, mae: 0.049101, r2: 0.767382, val_loss: 0.005996, val_mae: 0.054117, val_r2: 0.709909
2024-05-22 14:19:44 Epoch 41: lr=1e-05
2024-05-22 14:20:56 [Epoch: 41] loss: 0.004757, mae: 0.049091, r2: 0.767526, val_loss: 0.005995, val_mae: 0.053871, val_r2: 0.710459
2024-05-22 14:20:56 Epoch 42: lr=1e-05
2024-05-22 14:22:09 [Epoch: 42] loss: 0.004749, mae: 0.049040, r2: 0.767979, val_loss: 0.006000, val_mae: 0.054078, val_r2: 0.710353
2024-05-22 14:22:09 Epoch 43: lr=1e-05
2024-05-22 14:23:21 [Epoch: 43] loss: 0.004746, mae: 0.049035, r2: 0.768343, val_loss: 0.005993, val_mae: 0.053896, val_r2: 0.710358
2024-05-22 14:23:21 Epoch 44: lr=1e-05
2024-05-22 14:24:34 [Epoch: 44] loss: 0.004739, mae: 0.048976, r2: 0.768499, val_loss: 0.006003, val_mae: 0.053999, val_r2: 0.710431
2024-05-22 14:24:34 Epoch 45: lr=1e-05
2024-05-22 14:25:46 [Epoch: 45] loss: 0.004733, mae: 0.048980, r2: 0.768719, val_loss: 0.006020, val_mae: 0.053880, val_r2: 0.709530
2024-05-22 14:25:46 Epoch 46: lr=1e-05
2024-05-22 14:26:58 [Epoch: 46] loss: 0.004732, mae: 0.048926, r2: 0.768857, val_loss: 0.005976, val_mae: 0.053951, val_r2: 0.711740
2024-05-22 14:26:58 Epoch 47: lr=1e-05
2024-05-22 14:28:11 [Epoch: 47] loss: 0.004716, mae: 0.048882, r2: 0.769592, val_loss: 0.005992, val_mae: 0.054121, val_r2: 0.710758
2024-05-22 14:28:11 Epoch 48: lr=1e-05
2024-05-22 14:29:24 [Epoch: 48] loss: 0.004723, mae: 0.048915, r2: 0.769281, val_loss: 0.005995, val_mae: 0.053944, val_r2: 0.709931
2024-05-22 14:29:24 Epoch 49: lr=1e-05
2024-05-22 14:30:36 [Epoch: 49] loss: 0.004716, mae: 0.048869, r2: 0.769924, val_loss: 0.005995, val_mae: 0.053840, val_r2: 0.710250
2024-05-22 14:30:37 history_length: 50
2024-05-22 14:30:37 stopping: complete
2024-05-22 14:30:37 Comparing y_true and y_pred:
2024-05-22 14:30:37   mse: 0.14899934
2024-05-22 14:30:37   mae: 0.34361158
2024-05-22 14:30:37   r2: -1.73134682
2024-05-22 14:30:37   corr: 0.17980316
