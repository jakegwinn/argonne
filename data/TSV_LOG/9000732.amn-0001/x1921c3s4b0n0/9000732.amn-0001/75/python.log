2024-05-22 13:29:36 UNO RUN ...
2024-05-22 13:29:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 50, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/9000732.amn-0001/75', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '9000732.amn-0001', 'run_id': '75', 'logfile': '/dev/shm/Uno/save/9000732.amn-0001/75/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/9000732.amn-0001/75', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c3s4b0n0.75.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/9000732.amn-0001/75/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/9000732.amn-0001/75'}
2024-05-22 13:29:36 Feature encoding submodel for cell.rnaseq:
2024-05-22 13:29:36 Model: "cell.rnaseq"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense (Dense)               (None, 1000)              959000    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-22 13:29:36  ntDropout)                                                      
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Trainable params: 2961000 (11.30 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Feature encoding submodel for drug.descriptors:
2024-05-22 13:29:36 Model: "drug.descriptors"
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape              Param #   
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-22 13:29:36  nentDropout)                                                    
2024-05-22 13:29:36                                                                  
2024-05-22 13:29:36 =================================================================
2024-05-22 13:29:36 Total params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Trainable params: 3616000 (13.79 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 _________________________________________________________________
2024-05-22 13:29:36 Combined model:
2024-05-22 13:29:36 Model: "model"
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-22 13:29:36  yer)                                                                                             
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-22 13:29:36  nputLayer)                                                                                       
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-22 13:29:36  al)                                                                ]']                           
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-22 13:29:36                                                                      'drug.descriptors[0][0]']    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-22 13:29:36  nentDropout)                                                                                     
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-22 13:29:36  anentDropout)                                                                                    
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-22 13:29:36                                                                                                   
2024-05-22 13:29:36 ==================================================================================================
2024-05-22 13:29:36 Total params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Trainable params: 12583001 (48.00 MB)
2024-05-22 13:29:36 Non-trainable params: 0 (0.00 Byte)
2024-05-22 13:29:36 __________________________________________________________________________________________________
2024-05-22 13:29:37 CKPT CONSTRUCT...
2024-05-22 13:29:37 CKPT CONSTRUCT OK.
2024-05-22 13:29:37 template model: <keras.src.engine.functional.Functional object at 0x15154a6c6610>
2024-05-22 13:29:38 COMPILE
2024-05-22 13:29:38 Will save weights to: /dev/shm/Uno/save/9000732.amn-0001/75/1.1.model.h5
2024-05-22 13:29:55 Between random pairs in y_val:
2024-05-22 13:29:55   mse: 0.04776048
2024-05-22 13:29:55   mae: 0.15986260
2024-05-22 13:29:55   r2: -1.00260302
2024-05-22 13:29:55   corr: -0.00130151
2024-05-22 13:29:55 Data points per epoch: train = 469568, val = 117392, test = 749
2024-05-22 13:29:55 Steps per epoch: train = 14674, val = 3668, test = 23
2024-05-22 13:29:55 Epoch 0: lr=0.001
2024-05-22 13:31:08 [Epoch: 0] loss: 0.043713, mae: 0.079924, r2: -1.195332, val_loss: 0.008535, val_mae: 0.066718, val_r2: 0.594862
2024-05-22 13:31:08 Epoch 1: lr=0.00082
2024-05-22 13:32:19 [Epoch: 1] loss: 0.008024, mae: 0.064042, r2: 0.619421, val_loss: 0.007687, val_mae: 0.061743, val_r2: 0.637959
2024-05-22 13:32:19 Epoch 2: lr=0.00064
2024-05-22 13:33:31 [Epoch: 2] loss: 0.007319, mae: 0.060829, r2: 0.651390, val_loss: 0.007135, val_mae: 0.060188, val_r2: 0.662671
2024-05-22 13:33:31 Epoch 3: lr=0.00046
2024-05-22 13:34:42 [Epoch: 3] loss: 0.006829, mae: 0.058644, r2: 0.673996, val_loss: 0.006755, val_mae: 0.058708, val_r2: 0.678288
2024-05-22 13:34:42 Epoch 4: lr=0.00028
2024-05-22 13:35:54 [Epoch: 4] loss: 0.006433, mae: 0.056781, r2: 0.692307, val_loss: 0.006555, val_mae: 0.057436, val_r2: 0.688023
2024-05-22 13:35:54 Epoch 5: lr=0.0001
2024-05-22 13:37:05 [Epoch: 5] loss: 0.006087, mae: 0.055219, r2: 0.708206, val_loss: 0.006371, val_mae: 0.056398, val_r2: 0.694653
2024-05-22 13:37:05 Epoch 6: lr=0.0001
2024-05-22 13:38:17 [Epoch: 6] loss: 0.005971, mae: 0.054699, r2: 0.713610, val_loss: 0.006316, val_mae: 0.055912, val_r2: 0.697449
2024-05-22 13:38:17 Epoch 7: lr=0.0001
2024-05-22 13:39:28 [Epoch: 7] loss: 0.005898, mae: 0.054339, r2: 0.717024, val_loss: 0.006291, val_mae: 0.055806, val_r2: 0.699219
2024-05-22 13:39:28 Epoch 8: lr=0.0001
2024-05-22 13:40:39 [Epoch: 8] loss: 0.005830, mae: 0.054038, r2: 0.720186, val_loss: 0.006269, val_mae: 0.055829, val_r2: 0.699960
2024-05-22 13:40:40 Epoch 9: lr=0.0001
2024-05-22 13:41:51 [Epoch: 9] loss: 0.005759, mae: 0.053748, r2: 0.723599, val_loss: 0.006241, val_mae: 0.055326, val_r2: 0.700197
2024-05-22 13:41:51 Epoch 10: lr=0.0001
2024-05-22 13:43:03 [Epoch: 10] loss: 0.005697, mae: 0.053445, r2: 0.726261, val_loss: 0.006222, val_mae: 0.055404, val_r2: 0.702051
2024-05-22 13:43:03 Epoch 11: lr=0.0001
2024-05-22 13:44:14 [Epoch: 11] loss: 0.005643, mae: 0.053237, r2: 0.728533, val_loss: 0.006190, val_mae: 0.055283, val_r2: 0.703278
2024-05-22 13:44:14 Epoch 12: lr=0.0001
2024-05-22 13:45:26 [Epoch: 12] loss: 0.005587, mae: 0.052949, r2: 0.731482, val_loss: 0.006189, val_mae: 0.055948, val_r2: 0.702800
2024-05-22 13:45:26 Epoch 13: lr=0.0001
2024-05-22 13:46:37 [Epoch: 13] loss: 0.005532, mae: 0.052709, r2: 0.734156, val_loss: 0.006154, val_mae: 0.055055, val_r2: 0.704162
2024-05-22 13:46:37 Epoch 14: lr=0.0001
2024-05-22 13:47:49 [Epoch: 14] loss: 0.005479, mae: 0.052478, r2: 0.736576, val_loss: 0.006154, val_mae: 0.054750, val_r2: 0.705260
2024-05-22 13:47:49 Epoch 15: lr=0.0001
2024-05-22 13:49:00 [Epoch: 15] loss: 0.005428, mae: 0.052225, r2: 0.738869, val_loss: 0.006113, val_mae: 0.055001, val_r2: 0.707037
2024-05-22 13:49:00 Epoch 16: lr=0.0001
2024-05-22 13:50:12 [Epoch: 16] loss: 0.005371, mae: 0.051960, r2: 0.741680, val_loss: 0.006130, val_mae: 0.054950, val_r2: 0.705298
2024-05-22 13:50:12 Epoch 17: lr=0.0001
2024-05-22 13:51:23 [Epoch: 17] loss: 0.005324, mae: 0.051704, r2: 0.744087, val_loss: 0.006130, val_mae: 0.054484, val_r2: 0.706194
2024-05-22 13:51:23 Epoch 18: lr=0.0001
2024-05-22 13:52:35 [Epoch: 18] loss: 0.005268, mae: 0.051453, r2: 0.746307, val_loss: 0.006100, val_mae: 0.054518, val_r2: 0.707878
2024-05-22 13:52:35 Epoch 19: lr=5e-05
2024-05-22 13:53:46 [Epoch: 19] loss: 0.005155, mae: 0.050920, r2: 0.751646, val_loss: 0.006089, val_mae: 0.054351, val_r2: 0.707651
2024-05-22 13:53:46 Epoch 20: lr=5e-05
2024-05-22 13:54:57 [Epoch: 20] loss: 0.005117, mae: 0.050718, r2: 0.753617, val_loss: 0.006074, val_mae: 0.054402, val_r2: 0.709372
2024-05-22 13:54:58 Epoch 21: lr=5e-05
2024-05-22 13:56:09 [Epoch: 21] loss: 0.005095, mae: 0.050603, r2: 0.754519, val_loss: 0.006072, val_mae: 0.054415, val_r2: 0.707995
2024-05-22 13:56:09 Epoch 22: lr=5e-05
2024-05-22 13:57:21 [Epoch: 22] loss: 0.005061, mae: 0.050488, r2: 0.756105, val_loss: 0.006081, val_mae: 0.054302, val_r2: 0.708084
2024-05-22 13:57:21 Epoch 23: lr=5e-05
2024-05-22 13:58:32 [Epoch: 23] loss: 0.005039, mae: 0.050357, r2: 0.757234, val_loss: 0.006077, val_mae: 0.054316, val_r2: 0.709264
2024-05-22 13:58:32 Epoch 24: lr=2.5e-05
2024-05-22 13:59:44 [Epoch: 24] loss: 0.004980, mae: 0.050066, r2: 0.760057, val_loss: 0.006072, val_mae: 0.054328, val_r2: 0.708696
2024-05-22 13:59:44 Epoch 25: lr=2.5e-05
2024-05-22 14:00:55 [Epoch: 25] loss: 0.004950, mae: 0.049927, r2: 0.761065, val_loss: 0.006052, val_mae: 0.054629, val_r2: 0.709304
2024-05-22 14:00:55 Epoch 26: lr=2.5e-05
2024-05-22 14:02:07 [Epoch: 26] loss: 0.004950, mae: 0.049912, r2: 0.761508, val_loss: 0.006053, val_mae: 0.054258, val_r2: 0.710160
2024-05-22 14:02:07 Epoch 27: lr=2.5e-05
2024-05-22 14:03:19 [Epoch: 27] loss: 0.004926, mae: 0.049804, r2: 0.762326, val_loss: 0.006045, val_mae: 0.054121, val_r2: 0.710140
2024-05-22 14:03:19 Epoch 28: lr=2.5e-05
2024-05-22 14:04:30 [Epoch: 28] loss: 0.004913, mae: 0.049742, r2: 0.763178, val_loss: 0.006049, val_mae: 0.054212, val_r2: 0.710046
2024-05-22 14:04:30 Epoch 29: lr=2.5e-05
2024-05-22 14:05:41 [Epoch: 29] loss: 0.004896, mae: 0.049654, r2: 0.763907, val_loss: 0.006045, val_mae: 0.054204, val_r2: 0.710424
2024-05-22 14:05:42 Epoch 30: lr=2.5e-05
2024-05-22 14:06:53 [Epoch: 30] loss: 0.004892, mae: 0.049682, r2: 0.763899, val_loss: 0.006051, val_mae: 0.054136, val_r2: 0.709410
2024-05-22 14:06:53 Epoch 31: lr=1.25e-05
2024-05-22 14:08:04 [Epoch: 31] loss: 0.004859, mae: 0.049507, r2: 0.765418, val_loss: 0.006057, val_mae: 0.054276, val_r2: 0.710067
2024-05-22 14:08:04 Epoch 32: lr=1.25e-05
2024-05-22 14:09:16 [Epoch: 32] loss: 0.004848, mae: 0.049424, r2: 0.766186, val_loss: 0.006048, val_mae: 0.054220, val_r2: 0.709400
2024-05-22 14:09:16 Epoch 33: lr=1.25e-05
2024-05-22 14:10:28 [Epoch: 33] loss: 0.004851, mae: 0.049439, r2: 0.765882, val_loss: 0.006074, val_mae: 0.054494, val_r2: 0.709049
2024-05-22 14:10:28 Epoch 34: lr=1.25e-05
2024-05-22 14:11:39 [Epoch: 34] loss: 0.004839, mae: 0.049403, r2: 0.766555, val_loss: 0.006072, val_mae: 0.054269, val_r2: 0.708972
2024-05-22 14:11:39 Epoch 35: lr=1.25e-05
2024-05-22 14:12:51 [Epoch: 35] loss: 0.004828, mae: 0.049342, r2: 0.767068, val_loss: 0.006054, val_mae: 0.054164, val_r2: 0.709729
2024-05-22 14:12:51 Epoch 36: lr=1e-05
2024-05-22 14:14:02 [Epoch: 36] loss: 0.004824, mae: 0.049335, r2: 0.767195, val_loss: 0.006071, val_mae: 0.054413, val_r2: 0.708873
2024-05-22 14:14:02 Epoch 37: lr=1e-05
2024-05-22 14:15:14 [Epoch: 37] loss: 0.004812, mae: 0.049292, r2: 0.767789, val_loss: 0.006055, val_mae: 0.054166, val_r2: 0.708913
2024-05-22 14:15:14 Epoch 38: lr=1e-05
2024-05-22 14:16:26 [Epoch: 38] loss: 0.004800, mae: 0.049195, r2: 0.768362, val_loss: 0.006038, val_mae: 0.054150, val_r2: 0.709764
2024-05-22 14:16:26 Epoch 39: lr=1e-05
2024-05-22 14:17:37 [Epoch: 39] loss: 0.004804, mae: 0.049214, r2: 0.768206, val_loss: 0.006065, val_mae: 0.054184, val_r2: 0.709454
2024-05-22 14:17:37 Epoch 40: lr=1e-05
2024-05-22 14:18:48 [Epoch: 40] loss: 0.004802, mae: 0.049213, r2: 0.768151, val_loss: 0.006059, val_mae: 0.054144, val_r2: 0.709201
2024-05-22 14:18:48 Epoch 41: lr=1e-05
2024-05-22 14:20:00 [Epoch: 41] loss: 0.004791, mae: 0.049192, r2: 0.768655, val_loss: 0.006047, val_mae: 0.054191, val_r2: 0.709725
2024-05-22 14:20:00 Epoch 42: lr=1e-05
2024-05-22 14:21:11 [Epoch: 42] loss: 0.004785, mae: 0.049109, r2: 0.769259, val_loss: 0.006050, val_mae: 0.054141, val_r2: 0.709416
2024-05-22 14:21:12 Epoch 43: lr=1e-05
2024-05-22 14:22:23 [Epoch: 43] loss: 0.004791, mae: 0.049167, r2: 0.768711, val_loss: 0.006041, val_mae: 0.054224, val_r2: 0.710437
2024-05-22 14:22:23 Epoch 44: lr=1e-05
2024-05-22 14:23:34 [Epoch: 44] loss: 0.004780, mae: 0.049101, r2: 0.769162, val_loss: 0.006081, val_mae: 0.054156, val_r2: 0.708327
2024-05-22 14:23:34 Epoch 45: lr=1e-05
2024-05-22 14:24:45 [Epoch: 45] loss: 0.004770, mae: 0.049049, r2: 0.769838, val_loss: 0.006072, val_mae: 0.054302, val_r2: 0.708328
2024-05-22 14:24:45 Epoch 46: lr=1e-05
2024-05-22 14:25:56 [Epoch: 46] loss: 0.004770, mae: 0.049043, r2: 0.769473, val_loss: 0.006063, val_mae: 0.054194, val_r2: 0.708964
2024-05-22 14:25:56 Epoch 47: lr=1e-05
2024-05-22 14:27:07 [Epoch: 47] loss: 0.004766, mae: 0.049030, r2: 0.769896, val_loss: 0.006066, val_mae: 0.054239, val_r2: 0.708863
2024-05-22 14:27:07 Epoch 48: lr=1e-05
2024-05-22 14:28:18 [Epoch: 48] loss: 0.004758, mae: 0.049015, r2: 0.770518, val_loss: 0.006108, val_mae: 0.054359, val_r2: 0.707223
2024-05-22 14:28:19 history_length: 49
2024-05-22 14:28:19 stopping: early
2024-05-22 14:28:19 Comparing y_true and y_pred:
2024-05-22 14:28:19   mse: 0.00703990
2024-05-22 14:28:19   mae: 0.06940599
2024-05-22 14:28:19   r2: -0.26602266
2024-05-22 14:28:19   corr: 0.13611606
