2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/136', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '136', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/136/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/136', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s3b0n0.136.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/136/2.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/136'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x145eaab23850>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/136/2.0.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04730159
2024-05-18 17:28:57   mae: 0.15916549
2024-05-18 17:28:57   r2: -0.99984718
2024-05-18 17:28:57   corr: 0.00007641
2024-05-18 17:28:57 Data points per epoch: train = 468593, val = 117149, test = 1967
2024-05-18 17:28:57 Steps per epoch: train = 14643, val = 3660, test = 61
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.031491, mae: 0.080016, r2: -0.494814, val_loss: 0.008502, val_mae: 0.067263, val_r2: 0.595207
2024-05-18 17:30:09 Epoch 1: lr=0.00082
2024-05-18 17:31:20 [Epoch: 1] loss: 0.007977, mae: 0.063881, r2: 0.622231, val_loss: 0.007539, val_mae: 0.062677, val_r2: 0.637070
2024-05-18 17:31:20 Epoch 2: lr=0.00064
2024-05-18 17:32:31 [Epoch: 2] loss: 0.007311, mae: 0.060804, r2: 0.652560, val_loss: 0.007007, val_mae: 0.059631, val_r2: 0.662041
2024-05-18 17:32:31 Epoch 3: lr=0.00046
2024-05-18 17:33:42 [Epoch: 3] loss: 0.006814, mae: 0.058537, r2: 0.675593, val_loss: 0.006727, val_mae: 0.058067, val_r2: 0.678518
2024-05-18 17:33:42 Epoch 4: lr=0.00028
2024-05-18 17:34:53 [Epoch: 4] loss: 0.006422, mae: 0.056755, r2: 0.693748, val_loss: 0.006539, val_mae: 0.056895, val_r2: 0.684337
2024-05-18 17:34:53 Epoch 5: lr=0.0001
2024-05-18 17:36:04 [Epoch: 5] loss: 0.006083, mae: 0.055154, r2: 0.709404, val_loss: 0.006308, val_mae: 0.055930, val_r2: 0.695858
2024-05-18 17:36:04 Epoch 6: lr=0.0001
2024-05-18 17:37:16 [Epoch: 6] loss: 0.005975, mae: 0.054630, r2: 0.714268, val_loss: 0.006298, val_mae: 0.055737, val_r2: 0.695023
2024-05-18 17:37:16 Epoch 7: lr=0.0001
2024-05-18 17:38:27 [Epoch: 7] loss: 0.005903, mae: 0.054326, r2: 0.717655, val_loss: 0.006247, val_mae: 0.055944, val_r2: 0.697867
2024-05-18 17:38:27 Epoch 8: lr=0.0001
2024-05-18 17:39:38 [Epoch: 8] loss: 0.005839, mae: 0.054024, r2: 0.720618, val_loss: 0.006219, val_mae: 0.055192, val_r2: 0.699911
2024-05-18 17:39:38 Epoch 9: lr=0.0001
2024-05-18 17:40:50 [Epoch: 9] loss: 0.005769, mae: 0.053713, r2: 0.723893, val_loss: 0.006232, val_mae: 0.055688, val_r2: 0.696669
2024-05-18 17:40:50 Epoch 10: lr=0.0001
2024-05-18 17:42:01 [Epoch: 10] loss: 0.005704, mae: 0.053418, r2: 0.726763, val_loss: 0.006142, val_mae: 0.055067, val_r2: 0.704151
2024-05-18 17:42:01 Epoch 11: lr=0.0001
2024-05-18 17:43:12 [Epoch: 11] loss: 0.005653, mae: 0.053166, r2: 0.729120, val_loss: 0.006143, val_mae: 0.054865, val_r2: 0.702751
2024-05-18 17:43:12 Epoch 12: lr=0.0001
2024-05-18 17:44:24 [Epoch: 12] loss: 0.005597, mae: 0.052897, r2: 0.731903, val_loss: 0.006194, val_mae: 0.055754, val_r2: 0.698654
2024-05-18 17:44:24 Epoch 13: lr=0.0001
2024-05-18 17:45:35 [Epoch: 13] loss: 0.005540, mae: 0.052636, r2: 0.734623, val_loss: 0.006108, val_mae: 0.054808, val_r2: 0.704763
2024-05-18 17:45:35 Epoch 14: lr=0.0001
2024-05-18 17:46:46 [Epoch: 14] loss: 0.005479, mae: 0.052384, r2: 0.737361, val_loss: 0.006092, val_mae: 0.054450, val_r2: 0.704760
2024-05-18 17:46:46 Epoch 15: lr=0.0001
2024-05-18 17:47:57 [Epoch: 15] loss: 0.005427, mae: 0.052173, r2: 0.739822, val_loss: 0.006079, val_mae: 0.054384, val_r2: 0.706378
2024-05-18 17:47:57 Epoch 16: lr=5e-05
2024-05-18 17:49:08 [Epoch: 16] loss: 0.005317, mae: 0.051611, r2: 0.745054, val_loss: 0.006075, val_mae: 0.054329, val_r2: 0.705950
2024-05-18 17:49:08 Epoch 17: lr=5e-05
2024-05-18 17:50:20 [Epoch: 17] loss: 0.005263, mae: 0.051390, r2: 0.747487, val_loss: 0.006057, val_mae: 0.054675, val_r2: 0.706025
2024-05-18 17:50:20 Epoch 18: lr=5e-05
2024-05-18 17:51:31 [Epoch: 18] loss: 0.005240, mae: 0.051263, r2: 0.748321, val_loss: 0.006027, val_mae: 0.054254, val_r2: 0.707370
2024-05-18 17:51:31 Epoch 19: lr=5e-05
2024-05-18 17:52:42 [Epoch: 19] loss: 0.005214, mae: 0.051114, r2: 0.749672, val_loss: 0.006018, val_mae: 0.054385, val_r2: 0.708455
2024-05-18 17:52:42 Epoch 20: lr=5e-05
2024-05-18 17:53:54 [Epoch: 20] loss: 0.005183, mae: 0.051016, r2: 0.751057, val_loss: 0.006028, val_mae: 0.054462, val_r2: 0.707394
2024-05-18 17:53:54 Epoch 21: lr=5e-05
2024-05-18 17:55:05 [Epoch: 21] loss: 0.005156, mae: 0.050882, r2: 0.752482, val_loss: 0.006064, val_mae: 0.054212, val_r2: 0.705436
2024-05-18 17:55:05 Epoch 22: lr=5e-05
2024-05-18 17:56:16 [Epoch: 22] loss: 0.005132, mae: 0.050794, r2: 0.753433, val_loss: 0.006037, val_mae: 0.053936, val_r2: 0.707024
2024-05-18 17:56:16 Epoch 23: lr=5e-05
2024-05-18 17:57:27 [Epoch: 23] loss: 0.005100, mae: 0.050599, r2: 0.754724, val_loss: 0.006018, val_mae: 0.054119, val_r2: 0.708021
2024-05-18 17:57:28 Epoch 24: lr=2.5e-05
2024-05-18 17:58:39 [Epoch: 24] loss: 0.005041, mae: 0.050345, r2: 0.757740, val_loss: 0.006006, val_mae: 0.054021, val_r2: 0.709185
2024-05-18 17:58:39 Epoch 25: lr=2.5e-05
2024-05-18 17:59:50 [Epoch: 25] loss: 0.005026, mae: 0.050233, r2: 0.758195, val_loss: 0.006025, val_mae: 0.054072, val_r2: 0.707813
2024-05-18 17:59:50 Epoch 26: lr=2.5e-05
2024-05-18 18:01:01 [Epoch: 26] loss: 0.005010, mae: 0.050173, r2: 0.759147, val_loss: 0.006003, val_mae: 0.054107, val_r2: 0.708351
2024-05-18 18:01:01 Epoch 27: lr=2.5e-05
2024-05-18 18:02:12 [Epoch: 27] loss: 0.004988, mae: 0.050097, r2: 0.759839, val_loss: 0.006010, val_mae: 0.054216, val_r2: 0.707739
2024-05-18 18:02:12 Epoch 28: lr=2.5e-05
2024-05-18 18:03:23 [Epoch: 28] loss: 0.004982, mae: 0.050040, r2: 0.760360, val_loss: 0.006040, val_mae: 0.054043, val_r2: 0.707621
2024-05-18 18:03:23 Epoch 29: lr=1.25e-05
2024-05-18 18:04:34 [Epoch: 29] loss: 0.004940, mae: 0.049880, r2: 0.762281, val_loss: 0.006008, val_mae: 0.053988, val_r2: 0.708715
2024-05-18 18:04:34 Epoch 30: lr=1.25e-05
2024-05-18 18:05:45 [Epoch: 30] loss: 0.004929, mae: 0.049827, r2: 0.762847, val_loss: 0.006008, val_mae: 0.054261, val_r2: 0.708699
2024-05-18 18:05:45 Epoch 31: lr=1.25e-05
2024-05-18 18:06:56 [Epoch: 31] loss: 0.004933, mae: 0.049818, r2: 0.762607, val_loss: 0.006012, val_mae: 0.054122, val_r2: 0.708128
2024-05-18 18:06:56 Epoch 32: lr=1.25e-05
2024-05-18 18:08:07 [Epoch: 32] loss: 0.004916, mae: 0.049734, r2: 0.763368, val_loss: 0.006012, val_mae: 0.053942, val_r2: 0.707994
2024-05-18 18:08:07 Epoch 33: lr=1.25e-05
2024-05-18 18:09:18 [Epoch: 33] loss: 0.004915, mae: 0.049729, r2: 0.763284, val_loss: 0.006028, val_mae: 0.054219, val_r2: 0.707076
2024-05-18 18:09:18 Epoch 34: lr=1e-05
2024-05-18 18:10:29 [Epoch: 34] loss: 0.004900, mae: 0.049662, r2: 0.764042, val_loss: 0.006001, val_mae: 0.054057, val_r2: 0.708863
2024-05-18 18:10:30 Epoch 35: lr=1e-05
2024-05-18 18:11:41 [Epoch: 35] loss: 0.004890, mae: 0.049635, r2: 0.764659, val_loss: 0.006000, val_mae: 0.054046, val_r2: 0.708448
2024-05-18 18:11:41 Epoch 36: lr=1e-05
2024-05-18 18:12:52 [Epoch: 36] loss: 0.004896, mae: 0.049651, r2: 0.764286, val_loss: 0.005982, val_mae: 0.053904, val_r2: 0.709867
2024-05-18 18:12:52 Epoch 37: lr=1e-05
2024-05-18 18:14:03 [Epoch: 37] loss: 0.004888, mae: 0.049583, r2: 0.764516, val_loss: 0.006004, val_mae: 0.053926, val_r2: 0.709180
2024-05-18 18:14:03 Epoch 38: lr=1e-05
2024-05-18 18:15:14 [Epoch: 38] loss: 0.004880, mae: 0.049548, r2: 0.765056, val_loss: 0.006014, val_mae: 0.053981, val_r2: 0.707615
2024-05-18 18:15:14 Epoch 39: lr=1e-05
2024-05-18 18:16:25 [Epoch: 39] loss: 0.004873, mae: 0.049535, r2: 0.765328, val_loss: 0.005994, val_mae: 0.053901, val_r2: 0.708784
2024-05-18 18:16:25 Epoch 40: lr=1e-05
2024-05-18 18:17:36 [Epoch: 40] loss: 0.004874, mae: 0.049511, r2: 0.765438, val_loss: 0.005980, val_mae: 0.053886, val_r2: 0.710130
2024-05-18 18:17:36 Epoch 41: lr=1e-05
2024-05-18 18:18:47 [Epoch: 41] loss: 0.004866, mae: 0.049524, r2: 0.765691, val_loss: 0.006003, val_mae: 0.053988, val_r2: 0.709120
2024-05-18 18:18:47 Epoch 42: lr=1e-05
2024-05-18 18:19:58 [Epoch: 42] loss: 0.004857, mae: 0.049465, r2: 0.766197, val_loss: 0.005974, val_mae: 0.053741, val_r2: 0.709805
2024-05-18 18:19:58 Epoch 43: lr=1e-05
2024-05-18 18:21:08 [Epoch: 43] loss: 0.004859, mae: 0.049474, r2: 0.765955, val_loss: 0.005997, val_mae: 0.054001, val_r2: 0.708632
2024-05-18 18:21:08 Epoch 44: lr=1e-05
2024-05-18 18:22:19 [Epoch: 44] loss: 0.004853, mae: 0.049451, r2: 0.766215, val_loss: 0.006017, val_mae: 0.054150, val_r2: 0.708410
2024-05-18 18:22:19 Epoch 45: lr=1e-05
2024-05-18 18:23:30 [Epoch: 45] loss: 0.004838, mae: 0.049408, r2: 0.766882, val_loss: 0.006002, val_mae: 0.054078, val_r2: 0.708076
2024-05-18 18:23:30 Epoch 46: lr=1e-05
2024-05-18 18:24:41 [Epoch: 46] loss: 0.004837, mae: 0.049341, r2: 0.767043, val_loss: 0.006006, val_mae: 0.054032, val_r2: 0.708862
2024-05-18 18:24:41 Epoch 47: lr=1e-05
2024-05-18 18:25:52 [Epoch: 47] loss: 0.004836, mae: 0.049364, r2: 0.767112, val_loss: 0.006013, val_mae: 0.054015, val_r2: 0.707943
2024-05-18 18:25:52 Epoch 48: lr=1e-05
2024-05-18 18:27:03 [Epoch: 48] loss: 0.004817, mae: 0.049253, r2: 0.767919, val_loss: 0.006019, val_mae: 0.053874, val_r2: 0.707877
2024-05-18 18:27:03 Epoch 49: lr=1e-05
2024-05-18 18:28:14 [Epoch: 49] loss: 0.004827, mae: 0.049313, r2: 0.767410, val_loss: 0.005999, val_mae: 0.053901, val_r2: 0.708467
2024-05-18 18:28:14 Epoch 50: lr=1e-05
2024-05-18 18:29:25 [Epoch: 50] loss: 0.004810, mae: 0.049266, r2: 0.768061, val_loss: 0.006007, val_mae: 0.054008, val_r2: 0.708554
2024-05-18 18:29:25 Epoch 51: lr=1e-05
2024-05-18 18:30:36 [Epoch: 51] loss: 0.004804, mae: 0.049206, r2: 0.768541, val_loss: 0.005993, val_mae: 0.054131, val_r2: 0.709046
2024-05-18 18:30:36 Epoch 52: lr=1e-05
2024-05-18 18:31:47 [Epoch: 52] loss: 0.004810, mae: 0.049222, r2: 0.768071, val_loss: 0.006000, val_mae: 0.053943, val_r2: 0.708873
2024-05-18 18:31:47 history_length: 53
2024-05-18 18:31:47 stopping: early
2024-05-18 18:31:47 Comparing y_true and y_pred:
2024-05-18 18:31:47   mse: 0.02259151
2024-05-18 18:31:47   mae: 0.12448087
2024-05-18 18:31:47   r2: 0.01832684
2024-05-18 18:31:47   corr: 0.58365811
