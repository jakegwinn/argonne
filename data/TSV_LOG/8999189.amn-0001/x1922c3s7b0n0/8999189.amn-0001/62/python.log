2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/62', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '62', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/62/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/62', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s7b0n0.62.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/62/1.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/62'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x154441796640>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/62/1.0.model.h5
2024-05-18 17:28:56 Between random pairs in y_val:
2024-05-18 17:28:56   mse: 0.04737428
2024-05-18 17:28:56   mae: 0.15946705
2024-05-18 17:28:56   r2: -0.99563990
2024-05-18 17:28:56   corr: 0.00218005
2024-05-18 17:28:56 Data points per epoch: train = 469878, val = 117470, test = 361
2024-05-18 17:28:56 Steps per epoch: train = 14683, val = 3670, test = 11
2024-05-18 17:28:56 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.024271, mae: 0.079305, r2: -0.132486, val_loss: 0.008722, val_mae: 0.068068, val_r2: 0.581679
2024-05-18 17:30:10 Epoch 1: lr=0.00082
2024-05-18 17:31:21 [Epoch: 1] loss: 0.007980, mae: 0.063846, r2: 0.620800, val_loss: 0.007739, val_mae: 0.061361, val_r2: 0.626410
2024-05-18 17:31:22 Epoch 2: lr=0.00064
2024-05-18 17:32:34 [Epoch: 2] loss: 0.007318, mae: 0.060878, r2: 0.651266, val_loss: 0.007352, val_mae: 0.060433, val_r2: 0.651355
2024-05-18 17:32:34 Epoch 3: lr=0.00046
2024-05-18 17:33:45 [Epoch: 3] loss: 0.006858, mae: 0.058756, r2: 0.672651, val_loss: 0.006914, val_mae: 0.058749, val_r2: 0.670736
2024-05-18 17:33:45 Epoch 4: lr=0.00028
2024-05-18 17:34:57 [Epoch: 4] loss: 0.006455, mae: 0.056898, r2: 0.690937, val_loss: 0.006632, val_mae: 0.057830, val_r2: 0.682194
2024-05-18 17:34:57 Epoch 5: lr=0.0001
2024-05-18 17:36:09 [Epoch: 5] loss: 0.006136, mae: 0.055411, r2: 0.705752, val_loss: 0.006473, val_mae: 0.056132, val_r2: 0.687774
2024-05-18 17:36:09 Epoch 6: lr=0.0001
2024-05-18 17:37:21 [Epoch: 6] loss: 0.006028, mae: 0.054931, r2: 0.710670, val_loss: 0.006420, val_mae: 0.056228, val_r2: 0.691658
2024-05-18 17:37:21 Epoch 7: lr=0.0001
2024-05-18 17:38:33 [Epoch: 7] loss: 0.005934, mae: 0.054510, r2: 0.715123, val_loss: 0.006405, val_mae: 0.056777, val_r2: 0.690717
2024-05-18 17:38:33 Epoch 8: lr=0.0001
2024-05-18 17:39:45 [Epoch: 8] loss: 0.005875, mae: 0.054247, r2: 0.717853, val_loss: 0.006344, val_mae: 0.055827, val_r2: 0.695243
2024-05-18 17:39:45 Epoch 9: lr=0.0001
2024-05-18 17:40:58 [Epoch: 9] loss: 0.005809, mae: 0.053962, r2: 0.721141, val_loss: 0.006304, val_mae: 0.055736, val_r2: 0.695742
2024-05-18 17:40:58 Epoch 10: lr=0.0001
2024-05-18 17:42:09 [Epoch: 10] loss: 0.005747, mae: 0.053659, r2: 0.723999, val_loss: 0.006274, val_mae: 0.055329, val_r2: 0.698573
2024-05-18 17:42:09 Epoch 11: lr=0.0001
2024-05-18 17:43:22 [Epoch: 11] loss: 0.005697, mae: 0.053441, r2: 0.726041, val_loss: 0.006301, val_mae: 0.055419, val_r2: 0.695512
2024-05-18 17:43:22 Epoch 12: lr=0.0001
2024-05-18 17:44:34 [Epoch: 12] loss: 0.005626, mae: 0.053099, r2: 0.729533, val_loss: 0.006286, val_mae: 0.055179, val_r2: 0.696863
2024-05-18 17:44:34 Epoch 13: lr=0.0001
2024-05-18 17:45:46 [Epoch: 13] loss: 0.005578, mae: 0.052892, r2: 0.731693, val_loss: 0.006211, val_mae: 0.055114, val_r2: 0.701347
2024-05-18 17:45:46 Epoch 14: lr=0.0001
2024-05-18 17:46:58 [Epoch: 14] loss: 0.005530, mae: 0.052665, r2: 0.733849, val_loss: 0.006225, val_mae: 0.055121, val_r2: 0.701289
2024-05-18 17:46:58 Epoch 15: lr=0.0001
2024-05-18 17:48:10 [Epoch: 15] loss: 0.005463, mae: 0.052370, r2: 0.737099, val_loss: 0.006224, val_mae: 0.055296, val_r2: 0.700102
2024-05-18 17:48:10 Epoch 16: lr=0.0001
2024-05-18 17:49:22 [Epoch: 16] loss: 0.005410, mae: 0.052134, r2: 0.739329, val_loss: 0.006193, val_mae: 0.055519, val_r2: 0.701527
2024-05-18 17:49:22 Epoch 17: lr=0.0001
2024-05-18 17:50:34 [Epoch: 17] loss: 0.005363, mae: 0.051921, r2: 0.741866, val_loss: 0.006177, val_mae: 0.054459, val_r2: 0.702598
2024-05-18 17:50:34 Epoch 18: lr=0.0001
2024-05-18 17:51:46 [Epoch: 18] loss: 0.005324, mae: 0.051741, r2: 0.743625, val_loss: 0.006175, val_mae: 0.054775, val_r2: 0.703382
2024-05-18 17:51:46 Epoch 19: lr=5e-05
2024-05-18 17:52:58 [Epoch: 19] loss: 0.005203, mae: 0.051162, r2: 0.749177, val_loss: 0.006155, val_mae: 0.054591, val_r2: 0.703702
2024-05-18 17:52:58 Epoch 20: lr=5e-05
2024-05-18 17:54:10 [Epoch: 20] loss: 0.005162, mae: 0.050991, r2: 0.751266, val_loss: 0.006157, val_mae: 0.054666, val_r2: 0.703289
2024-05-18 17:54:10 Epoch 21: lr=5e-05
2024-05-18 17:55:22 [Epoch: 21] loss: 0.005133, mae: 0.050843, r2: 0.752408, val_loss: 0.006119, val_mae: 0.054584, val_r2: 0.705586
2024-05-18 17:55:22 Epoch 22: lr=5e-05
2024-05-18 17:56:34 [Epoch: 22] loss: 0.005113, mae: 0.050722, r2: 0.753380, val_loss: 0.006177, val_mae: 0.054434, val_r2: 0.702367
2024-05-18 17:56:34 Epoch 23: lr=5e-05
2024-05-18 17:57:46 [Epoch: 23] loss: 0.005087, mae: 0.050606, r2: 0.754889, val_loss: 0.006142, val_mae: 0.054763, val_r2: 0.703831
2024-05-18 17:57:46 Epoch 24: lr=2.5e-05
2024-05-18 17:58:58 [Epoch: 24] loss: 0.005016, mae: 0.050252, r2: 0.757859, val_loss: 0.006138, val_mae: 0.054552, val_r2: 0.704267
2024-05-18 17:58:58 Epoch 25: lr=2.5e-05
2024-05-18 18:00:10 [Epoch: 25] loss: 0.005003, mae: 0.050206, r2: 0.758485, val_loss: 0.006127, val_mae: 0.054476, val_r2: 0.705397
2024-05-18 18:00:10 Epoch 26: lr=2.5e-05
2024-05-18 18:01:23 [Epoch: 26] loss: 0.004990, mae: 0.050197, r2: 0.759141, val_loss: 0.006169, val_mae: 0.054635, val_r2: 0.702253
2024-05-18 18:01:23 Epoch 27: lr=2.5e-05
2024-05-18 18:02:34 [Epoch: 27] loss: 0.004974, mae: 0.050067, r2: 0.759964, val_loss: 0.006158, val_mae: 0.054554, val_r2: 0.703007
2024-05-18 18:02:35 Epoch 28: lr=2.5e-05
2024-05-18 18:03:47 [Epoch: 28] loss: 0.004968, mae: 0.050058, r2: 0.760040, val_loss: 0.006121, val_mae: 0.054506, val_r2: 0.705412
2024-05-18 18:03:47 Epoch 29: lr=1.25e-05
2024-05-18 18:04:59 [Epoch: 29] loss: 0.004926, mae: 0.049857, r2: 0.762015, val_loss: 0.006126, val_mae: 0.054509, val_r2: 0.704682
2024-05-18 18:04:59 Epoch 30: lr=1.25e-05
2024-05-18 18:06:11 [Epoch: 30] loss: 0.004913, mae: 0.049830, r2: 0.762695, val_loss: 0.006117, val_mae: 0.054493, val_r2: 0.705195
2024-05-18 18:06:11 Epoch 31: lr=1.25e-05
2024-05-18 18:07:23 [Epoch: 31] loss: 0.004904, mae: 0.049734, r2: 0.763053, val_loss: 0.006143, val_mae: 0.054586, val_r2: 0.704540
2024-05-18 18:07:23 Epoch 32: lr=1.25e-05
2024-05-18 18:08:35 [Epoch: 32] loss: 0.004904, mae: 0.049755, r2: 0.763222, val_loss: 0.006135, val_mae: 0.054672, val_r2: 0.704865
2024-05-18 18:08:35 Epoch 33: lr=1.25e-05
2024-05-18 18:09:47 [Epoch: 33] loss: 0.004888, mae: 0.049674, r2: 0.763872, val_loss: 0.006137, val_mae: 0.054428, val_r2: 0.704637
2024-05-18 18:09:47 Epoch 34: lr=1e-05
2024-05-18 18:10:59 [Epoch: 34] loss: 0.004887, mae: 0.049650, r2: 0.764004, val_loss: 0.006134, val_mae: 0.054374, val_r2: 0.704635
2024-05-18 18:11:00 Epoch 35: lr=1e-05
2024-05-18 18:12:12 [Epoch: 35] loss: 0.004869, mae: 0.049573, r2: 0.764867, val_loss: 0.006110, val_mae: 0.054394, val_r2: 0.705543
2024-05-18 18:12:12 Epoch 36: lr=1e-05
2024-05-18 18:13:24 [Epoch: 36] loss: 0.004868, mae: 0.049560, r2: 0.764714, val_loss: 0.006126, val_mae: 0.054391, val_r2: 0.705000
2024-05-18 18:13:25 Epoch 37: lr=1e-05
2024-05-18 18:14:36 [Epoch: 37] loss: 0.004862, mae: 0.049533, r2: 0.765075, val_loss: 0.006112, val_mae: 0.054253, val_r2: 0.705823
2024-05-18 18:14:36 Epoch 38: lr=1e-05
2024-05-18 18:15:48 [Epoch: 38] loss: 0.004865, mae: 0.049551, r2: 0.765296, val_loss: 0.006139, val_mae: 0.054390, val_r2: 0.704604
2024-05-18 18:15:48 Epoch 39: lr=1e-05
2024-05-18 18:16:59 [Epoch: 39] loss: 0.004859, mae: 0.049523, r2: 0.765268, val_loss: 0.006144, val_mae: 0.054523, val_r2: 0.703990
2024-05-18 18:16:59 Epoch 40: lr=1e-05
2024-05-18 18:18:11 [Epoch: 40] loss: 0.004848, mae: 0.049512, r2: 0.765740, val_loss: 0.006128, val_mae: 0.054283, val_r2: 0.704714
2024-05-18 18:18:11 Epoch 41: lr=1e-05
2024-05-18 18:19:23 [Epoch: 41] loss: 0.004851, mae: 0.049499, r2: 0.765729, val_loss: 0.006139, val_mae: 0.054397, val_r2: 0.703823
2024-05-18 18:19:23 Epoch 42: lr=1e-05
2024-05-18 18:20:35 [Epoch: 42] loss: 0.004831, mae: 0.049403, r2: 0.766476, val_loss: 0.006123, val_mae: 0.054464, val_r2: 0.704911
2024-05-18 18:20:35 Epoch 43: lr=1e-05
2024-05-18 18:21:47 [Epoch: 43] loss: 0.004835, mae: 0.049403, r2: 0.766111, val_loss: 0.006106, val_mae: 0.054420, val_r2: 0.706247
2024-05-18 18:21:47 Epoch 44: lr=1e-05
2024-05-18 18:22:59 [Epoch: 44] loss: 0.004830, mae: 0.049393, r2: 0.766587, val_loss: 0.006130, val_mae: 0.054186, val_r2: 0.705137
2024-05-18 18:22:59 Epoch 45: lr=1e-05
2024-05-18 18:24:11 [Epoch: 45] loss: 0.004819, mae: 0.049334, r2: 0.767005, val_loss: 0.006152, val_mae: 0.054685, val_r2: 0.704073
2024-05-18 18:24:11 Epoch 46: lr=1e-05
2024-05-18 18:25:22 [Epoch: 46] loss: 0.004815, mae: 0.049352, r2: 0.767272, val_loss: 0.006146, val_mae: 0.054364, val_r2: 0.704393
2024-05-18 18:25:22 Epoch 47: lr=1e-05
2024-05-18 18:26:34 [Epoch: 47] loss: 0.004815, mae: 0.049303, r2: 0.767274, val_loss: 0.006116, val_mae: 0.054346, val_r2: 0.705835
2024-05-18 18:26:34 Epoch 48: lr=1e-05
2024-05-18 18:27:46 [Epoch: 48] loss: 0.004828, mae: 0.049374, r2: 0.766789, val_loss: 0.006119, val_mae: 0.054396, val_r2: 0.705484
2024-05-18 18:27:46 Epoch 49: lr=1e-05
2024-05-18 18:28:57 [Epoch: 49] loss: 0.004809, mae: 0.049293, r2: 0.767744, val_loss: 0.006160, val_mae: 0.054438, val_r2: 0.703708
2024-05-18 18:28:58 Epoch 50: lr=1e-05
2024-05-18 18:30:09 [Epoch: 50] loss: 0.004810, mae: 0.049264, r2: 0.767418, val_loss: 0.006145, val_mae: 0.054271, val_r2: 0.704437
2024-05-18 18:30:09 Epoch 51: lr=1e-05
2024-05-18 18:31:21 [Epoch: 51] loss: 0.004795, mae: 0.049220, r2: 0.768128, val_loss: 0.006138, val_mae: 0.054483, val_r2: 0.704782
2024-05-18 18:31:21 Epoch 52: lr=1e-05
2024-05-18 18:32:32 [Epoch: 52] loss: 0.004786, mae: 0.049185, r2: 0.768581, val_loss: 0.006120, val_mae: 0.054285, val_r2: 0.705068
2024-05-18 18:32:32 Epoch 53: lr=1e-05
2024-05-18 18:33:44 [Epoch: 53] loss: 0.004790, mae: 0.049161, r2: 0.768444, val_loss: 0.006108, val_mae: 0.054244, val_r2: 0.706075
2024-05-18 18:33:44 history_length: 54
2024-05-18 18:33:44 stopping: early
2024-05-18 18:33:44 Comparing y_true and y_pred:
2024-05-18 18:33:44   mse: 0.05922224
2024-05-18 18:33:44   mae: 0.22728300
2024-05-18 18:33:44   r2: -3.83510871
2024-05-18 18:33:44   corr: 0.29049007
