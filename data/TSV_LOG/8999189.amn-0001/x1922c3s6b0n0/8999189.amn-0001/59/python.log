2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/59', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '59', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/59/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/59', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s6b0n0.59.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/59/5.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/59'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x149aa8377bb0>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/59/5.1.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04765272
2024-05-18 17:28:57   mae: 0.15962773
2024-05-18 17:28:57   r2: -1.00231661
2024-05-18 17:28:57   corr: -0.00115831
2024-05-18 17:28:57 Data points per epoch: train = 469619, val = 117405, test = 685
2024-05-18 17:28:57 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.024102, mae: 0.079326, r2: 0.010271, val_loss: 0.009023, val_mae: 0.071086, val_r2: 0.573394
2024-05-18 17:30:09 Epoch 1: lr=0.00082
2024-05-18 17:31:19 [Epoch: 1] loss: 0.008001, mae: 0.064039, r2: 0.621800, val_loss: 0.007704, val_mae: 0.061527, val_r2: 0.627100
2024-05-18 17:31:20 Epoch 2: lr=0.00064
2024-05-18 17:32:30 [Epoch: 2] loss: 0.007346, mae: 0.060944, r2: 0.651398, val_loss: 0.007228, val_mae: 0.060069, val_r2: 0.652922
2024-05-18 17:32:30 Epoch 3: lr=0.00046
2024-05-18 17:33:40 [Epoch: 3] loss: 0.006865, mae: 0.058791, r2: 0.673690, val_loss: 0.006958, val_mae: 0.060708, val_r2: 0.663918
2024-05-18 17:33:40 Epoch 4: lr=0.00028
2024-05-18 17:34:50 [Epoch: 4] loss: 0.006479, mae: 0.057018, r2: 0.691287, val_loss: 0.006624, val_mae: 0.057961, val_r2: 0.680182
2024-05-18 17:34:50 Epoch 5: lr=0.0001
2024-05-18 17:36:01 [Epoch: 5] loss: 0.006150, mae: 0.055521, r2: 0.706439, val_loss: 0.006418, val_mae: 0.056300, val_r2: 0.691191
2024-05-18 17:36:01 Epoch 6: lr=0.0001
2024-05-18 17:37:11 [Epoch: 6] loss: 0.006029, mae: 0.054977, r2: 0.711845, val_loss: 0.006403, val_mae: 0.055915, val_r2: 0.690100
2024-05-18 17:37:11 Epoch 7: lr=0.0001
2024-05-18 17:38:21 [Epoch: 7] loss: 0.005968, mae: 0.054686, r2: 0.714961, val_loss: 0.006399, val_mae: 0.055609, val_r2: 0.690105
2024-05-18 17:38:21 Epoch 8: lr=0.0001
2024-05-18 17:39:32 [Epoch: 8] loss: 0.005886, mae: 0.054334, r2: 0.718462, val_loss: 0.006292, val_mae: 0.055632, val_r2: 0.696625
2024-05-18 17:39:32 Epoch 9: lr=0.0001
2024-05-18 17:40:42 [Epoch: 9] loss: 0.005821, mae: 0.054037, r2: 0.721455, val_loss: 0.006291, val_mae: 0.055473, val_r2: 0.696261
2024-05-18 17:40:42 Epoch 10: lr=0.0001
2024-05-18 17:41:52 [Epoch: 10] loss: 0.005759, mae: 0.053782, r2: 0.724404, val_loss: 0.006267, val_mae: 0.055570, val_r2: 0.698064
2024-05-18 17:41:53 Epoch 11: lr=0.0001
2024-05-18 17:43:03 [Epoch: 11] loss: 0.005702, mae: 0.053517, r2: 0.726988, val_loss: 0.006242, val_mae: 0.055545, val_r2: 0.697862
2024-05-18 17:43:03 Epoch 12: lr=0.0001
2024-05-18 17:44:13 [Epoch: 12] loss: 0.005657, mae: 0.053316, r2: 0.729127, val_loss: 0.006220, val_mae: 0.055361, val_r2: 0.699546
2024-05-18 17:44:13 Epoch 13: lr=0.0001
2024-05-18 17:45:24 [Epoch: 13] loss: 0.005595, mae: 0.053024, r2: 0.731835, val_loss: 0.006237, val_mae: 0.054914, val_r2: 0.697406
2024-05-18 17:45:24 Epoch 14: lr=5e-05
2024-05-18 17:46:34 [Epoch: 14] loss: 0.005470, mae: 0.052427, r2: 0.737534, val_loss: 0.006172, val_mae: 0.055062, val_r2: 0.701562
2024-05-18 17:46:34 Epoch 15: lr=5e-05
2024-05-18 17:47:44 [Epoch: 15] loss: 0.005423, mae: 0.052241, r2: 0.739847, val_loss: 0.006190, val_mae: 0.055175, val_r2: 0.700651
2024-05-18 17:47:45 Epoch 16: lr=5e-05
2024-05-18 17:48:55 [Epoch: 16] loss: 0.005409, mae: 0.052118, r2: 0.740697, val_loss: 0.006172, val_mae: 0.055009, val_r2: 0.700900
2024-05-18 17:48:55 Epoch 17: lr=5e-05
2024-05-18 17:50:05 [Epoch: 17] loss: 0.005372, mae: 0.051982, r2: 0.742251, val_loss: 0.006153, val_mae: 0.054726, val_r2: 0.701832
2024-05-18 17:50:05 Epoch 18: lr=5e-05
2024-05-18 17:51:15 [Epoch: 18] loss: 0.005338, mae: 0.051839, r2: 0.743838, val_loss: 0.006179, val_mae: 0.054867, val_r2: 0.701540
2024-05-18 17:51:16 Epoch 19: lr=5e-05
2024-05-18 17:52:26 [Epoch: 19] loss: 0.005319, mae: 0.051735, r2: 0.744702, val_loss: 0.006147, val_mae: 0.054877, val_r2: 0.701785
2024-05-18 17:52:26 Epoch 20: lr=2.5e-05
2024-05-18 17:53:36 [Epoch: 20] loss: 0.005251, mae: 0.051422, r2: 0.747720, val_loss: 0.006129, val_mae: 0.054851, val_r2: 0.703454
2024-05-18 17:53:36 Epoch 21: lr=2.5e-05
2024-05-18 17:54:47 [Epoch: 21] loss: 0.005230, mae: 0.051308, r2: 0.748946, val_loss: 0.006137, val_mae: 0.054828, val_r2: 0.702369
2024-05-18 17:54:47 Epoch 22: lr=2.5e-05
2024-05-18 17:55:57 [Epoch: 22] loss: 0.005203, mae: 0.051186, r2: 0.750203, val_loss: 0.006132, val_mae: 0.055025, val_r2: 0.703485
2024-05-18 17:55:57 Epoch 23: lr=2.5e-05
2024-05-18 17:57:07 [Epoch: 23] loss: 0.005209, mae: 0.051197, r2: 0.749963, val_loss: 0.006155, val_mae: 0.054909, val_r2: 0.702785
2024-05-18 17:57:07 Epoch 24: lr=2.5e-05
2024-05-18 17:58:18 [Epoch: 24] loss: 0.005183, mae: 0.051087, r2: 0.751074, val_loss: 0.006133, val_mae: 0.054835, val_r2: 0.703094
2024-05-18 17:58:18 Epoch 25: lr=1.25e-05
2024-05-18 17:59:28 [Epoch: 25] loss: 0.005153, mae: 0.050959, r2: 0.752441, val_loss: 0.006130, val_mae: 0.054905, val_r2: 0.703105
2024-05-18 17:59:28 Epoch 26: lr=1.25e-05
2024-05-18 18:00:38 [Epoch: 26] loss: 0.005138, mae: 0.050901, r2: 0.753069, val_loss: 0.006175, val_mae: 0.054731, val_r2: 0.700963
2024-05-18 18:00:38 Epoch 27: lr=1.25e-05
2024-05-18 18:01:49 [Epoch: 27] loss: 0.005135, mae: 0.050881, r2: 0.753272, val_loss: 0.006135, val_mae: 0.054724, val_r2: 0.703421
2024-05-18 18:01:49 Epoch 28: lr=1.25e-05
2024-05-18 18:02:59 [Epoch: 28] loss: 0.005119, mae: 0.050780, r2: 0.754205, val_loss: 0.006131, val_mae: 0.054739, val_r2: 0.703445
2024-05-18 18:02:59 Epoch 29: lr=1.25e-05
2024-05-18 18:04:10 [Epoch: 29] loss: 0.005122, mae: 0.050823, r2: 0.753873, val_loss: 0.006129, val_mae: 0.054847, val_r2: 0.703717
2024-05-18 18:04:10 Epoch 30: lr=1e-05
2024-05-18 18:05:20 [Epoch: 30] loss: 0.005098, mae: 0.050727, r2: 0.755121, val_loss: 0.006145, val_mae: 0.054633, val_r2: 0.702398
2024-05-18 18:05:20 Epoch 31: lr=1e-05
2024-05-18 18:06:30 [Epoch: 31] loss: 0.005089, mae: 0.050658, r2: 0.755333, val_loss: 0.006148, val_mae: 0.054779, val_r2: 0.702326
2024-05-18 18:06:30 Epoch 32: lr=1e-05
2024-05-18 18:07:41 [Epoch: 32] loss: 0.005088, mae: 0.050681, r2: 0.755464, val_loss: 0.006146, val_mae: 0.054799, val_r2: 0.702023
2024-05-18 18:07:41 Epoch 33: lr=1e-05
2024-05-18 18:08:51 [Epoch: 33] loss: 0.005084, mae: 0.050653, r2: 0.755599, val_loss: 0.006115, val_mae: 0.054768, val_r2: 0.703676
2024-05-18 18:08:51 Epoch 34: lr=1e-05
2024-05-18 18:10:02 [Epoch: 34] loss: 0.005079, mae: 0.050640, r2: 0.755932, val_loss: 0.006116, val_mae: 0.054770, val_r2: 0.702997
2024-05-18 18:10:02 Epoch 35: lr=1e-05
2024-05-18 18:11:12 [Epoch: 35] loss: 0.005067, mae: 0.050553, r2: 0.756508, val_loss: 0.006137, val_mae: 0.054603, val_r2: 0.702094
2024-05-18 18:11:12 Epoch 36: lr=1e-05
2024-05-18 18:12:22 [Epoch: 36] loss: 0.005065, mae: 0.050532, r2: 0.756697, val_loss: 0.006129, val_mae: 0.054672, val_r2: 0.703785
2024-05-18 18:12:22 Epoch 37: lr=1e-05
2024-05-18 18:13:33 [Epoch: 37] loss: 0.005062, mae: 0.050543, r2: 0.756750, val_loss: 0.006120, val_mae: 0.054601, val_r2: 0.703823
2024-05-18 18:13:33 Epoch 38: lr=1e-05
2024-05-18 18:14:43 [Epoch: 38] loss: 0.005058, mae: 0.050517, r2: 0.756929, val_loss: 0.006120, val_mae: 0.054657, val_r2: 0.702720
2024-05-18 18:14:43 Epoch 39: lr=1e-05
2024-05-18 18:15:54 [Epoch: 39] loss: 0.005052, mae: 0.050470, r2: 0.757124, val_loss: 0.006105, val_mae: 0.054591, val_r2: 0.704225
2024-05-18 18:15:54 Epoch 40: lr=1e-05
2024-05-18 18:17:04 [Epoch: 40] loss: 0.005046, mae: 0.050458, r2: 0.757588, val_loss: 0.006111, val_mae: 0.054689, val_r2: 0.704290
2024-05-18 18:17:04 Epoch 41: lr=1e-05
2024-05-18 18:18:14 [Epoch: 41] loss: 0.005045, mae: 0.050450, r2: 0.757583, val_loss: 0.006095, val_mae: 0.054635, val_r2: 0.705355
2024-05-18 18:18:14 Epoch 42: lr=1e-05
2024-05-18 18:19:25 [Epoch: 42] loss: 0.005032, mae: 0.050361, r2: 0.758323, val_loss: 0.006120, val_mae: 0.054621, val_r2: 0.703695
2024-05-18 18:19:25 Epoch 43: lr=1e-05
2024-05-18 18:20:35 [Epoch: 43] loss: 0.005035, mae: 0.050420, r2: 0.757990, val_loss: 0.006122, val_mae: 0.054401, val_r2: 0.704189
2024-05-18 18:20:35 Epoch 44: lr=1e-05
2024-05-18 18:21:45 [Epoch: 44] loss: 0.005021, mae: 0.050344, r2: 0.758639, val_loss: 0.006139, val_mae: 0.054624, val_r2: 0.702055
2024-05-18 18:21:45 Epoch 45: lr=1e-05
2024-05-18 18:22:56 [Epoch: 45] loss: 0.005024, mae: 0.050362, r2: 0.758670, val_loss: 0.006135, val_mae: 0.054580, val_r2: 0.703578
2024-05-18 18:22:56 Epoch 46: lr=1e-05
2024-05-18 18:24:06 [Epoch: 46] loss: 0.005016, mae: 0.050314, r2: 0.758923, val_loss: 0.006126, val_mae: 0.054585, val_r2: 0.703411
2024-05-18 18:24:06 Epoch 47: lr=1e-05
2024-05-18 18:25:16 [Epoch: 47] loss: 0.005012, mae: 0.050256, r2: 0.758826, val_loss: 0.006143, val_mae: 0.054583, val_r2: 0.702437
2024-05-18 18:25:16 Epoch 48: lr=1e-05
2024-05-18 18:26:26 [Epoch: 48] loss: 0.005005, mae: 0.050253, r2: 0.759506, val_loss: 0.006128, val_mae: 0.054507, val_r2: 0.703347
2024-05-18 18:26:26 Epoch 49: lr=1e-05
2024-05-18 18:27:36 [Epoch: 49] loss: 0.004996, mae: 0.050210, r2: 0.759973, val_loss: 0.006118, val_mae: 0.054531, val_r2: 0.703594
2024-05-18 18:27:36 Epoch 50: lr=1e-05
2024-05-18 18:28:46 [Epoch: 50] loss: 0.004989, mae: 0.050191, r2: 0.760161, val_loss: 0.006116, val_mae: 0.054567, val_r2: 0.703773
2024-05-18 18:28:46 Epoch 51: lr=1e-05
2024-05-18 18:29:56 [Epoch: 51] loss: 0.004993, mae: 0.050191, r2: 0.759969, val_loss: 0.006115, val_mae: 0.054463, val_r2: 0.703618
2024-05-18 18:29:57 history_length: 52
2024-05-18 18:29:57 stopping: early
2024-05-18 18:29:57 Comparing y_true and y_pred:
2024-05-18 18:29:57   mse: 0.02946809
2024-05-18 18:29:57   mae: 0.13744993
2024-05-18 18:29:57   r2: -14.62995967
2024-05-18 18:29:57   corr: 0.11913373
