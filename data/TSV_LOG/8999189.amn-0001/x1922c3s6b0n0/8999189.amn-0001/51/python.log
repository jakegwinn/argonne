2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/51', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '51', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/51/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/51', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s6b0n0.51.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/51/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/51'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x1488058d6850>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/51/1.1.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04768966
2024-05-18 17:28:57   mae: 0.15994528
2024-05-18 17:28:57   r2: -1.00534118
2024-05-18 17:28:57   corr: -0.00267059
2024-05-18 17:28:57 Data points per epoch: train = 468724, val = 117181, test = 1804
2024-05-18 17:28:57 Steps per epoch: train = 14647, val = 3661, test = 56
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:11 [Epoch: 0] loss: 0.027558, mae: 0.079562, r2: -0.058748, val_loss: 0.008530, val_mae: 0.066552, val_r2: 0.602621
2024-05-18 17:30:11 Epoch 1: lr=0.00082
2024-05-18 17:31:23 [Epoch: 1] loss: 0.008007, mae: 0.063989, r2: 0.622015, val_loss: 0.007577, val_mae: 0.061492, val_r2: 0.637514
2024-05-18 17:31:23 Epoch 2: lr=0.00064
2024-05-18 17:32:36 [Epoch: 2] loss: 0.007309, mae: 0.060832, r2: 0.653736, val_loss: 0.007302, val_mae: 0.062158, val_r2: 0.655164
2024-05-18 17:32:36 Epoch 3: lr=0.00046
2024-05-18 17:33:48 [Epoch: 3] loss: 0.006834, mae: 0.058609, r2: 0.675473, val_loss: 0.006878, val_mae: 0.058237, val_r2: 0.671716
2024-05-18 17:33:48 Epoch 4: lr=0.00028
2024-05-18 17:35:00 [Epoch: 4] loss: 0.006447, mae: 0.056796, r2: 0.693250, val_loss: 0.006593, val_mae: 0.057215, val_r2: 0.684080
2024-05-18 17:35:00 Epoch 5: lr=0.0001
2024-05-18 17:36:13 [Epoch: 5] loss: 0.006117, mae: 0.055268, r2: 0.708119, val_loss: 0.006457, val_mae: 0.056558, val_r2: 0.692432
2024-05-18 17:36:13 Epoch 6: lr=0.0001
2024-05-18 17:37:26 [Epoch: 6] loss: 0.006000, mae: 0.054788, r2: 0.713762, val_loss: 0.006440, val_mae: 0.056571, val_r2: 0.691602
2024-05-18 17:37:26 Epoch 7: lr=0.0001
2024-05-18 17:38:39 [Epoch: 7] loss: 0.005934, mae: 0.054477, r2: 0.716622, val_loss: 0.006402, val_mae: 0.055884, val_r2: 0.695597
2024-05-18 17:38:39 Epoch 8: lr=0.0001
2024-05-18 17:39:51 [Epoch: 8] loss: 0.005856, mae: 0.054122, r2: 0.720451, val_loss: 0.006369, val_mae: 0.056088, val_r2: 0.694073
2024-05-18 17:39:52 Epoch 9: lr=0.0001
2024-05-18 17:41:05 [Epoch: 9] loss: 0.005801, mae: 0.053860, r2: 0.722804, val_loss: 0.006324, val_mae: 0.055896, val_r2: 0.697074
2024-05-18 17:41:05 Epoch 10: lr=0.0001
2024-05-18 17:42:17 [Epoch: 10] loss: 0.005738, mae: 0.053553, r2: 0.725591, val_loss: 0.006325, val_mae: 0.055325, val_r2: 0.697446
2024-05-18 17:42:17 Epoch 11: lr=0.0001
2024-05-18 17:43:30 [Epoch: 11] loss: 0.005680, mae: 0.053306, r2: 0.728321, val_loss: 0.006256, val_mae: 0.055704, val_r2: 0.700304
2024-05-18 17:43:30 Epoch 12: lr=0.0001
2024-05-18 17:44:42 [Epoch: 12] loss: 0.005611, mae: 0.053011, r2: 0.731585, val_loss: 0.006245, val_mae: 0.055422, val_r2: 0.700944
2024-05-18 17:44:43 Epoch 13: lr=0.0001
2024-05-18 17:45:55 [Epoch: 13] loss: 0.005563, mae: 0.052763, r2: 0.733667, val_loss: 0.006249, val_mae: 0.055210, val_r2: 0.701188
2024-05-18 17:45:55 Epoch 14: lr=0.0001
2024-05-18 17:47:08 [Epoch: 14] loss: 0.005508, mae: 0.052530, r2: 0.736467, val_loss: 0.006231, val_mae: 0.055189, val_r2: 0.701859
2024-05-18 17:47:08 Epoch 15: lr=5e-05
2024-05-18 17:48:20 [Epoch: 15] loss: 0.005391, mae: 0.051958, r2: 0.741892, val_loss: 0.006187, val_mae: 0.055081, val_r2: 0.704296
2024-05-18 17:48:21 Epoch 16: lr=5e-05
2024-05-18 17:49:33 [Epoch: 16] loss: 0.005352, mae: 0.051775, r2: 0.743586, val_loss: 0.006181, val_mae: 0.054941, val_r2: 0.705368
2024-05-18 17:49:33 Epoch 17: lr=5e-05
2024-05-18 17:50:45 [Epoch: 17] loss: 0.005316, mae: 0.051569, r2: 0.745362, val_loss: 0.006160, val_mae: 0.055338, val_r2: 0.705499
2024-05-18 17:50:45 Epoch 18: lr=5e-05
2024-05-18 17:51:58 [Epoch: 18] loss: 0.005294, mae: 0.051511, r2: 0.746282, val_loss: 0.006139, val_mae: 0.055081, val_r2: 0.706244
2024-05-18 17:51:58 Epoch 19: lr=5e-05
2024-05-18 17:53:10 [Epoch: 19] loss: 0.005255, mae: 0.051359, r2: 0.748269, val_loss: 0.006151, val_mae: 0.054772, val_r2: 0.705519
2024-05-18 17:53:11 Epoch 20: lr=5e-05
2024-05-18 17:54:23 [Epoch: 20] loss: 0.005240, mae: 0.051239, r2: 0.748881, val_loss: 0.006154, val_mae: 0.054873, val_r2: 0.704427
2024-05-18 17:54:23 Epoch 21: lr=2.5e-05
2024-05-18 17:55:36 [Epoch: 21] loss: 0.005167, mae: 0.050916, r2: 0.752126, val_loss: 0.006139, val_mae: 0.054617, val_r2: 0.706984
2024-05-18 17:55:36 Epoch 22: lr=2.5e-05
2024-05-18 17:56:48 [Epoch: 22] loss: 0.005155, mae: 0.050849, r2: 0.752844, val_loss: 0.006142, val_mae: 0.054754, val_r2: 0.706693
2024-05-18 17:56:48 Epoch 23: lr=2.5e-05
2024-05-18 17:58:01 [Epoch: 23] loss: 0.005125, mae: 0.050715, r2: 0.754263, val_loss: 0.006136, val_mae: 0.054942, val_r2: 0.706140
2024-05-18 17:58:01 Epoch 24: lr=2.5e-05
2024-05-18 17:59:13 [Epoch: 24] loss: 0.005126, mae: 0.050723, r2: 0.754072, val_loss: 0.006133, val_mae: 0.054697, val_r2: 0.706779
2024-05-18 17:59:13 Epoch 25: lr=2.5e-05
2024-05-18 18:00:26 [Epoch: 25] loss: 0.005105, mae: 0.050615, r2: 0.754980, val_loss: 0.006112, val_mae: 0.054860, val_r2: 0.706940
2024-05-18 18:00:26 Epoch 26: lr=1.25e-05
2024-05-18 18:01:39 [Epoch: 26] loss: 0.005068, mae: 0.050437, r2: 0.757053, val_loss: 0.006153, val_mae: 0.054629, val_r2: 0.705499
2024-05-18 18:01:39 Epoch 27: lr=1.25e-05
2024-05-18 18:02:51 [Epoch: 27] loss: 0.005052, mae: 0.050355, r2: 0.757478, val_loss: 0.006157, val_mae: 0.054776, val_r2: 0.705080
2024-05-18 18:02:51 Epoch 28: lr=1.25e-05
2024-05-18 18:04:04 [Epoch: 28] loss: 0.005059, mae: 0.050373, r2: 0.757109, val_loss: 0.006122, val_mae: 0.054813, val_r2: 0.706722
2024-05-18 18:04:04 Epoch 29: lr=1.25e-05
2024-05-18 18:05:16 [Epoch: 29] loss: 0.005052, mae: 0.050348, r2: 0.757655, val_loss: 0.006117, val_mae: 0.054525, val_r2: 0.707434
2024-05-18 18:05:16 Epoch 30: lr=1.25e-05
2024-05-18 18:06:28 [Epoch: 30] loss: 0.005036, mae: 0.050290, r2: 0.758057, val_loss: 0.006154, val_mae: 0.054812, val_r2: 0.705178
2024-05-18 18:06:28 Epoch 31: lr=1e-05
2024-05-18 18:07:41 [Epoch: 31] loss: 0.005015, mae: 0.050183, r2: 0.759212, val_loss: 0.006115, val_mae: 0.054576, val_r2: 0.707026
2024-05-18 18:07:41 Epoch 32: lr=1e-05
2024-05-18 18:08:54 [Epoch: 32] loss: 0.005013, mae: 0.050172, r2: 0.759157, val_loss: 0.006150, val_mae: 0.054664, val_r2: 0.704799
2024-05-18 18:08:54 Epoch 33: lr=1e-05
2024-05-18 18:10:06 [Epoch: 33] loss: 0.005026, mae: 0.050201, r2: 0.758793, val_loss: 0.006128, val_mae: 0.054815, val_r2: 0.706828
2024-05-18 18:10:06 Epoch 34: lr=1e-05
2024-05-18 18:11:19 [Epoch: 34] loss: 0.005014, mae: 0.050182, r2: 0.759416, val_loss: 0.006108, val_mae: 0.054593, val_r2: 0.707135
2024-05-18 18:11:20 Epoch 35: lr=1e-05
2024-05-18 18:12:32 [Epoch: 35] loss: 0.005003, mae: 0.050147, r2: 0.759686, val_loss: 0.006140, val_mae: 0.054624, val_r2: 0.705983
2024-05-18 18:12:32 Epoch 36: lr=1e-05
2024-05-18 18:13:45 [Epoch: 36] loss: 0.004986, mae: 0.050078, r2: 0.760471, val_loss: 0.006133, val_mae: 0.054679, val_r2: 0.706049
2024-05-18 18:13:45 Epoch 37: lr=1e-05
2024-05-18 18:14:57 [Epoch: 37] loss: 0.004994, mae: 0.050059, r2: 0.760370, val_loss: 0.006107, val_mae: 0.054860, val_r2: 0.707534
2024-05-18 18:14:57 Epoch 38: lr=1e-05
2024-05-18 18:16:10 [Epoch: 38] loss: 0.004978, mae: 0.050000, r2: 0.760979, val_loss: 0.006135, val_mae: 0.054630, val_r2: 0.705736
2024-05-18 18:16:10 Epoch 39: lr=1e-05
2024-05-18 18:17:23 [Epoch: 39] loss: 0.004982, mae: 0.050003, r2: 0.760574, val_loss: 0.006120, val_mae: 0.054713, val_r2: 0.706340
2024-05-18 18:17:23 Epoch 40: lr=1e-05
2024-05-18 18:18:35 [Epoch: 40] loss: 0.004973, mae: 0.049953, r2: 0.761357, val_loss: 0.006147, val_mae: 0.054586, val_r2: 0.705327
2024-05-18 18:18:35 Epoch 41: lr=1e-05
2024-05-18 18:19:48 [Epoch: 41] loss: 0.004968, mae: 0.049960, r2: 0.761326, val_loss: 0.006127, val_mae: 0.054495, val_r2: 0.706563
2024-05-18 18:19:48 Epoch 42: lr=1e-05
2024-05-18 18:21:01 [Epoch: 42] loss: 0.004961, mae: 0.049919, r2: 0.761809, val_loss: 0.006101, val_mae: 0.054597, val_r2: 0.707618
2024-05-18 18:21:01 Epoch 43: lr=1e-05
2024-05-18 18:22:13 [Epoch: 43] loss: 0.004959, mae: 0.049911, r2: 0.761735, val_loss: 0.006132, val_mae: 0.054637, val_r2: 0.705976
2024-05-18 18:22:13 Epoch 44: lr=1e-05
2024-05-18 18:23:26 [Epoch: 44] loss: 0.004949, mae: 0.049868, r2: 0.762248, val_loss: 0.006140, val_mae: 0.054524, val_r2: 0.705364
2024-05-18 18:23:26 Epoch 45: lr=1e-05
2024-05-18 18:24:39 [Epoch: 45] loss: 0.004946, mae: 0.049847, r2: 0.762346, val_loss: 0.006116, val_mae: 0.054568, val_r2: 0.707052
2024-05-18 18:24:39 Epoch 46: lr=1e-05
2024-05-18 18:25:51 [Epoch: 46] loss: 0.004942, mae: 0.049833, r2: 0.762627, val_loss: 0.006123, val_mae: 0.054600, val_r2: 0.707289
2024-05-18 18:25:51 Epoch 47: lr=1e-05
2024-05-18 18:27:03 [Epoch: 47] loss: 0.004944, mae: 0.049877, r2: 0.762487, val_loss: 0.006126, val_mae: 0.054589, val_r2: 0.706865
2024-05-18 18:27:04 Epoch 48: lr=1e-05
2024-05-18 18:28:16 [Epoch: 48] loss: 0.004933, mae: 0.049795, r2: 0.763206, val_loss: 0.006123, val_mae: 0.054614, val_r2: 0.706994
2024-05-18 18:28:16 Epoch 49: lr=1e-05
2024-05-18 18:29:29 [Epoch: 49] loss: 0.004926, mae: 0.049788, r2: 0.763390, val_loss: 0.006114, val_mae: 0.054403, val_r2: 0.707115
2024-05-18 18:29:29 Epoch 50: lr=1e-05
2024-05-18 18:30:41 [Epoch: 50] loss: 0.004914, mae: 0.049727, r2: 0.763934, val_loss: 0.006131, val_mae: 0.054675, val_r2: 0.706253
2024-05-18 18:30:41 Epoch 51: lr=1e-05
2024-05-18 18:31:54 [Epoch: 51] loss: 0.004920, mae: 0.049750, r2: 0.763684, val_loss: 0.006095, val_mae: 0.054401, val_r2: 0.708438
2024-05-18 18:31:54 Epoch 52: lr=1e-05
2024-05-18 18:33:06 [Epoch: 52] loss: 0.004917, mae: 0.049704, r2: 0.763870, val_loss: 0.006106, val_mae: 0.054578, val_r2: 0.707271
2024-05-18 18:33:06 Epoch 53: lr=1e-05
2024-05-18 18:34:18 [Epoch: 53] loss: 0.004897, mae: 0.049634, r2: 0.764775, val_loss: 0.006120, val_mae: 0.054493, val_r2: 0.706718
2024-05-18 18:34:18 Epoch 54: lr=1e-05
2024-05-18 18:35:31 [Epoch: 54] loss: 0.004896, mae: 0.049629, r2: 0.764725, val_loss: 0.006126, val_mae: 0.054483, val_r2: 0.706409
2024-05-18 18:35:31 Epoch 55: lr=1e-05
2024-05-18 18:36:43 [Epoch: 55] loss: 0.004902, mae: 0.049654, r2: 0.764534, val_loss: 0.006119, val_mae: 0.054445, val_r2: 0.706382
2024-05-18 18:36:43 Epoch 56: lr=1e-05
2024-05-18 18:37:56 [Epoch: 56] loss: 0.004885, mae: 0.049557, r2: 0.765242, val_loss: 0.006135, val_mae: 0.054621, val_r2: 0.706094
2024-05-18 18:37:56 Epoch 57: lr=1e-05
2024-05-18 18:39:08 [Epoch: 57] loss: 0.004880, mae: 0.049542, r2: 0.765539, val_loss: 0.006130, val_mae: 0.054486, val_r2: 0.706237
2024-05-18 18:39:09 Epoch 58: lr=1e-05
2024-05-18 18:40:21 [Epoch: 58] loss: 0.004875, mae: 0.049502, r2: 0.765892, val_loss: 0.006099, val_mae: 0.054308, val_r2: 0.707315
2024-05-18 18:40:21 Epoch 59: lr=1e-05
2024-05-18 18:41:33 [Epoch: 59] loss: 0.004876, mae: 0.049486, r2: 0.765900, val_loss: 0.006109, val_mae: 0.054479, val_r2: 0.707703
2024-05-18 18:41:33 Epoch 60: lr=1e-05
2024-05-18 18:42:46 [Epoch: 60] loss: 0.004872, mae: 0.049515, r2: 0.766066, val_loss: 0.006117, val_mae: 0.054580, val_r2: 0.706552
2024-05-18 18:42:46 Epoch 61: lr=1e-05
2024-05-18 18:43:58 [Epoch: 61] loss: 0.004869, mae: 0.049508, r2: 0.766021, val_loss: 0.006106, val_mae: 0.054448, val_r2: 0.707151
2024-05-18 18:43:59 history_length: 62
2024-05-18 18:43:59 stopping: early
2024-05-18 18:43:59 Comparing y_true and y_pred:
2024-05-18 18:43:59   mse: 0.01181845
2024-05-18 18:43:59   mae: 0.08362728
2024-05-18 18:43:59   r2: 0.17113336
2024-05-18 18:43:59   corr: 0.41952383
