2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/109', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '109', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/109/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/109', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s1b0n0.109.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/109/0.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/109'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x1526ea5f8760>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/109/0.1.model.h5
2024-05-18 17:28:56 Between random pairs in y_val:
2024-05-18 17:28:56   mse: 0.04776048
2024-05-18 17:28:56   mae: 0.16010444
2024-05-18 17:28:56   r2: -1.00431748
2024-05-18 17:28:56   corr: -0.00215874
2024-05-18 17:28:56 Data points per epoch: train = 469631, val = 117408, test = 670
2024-05-18 17:28:56 Steps per epoch: train = 14675, val = 3669, test = 20
2024-05-18 17:28:56 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.026524, mae: 0.079456, r2: -0.010227, val_loss: 0.008488, val_mae: 0.065207, val_r2: 0.595493
2024-05-18 17:30:09 Epoch 1: lr=0.00082
2024-05-18 17:31:21 [Epoch: 1] loss: 0.007952, mae: 0.063783, r2: 0.623194, val_loss: 0.007660, val_mae: 0.062089, val_r2: 0.642015
2024-05-18 17:31:21 Epoch 2: lr=0.00064
2024-05-18 17:32:32 [Epoch: 2] loss: 0.007314, mae: 0.060793, r2: 0.652959, val_loss: 0.007222, val_mae: 0.059649, val_r2: 0.654319
2024-05-18 17:32:32 Epoch 3: lr=0.00046
2024-05-18 17:33:43 [Epoch: 3] loss: 0.006857, mae: 0.058712, r2: 0.673278, val_loss: 0.006992, val_mae: 0.058302, val_r2: 0.665123
2024-05-18 17:33:43 Epoch 4: lr=0.00028
2024-05-18 17:34:55 [Epoch: 4] loss: 0.006460, mae: 0.056852, r2: 0.691757, val_loss: 0.006593, val_mae: 0.057897, val_r2: 0.686555
2024-05-18 17:34:55 Epoch 5: lr=0.0001
2024-05-18 17:36:06 [Epoch: 5] loss: 0.006129, mae: 0.055368, r2: 0.707234, val_loss: 0.006437, val_mae: 0.056250, val_r2: 0.693630
2024-05-18 17:36:06 Epoch 6: lr=0.0001
2024-05-18 17:37:17 [Epoch: 6] loss: 0.006031, mae: 0.054876, r2: 0.711824, val_loss: 0.006373, val_mae: 0.056154, val_r2: 0.694664
2024-05-18 17:37:17 Epoch 7: lr=0.0001
2024-05-18 17:38:29 [Epoch: 7] loss: 0.005946, mae: 0.054530, r2: 0.715672, val_loss: 0.006364, val_mae: 0.055651, val_r2: 0.695952
2024-05-18 17:38:29 Epoch 8: lr=0.0001
2024-05-18 17:39:40 [Epoch: 8] loss: 0.005873, mae: 0.054203, r2: 0.718869, val_loss: 0.006323, val_mae: 0.055553, val_r2: 0.697080
2024-05-18 17:39:40 Epoch 9: lr=0.0001
2024-05-18 17:40:51 [Epoch: 9] loss: 0.005800, mae: 0.053858, r2: 0.722603, val_loss: 0.006304, val_mae: 0.055415, val_r2: 0.699990
2024-05-18 17:40:52 Epoch 10: lr=0.0001
2024-05-18 17:42:03 [Epoch: 10] loss: 0.005742, mae: 0.053644, r2: 0.725177, val_loss: 0.006267, val_mae: 0.055658, val_r2: 0.700428
2024-05-18 17:42:03 Epoch 11: lr=0.0001
2024-05-18 17:43:14 [Epoch: 11] loss: 0.005678, mae: 0.053336, r2: 0.728103, val_loss: 0.006243, val_mae: 0.055751, val_r2: 0.701716
2024-05-18 17:43:15 Epoch 12: lr=0.0001
2024-05-18 17:44:25 [Epoch: 12] loss: 0.005620, mae: 0.053091, r2: 0.730743, val_loss: 0.006226, val_mae: 0.055892, val_r2: 0.702411
2024-05-18 17:44:25 Epoch 13: lr=0.0001
2024-05-18 17:45:37 [Epoch: 13] loss: 0.005559, mae: 0.052806, r2: 0.733504, val_loss: 0.006223, val_mae: 0.055130, val_r2: 0.702070
2024-05-18 17:45:37 Epoch 14: lr=0.0001
2024-05-18 17:46:48 [Epoch: 14] loss: 0.005502, mae: 0.052549, r2: 0.736345, val_loss: 0.006242, val_mae: 0.056134, val_r2: 0.699106
2024-05-18 17:46:48 Epoch 15: lr=0.0001
2024-05-18 17:48:00 [Epoch: 15] loss: 0.005461, mae: 0.052338, r2: 0.738137, val_loss: 0.006198, val_mae: 0.054902, val_r2: 0.702624
2024-05-18 17:48:00 Epoch 16: lr=0.0001
2024-05-18 17:49:11 [Epoch: 16] loss: 0.005418, mae: 0.052142, r2: 0.740184, val_loss: 0.006164, val_mae: 0.054907, val_r2: 0.704599
2024-05-18 17:49:11 Epoch 17: lr=0.0001
2024-05-18 17:50:22 [Epoch: 17] loss: 0.005363, mae: 0.051897, r2: 0.742769, val_loss: 0.006144, val_mae: 0.055361, val_r2: 0.705144
2024-05-18 17:50:22 Epoch 18: lr=0.0001
2024-05-18 17:51:33 [Epoch: 18] loss: 0.005304, mae: 0.051646, r2: 0.745350, val_loss: 0.006139, val_mae: 0.054696, val_r2: 0.706419
2024-05-18 17:51:33 Epoch 19: lr=5e-05
2024-05-18 17:52:44 [Epoch: 19] loss: 0.005192, mae: 0.051094, r2: 0.750771, val_loss: 0.006114, val_mae: 0.054408, val_r2: 0.707694
2024-05-18 17:52:45 Epoch 20: lr=5e-05
2024-05-18 17:53:56 [Epoch: 20] loss: 0.005148, mae: 0.050893, r2: 0.752550, val_loss: 0.006119, val_mae: 0.054724, val_r2: 0.707122
2024-05-18 17:53:56 Epoch 21: lr=5e-05
2024-05-18 17:55:07 [Epoch: 21] loss: 0.005110, mae: 0.050755, r2: 0.754319, val_loss: 0.006106, val_mae: 0.054628, val_r2: 0.707810
2024-05-18 17:55:07 Epoch 22: lr=5e-05
2024-05-18 17:56:19 [Epoch: 22] loss: 0.005095, mae: 0.050597, r2: 0.755040, val_loss: 0.006134, val_mae: 0.054328, val_r2: 0.706195
2024-05-18 17:56:19 Epoch 23: lr=5e-05
2024-05-18 17:57:30 [Epoch: 23] loss: 0.005069, mae: 0.050518, r2: 0.756232, val_loss: 0.006096, val_mae: 0.054901, val_r2: 0.707836
2024-05-18 17:57:30 Epoch 24: lr=5e-05
2024-05-18 17:58:41 [Epoch: 24] loss: 0.005042, mae: 0.050398, r2: 0.757448, val_loss: 0.006120, val_mae: 0.054849, val_r2: 0.706042
2024-05-18 17:58:42 Epoch 25: lr=2.5e-05
2024-05-18 17:59:52 [Epoch: 25] loss: 0.004988, mae: 0.050117, r2: 0.760213, val_loss: 0.006120, val_mae: 0.054490, val_r2: 0.707288
2024-05-18 17:59:52 Epoch 26: lr=2.5e-05
2024-05-18 18:01:04 [Epoch: 26] loss: 0.004957, mae: 0.049992, r2: 0.761393, val_loss: 0.006138, val_mae: 0.054513, val_r2: 0.705630
2024-05-18 18:01:04 Epoch 27: lr=2.5e-05
2024-05-18 18:02:15 [Epoch: 27] loss: 0.004948, mae: 0.049947, r2: 0.761942, val_loss: 0.006111, val_mae: 0.054371, val_r2: 0.707146
2024-05-18 18:02:15 Epoch 28: lr=2.5e-05
2024-05-18 18:03:26 [Epoch: 28] loss: 0.004936, mae: 0.049881, r2: 0.762461, val_loss: 0.006104, val_mae: 0.054523, val_r2: 0.707507
2024-05-18 18:03:27 Epoch 29: lr=2.5e-05
2024-05-18 18:04:37 [Epoch: 29] loss: 0.004921, mae: 0.049803, r2: 0.763156, val_loss: 0.006095, val_mae: 0.054322, val_r2: 0.707816
2024-05-18 18:04:38 Epoch 30: lr=1.25e-05
2024-05-18 18:05:49 [Epoch: 30] loss: 0.004890, mae: 0.049664, r2: 0.764676, val_loss: 0.006097, val_mae: 0.054270, val_r2: 0.707650
2024-05-18 18:05:49 Epoch 31: lr=1.25e-05
2024-05-18 18:07:00 [Epoch: 31] loss: 0.004886, mae: 0.049660, r2: 0.765072, val_loss: 0.006103, val_mae: 0.054442, val_r2: 0.707566
2024-05-18 18:07:00 Epoch 32: lr=1.25e-05
2024-05-18 18:08:11 [Epoch: 32] loss: 0.004874, mae: 0.049532, r2: 0.765381, val_loss: 0.006106, val_mae: 0.054348, val_r2: 0.706701
2024-05-18 18:08:12 Epoch 33: lr=1.25e-05
2024-05-18 18:09:23 [Epoch: 33] loss: 0.004867, mae: 0.049536, r2: 0.765737, val_loss: 0.006099, val_mae: 0.054376, val_r2: 0.708093
2024-05-18 18:09:23 Epoch 34: lr=1.25e-05
2024-05-18 18:10:34 [Epoch: 34] loss: 0.004852, mae: 0.049494, r2: 0.766353, val_loss: 0.006096, val_mae: 0.054403, val_r2: 0.708543
2024-05-18 18:10:34 Epoch 35: lr=1e-05
2024-05-18 18:11:46 [Epoch: 35] loss: 0.004851, mae: 0.049472, r2: 0.766492, val_loss: 0.006117, val_mae: 0.054448, val_r2: 0.707360
2024-05-18 18:11:46 Epoch 36: lr=1e-05
2024-05-18 18:12:57 [Epoch: 36] loss: 0.004837, mae: 0.049421, r2: 0.766860, val_loss: 0.006101, val_mae: 0.054441, val_r2: 0.707281
2024-05-18 18:12:57 Epoch 37: lr=1e-05
2024-05-18 18:14:09 [Epoch: 37] loss: 0.004837, mae: 0.049409, r2: 0.767015, val_loss: 0.006079, val_mae: 0.054158, val_r2: 0.708864
2024-05-18 18:14:09 Epoch 38: lr=1e-05
2024-05-18 18:15:19 [Epoch: 38] loss: 0.004842, mae: 0.049421, r2: 0.767002, val_loss: 0.006137, val_mae: 0.054417, val_r2: 0.706637
2024-05-18 18:15:19 Epoch 39: lr=1e-05
2024-05-18 18:16:31 [Epoch: 39] loss: 0.004832, mae: 0.049383, r2: 0.767311, val_loss: 0.006098, val_mae: 0.054278, val_r2: 0.708207
2024-05-18 18:16:31 Epoch 40: lr=1e-05
2024-05-18 18:17:42 [Epoch: 40] loss: 0.004823, mae: 0.049326, r2: 0.767660, val_loss: 0.006088, val_mae: 0.054358, val_r2: 0.708114
2024-05-18 18:17:42 Epoch 41: lr=1e-05
2024-05-18 18:18:54 [Epoch: 41] loss: 0.004815, mae: 0.049278, r2: 0.768216, val_loss: 0.006077, val_mae: 0.054320, val_r2: 0.708151
2024-05-18 18:18:54 Epoch 42: lr=1e-05
2024-05-18 18:20:05 [Epoch: 42] loss: 0.004812, mae: 0.049285, r2: 0.768493, val_loss: 0.006076, val_mae: 0.054308, val_r2: 0.708704
2024-05-18 18:20:05 Epoch 43: lr=1e-05
2024-05-18 18:21:16 [Epoch: 43] loss: 0.004810, mae: 0.049271, r2: 0.768451, val_loss: 0.006112, val_mae: 0.054377, val_r2: 0.707186
2024-05-18 18:21:16 Epoch 44: lr=1e-05
2024-05-18 18:22:27 [Epoch: 44] loss: 0.004802, mae: 0.049248, r2: 0.768734, val_loss: 0.006106, val_mae: 0.054369, val_r2: 0.707974
2024-05-18 18:22:28 Epoch 45: lr=1e-05
2024-05-18 18:23:39 [Epoch: 45] loss: 0.004791, mae: 0.049178, r2: 0.769038, val_loss: 0.006110, val_mae: 0.054317, val_r2: 0.707101
2024-05-18 18:23:39 Epoch 46: lr=1e-05
2024-05-18 18:24:50 [Epoch: 46] loss: 0.004788, mae: 0.049213, r2: 0.769368, val_loss: 0.006076, val_mae: 0.054331, val_r2: 0.708851
2024-05-18 18:24:50 Epoch 47: lr=1e-05
2024-05-18 18:26:01 [Epoch: 47] loss: 0.004790, mae: 0.049161, r2: 0.769207, val_loss: 0.006108, val_mae: 0.054465, val_r2: 0.706735
2024-05-18 18:26:01 Epoch 48: lr=1e-05
2024-05-18 18:27:12 [Epoch: 48] loss: 0.004773, mae: 0.049110, r2: 0.770125, val_loss: 0.006105, val_mae: 0.054404, val_r2: 0.707200
2024-05-18 18:27:13 Epoch 49: lr=1e-05
2024-05-18 18:28:24 [Epoch: 49] loss: 0.004787, mae: 0.049162, r2: 0.769428, val_loss: 0.006104, val_mae: 0.054269, val_r2: 0.707312
2024-05-18 18:28:24 Epoch 50: lr=1e-05
2024-05-18 18:29:35 [Epoch: 50] loss: 0.004773, mae: 0.049101, r2: 0.769905, val_loss: 0.006098, val_mae: 0.054496, val_r2: 0.707702
2024-05-18 18:29:35 Epoch 51: lr=1e-05
2024-05-18 18:30:46 [Epoch: 51] loss: 0.004762, mae: 0.049046, r2: 0.770530, val_loss: 0.006092, val_mae: 0.054330, val_r2: 0.707451
2024-05-18 18:30:46 Epoch 52: lr=1e-05
2024-05-18 18:31:57 [Epoch: 52] loss: 0.004770, mae: 0.049055, r2: 0.770536, val_loss: 0.006087, val_mae: 0.054415, val_r2: 0.708562
2024-05-18 18:31:57 history_length: 53
2024-05-18 18:31:57 stopping: early
2024-05-18 18:31:57 Comparing y_true and y_pred:
2024-05-18 18:31:57   mse: 0.03173144
2024-05-18 18:31:57   mae: 0.14783640
2024-05-18 18:31:57   r2: -0.88061814
2024-05-18 18:31:57   corr: 0.38696659
