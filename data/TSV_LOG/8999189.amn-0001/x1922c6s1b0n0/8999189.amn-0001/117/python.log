2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/117', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '117', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/117/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/117', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s1b0n0.117.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/117/4.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/117'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x154c404c2ee0>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/117/4.1.model.h5
2024-05-18 17:28:55 Between random pairs in y_val:
2024-05-18 17:28:55   mse: 0.04766482
2024-05-18 17:28:55   mae: 0.16005999
2024-05-18 17:28:55   r2: -1.00413153
2024-05-18 17:28:55   corr: -0.00206577
2024-05-18 17:28:55 Data points per epoch: train = 469179, val = 117295, test = 1235
2024-05-18 17:28:55 Steps per epoch: train = 14661, val = 3665, test = 38
2024-05-18 17:28:55 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.032703, mae: 0.079913, r2: -0.904580, val_loss: 0.008588, val_mae: 0.066603, val_r2: 0.597087
2024-05-18 17:30:09 Epoch 1: lr=0.00082
2024-05-18 17:31:21 [Epoch: 1] loss: 0.008022, mae: 0.064040, r2: 0.620393, val_loss: 0.007677, val_mae: 0.063929, val_r2: 0.635646
2024-05-18 17:31:21 Epoch 2: lr=0.00064
2024-05-18 17:32:33 [Epoch: 2] loss: 0.007335, mae: 0.060920, r2: 0.652250, val_loss: 0.007127, val_mae: 0.059952, val_r2: 0.658757
2024-05-18 17:32:33 Epoch 3: lr=0.00046
2024-05-18 17:33:44 [Epoch: 3] loss: 0.006851, mae: 0.058754, r2: 0.674493, val_loss: 0.006829, val_mae: 0.058944, val_r2: 0.677415
2024-05-18 17:33:44 Epoch 4: lr=0.00028
2024-05-18 17:34:56 [Epoch: 4] loss: 0.006451, mae: 0.056919, r2: 0.692561, val_loss: 0.006560, val_mae: 0.057470, val_r2: 0.687873
2024-05-18 17:34:56 Epoch 5: lr=0.0001
2024-05-18 17:36:07 [Epoch: 5] loss: 0.006121, mae: 0.055381, r2: 0.707901, val_loss: 0.006376, val_mae: 0.056646, val_r2: 0.693899
2024-05-18 17:36:08 Epoch 6: lr=0.0001
2024-05-18 17:37:19 [Epoch: 6] loss: 0.006010, mae: 0.054853, r2: 0.712974, val_loss: 0.006320, val_mae: 0.056292, val_r2: 0.698260
2024-05-18 17:37:19 Epoch 7: lr=0.0001
2024-05-18 17:38:31 [Epoch: 7] loss: 0.005932, mae: 0.054508, r2: 0.716598, val_loss: 0.006293, val_mae: 0.055583, val_r2: 0.699105
2024-05-18 17:38:31 Epoch 8: lr=0.0001
2024-05-18 17:39:43 [Epoch: 8] loss: 0.005871, mae: 0.054260, r2: 0.719335, val_loss: 0.006260, val_mae: 0.055689, val_r2: 0.700480
2024-05-18 17:39:43 Epoch 9: lr=0.0001
2024-05-18 17:40:55 [Epoch: 9] loss: 0.005796, mae: 0.053907, r2: 0.722680, val_loss: 0.006250, val_mae: 0.055364, val_r2: 0.701560
2024-05-18 17:40:55 Epoch 10: lr=0.0001
2024-05-18 17:42:07 [Epoch: 10] loss: 0.005746, mae: 0.053634, r2: 0.725161, val_loss: 0.006222, val_mae: 0.056133, val_r2: 0.701436
2024-05-18 17:42:07 Epoch 11: lr=0.0001
2024-05-18 17:43:19 [Epoch: 11] loss: 0.005685, mae: 0.053423, r2: 0.727696, val_loss: 0.006205, val_mae: 0.055904, val_r2: 0.703337
2024-05-18 17:43:19 Epoch 12: lr=0.0001
2024-05-18 17:44:31 [Epoch: 12] loss: 0.005616, mae: 0.053094, r2: 0.731196, val_loss: 0.006195, val_mae: 0.055010, val_r2: 0.703343
2024-05-18 17:44:31 Epoch 13: lr=0.0001
2024-05-18 17:45:43 [Epoch: 13] loss: 0.005560, mae: 0.052802, r2: 0.733723, val_loss: 0.006177, val_mae: 0.054769, val_r2: 0.704505
2024-05-18 17:45:43 Epoch 14: lr=5e-05
2024-05-18 17:46:55 [Epoch: 14] loss: 0.005455, mae: 0.052294, r2: 0.738502, val_loss: 0.006103, val_mae: 0.055011, val_r2: 0.708651
2024-05-18 17:46:55 Epoch 15: lr=5e-05
2024-05-18 17:48:07 [Epoch: 15] loss: 0.005396, mae: 0.052038, r2: 0.741354, val_loss: 0.006133, val_mae: 0.054892, val_r2: 0.705584
2024-05-18 17:48:07 Epoch 16: lr=5e-05
2024-05-18 17:49:19 [Epoch: 16] loss: 0.005368, mae: 0.051905, r2: 0.742643, val_loss: 0.006113, val_mae: 0.054838, val_r2: 0.707601
2024-05-18 17:49:19 Epoch 17: lr=5e-05
2024-05-18 17:50:30 [Epoch: 17] loss: 0.005335, mae: 0.051777, r2: 0.744222, val_loss: 0.006110, val_mae: 0.054677, val_r2: 0.708174
2024-05-18 17:50:31 Epoch 18: lr=5e-05
2024-05-18 17:51:42 [Epoch: 18] loss: 0.005304, mae: 0.051615, r2: 0.745526, val_loss: 0.006136, val_mae: 0.054693, val_r2: 0.705739
2024-05-18 17:51:42 Epoch 19: lr=5e-05
2024-05-18 17:52:54 [Epoch: 19] loss: 0.005275, mae: 0.051517, r2: 0.746942, val_loss: 0.006126, val_mae: 0.054632, val_r2: 0.707349
2024-05-18 17:52:54 Epoch 20: lr=2.5e-05
2024-05-18 17:54:06 [Epoch: 20] loss: 0.005211, mae: 0.051175, r2: 0.749857, val_loss: 0.006096, val_mae: 0.054496, val_r2: 0.707950
2024-05-18 17:54:06 Epoch 21: lr=2.5e-05
2024-05-18 17:55:18 [Epoch: 21] loss: 0.005192, mae: 0.051101, r2: 0.750732, val_loss: 0.006090, val_mae: 0.054479, val_r2: 0.707623
2024-05-18 17:55:18 Epoch 22: lr=2.5e-05
2024-05-18 17:56:30 [Epoch: 22] loss: 0.005176, mae: 0.051035, r2: 0.751463, val_loss: 0.006098, val_mae: 0.054426, val_r2: 0.708088
2024-05-18 17:56:30 Epoch 23: lr=2.5e-05
2024-05-18 17:57:42 [Epoch: 23] loss: 0.005167, mae: 0.050969, r2: 0.751983, val_loss: 0.006079, val_mae: 0.054534, val_r2: 0.709109
2024-05-18 17:57:42 Epoch 24: lr=2.5e-05
2024-05-18 17:58:54 [Epoch: 24] loss: 0.005141, mae: 0.050860, r2: 0.753044, val_loss: 0.006085, val_mae: 0.054379, val_r2: 0.708998
2024-05-18 17:58:54 Epoch 25: lr=1.25e-05
2024-05-18 18:00:06 [Epoch: 25] loss: 0.005114, mae: 0.050737, r2: 0.754313, val_loss: 0.006091, val_mae: 0.054726, val_r2: 0.708378
2024-05-18 18:00:06 Epoch 26: lr=1.25e-05
2024-05-18 18:01:18 [Epoch: 26] loss: 0.005115, mae: 0.050745, r2: 0.754349, val_loss: 0.006092, val_mae: 0.054601, val_r2: 0.707909
2024-05-18 18:01:18 Epoch 27: lr=1.25e-05
2024-05-18 18:02:30 [Epoch: 27] loss: 0.005092, mae: 0.050606, r2: 0.755414, val_loss: 0.006075, val_mae: 0.054426, val_r2: 0.708631
2024-05-18 18:02:30 Epoch 28: lr=1.25e-05
2024-05-18 18:03:42 [Epoch: 28] loss: 0.005084, mae: 0.050588, r2: 0.755689, val_loss: 0.006092, val_mae: 0.054494, val_r2: 0.707857
2024-05-18 18:03:43 Epoch 29: lr=1.25e-05
2024-05-18 18:04:54 [Epoch: 29] loss: 0.005077, mae: 0.050555, r2: 0.756107, val_loss: 0.006103, val_mae: 0.054417, val_r2: 0.707249
2024-05-18 18:04:54 Epoch 30: lr=1e-05
2024-05-18 18:06:05 [Epoch: 30] loss: 0.005057, mae: 0.050469, r2: 0.756904, val_loss: 0.006089, val_mae: 0.054548, val_r2: 0.707879
2024-05-18 18:06:05 Epoch 31: lr=1e-05
2024-05-18 18:07:17 [Epoch: 31] loss: 0.005064, mae: 0.050477, r2: 0.756534, val_loss: 0.006092, val_mae: 0.054551, val_r2: 0.707638
2024-05-18 18:07:17 Epoch 32: lr=1e-05
2024-05-18 18:08:29 [Epoch: 32] loss: 0.005050, mae: 0.050421, r2: 0.757070, val_loss: 0.006086, val_mae: 0.054401, val_r2: 0.708071
2024-05-18 18:08:30 Epoch 33: lr=1e-05
2024-05-18 18:09:41 [Epoch: 33] loss: 0.005047, mae: 0.050440, r2: 0.757497, val_loss: 0.006073, val_mae: 0.054516, val_r2: 0.709019
2024-05-18 18:09:41 Epoch 34: lr=1e-05
2024-05-18 18:10:53 [Epoch: 34] loss: 0.005038, mae: 0.050407, r2: 0.757727, val_loss: 0.006098, val_mae: 0.054516, val_r2: 0.707546
2024-05-18 18:10:53 Epoch 35: lr=1e-05
2024-05-18 18:12:05 [Epoch: 35] loss: 0.005036, mae: 0.050388, r2: 0.757743, val_loss: 0.006067, val_mae: 0.054358, val_r2: 0.709710
2024-05-18 18:12:05 Epoch 36: lr=1e-05
2024-05-18 18:13:17 [Epoch: 36] loss: 0.005033, mae: 0.050343, r2: 0.758017, val_loss: 0.006080, val_mae: 0.054609, val_r2: 0.709544
2024-05-18 18:13:17 Epoch 37: lr=1e-05
2024-05-18 18:14:29 [Epoch: 37] loss: 0.005018, mae: 0.050295, r2: 0.758737, val_loss: 0.006085, val_mae: 0.054351, val_r2: 0.708483
2024-05-18 18:14:29 Epoch 38: lr=1e-05
2024-05-18 18:15:41 [Epoch: 38] loss: 0.005031, mae: 0.050339, r2: 0.757911, val_loss: 0.006095, val_mae: 0.054463, val_r2: 0.707866
2024-05-18 18:15:41 Epoch 39: lr=1e-05
2024-05-18 18:16:53 [Epoch: 39] loss: 0.005002, mae: 0.050223, r2: 0.759609, val_loss: 0.006088, val_mae: 0.054514, val_r2: 0.708335
2024-05-18 18:16:53 Epoch 40: lr=1e-05
2024-05-18 18:18:05 [Epoch: 40] loss: 0.005010, mae: 0.050206, r2: 0.759228, val_loss: 0.006081, val_mae: 0.054321, val_r2: 0.708597
2024-05-18 18:18:05 Epoch 41: lr=1e-05
2024-05-18 18:19:17 [Epoch: 41] loss: 0.005001, mae: 0.050202, r2: 0.759482, val_loss: 0.006098, val_mae: 0.054456, val_r2: 0.707754
2024-05-18 18:19:17 Epoch 42: lr=1e-05
2024-05-18 18:20:28 [Epoch: 42] loss: 0.004990, mae: 0.050157, r2: 0.760000, val_loss: 0.006068, val_mae: 0.054517, val_r2: 0.709590
2024-05-18 18:20:29 Epoch 43: lr=1e-05
2024-05-18 18:21:40 [Epoch: 43] loss: 0.004992, mae: 0.050125, r2: 0.759853, val_loss: 0.006058, val_mae: 0.054513, val_r2: 0.709296
2024-05-18 18:21:40 Epoch 44: lr=1e-05
2024-05-18 18:22:52 [Epoch: 44] loss: 0.004985, mae: 0.050119, r2: 0.760054, val_loss: 0.006094, val_mae: 0.054396, val_r2: 0.707826
2024-05-18 18:22:52 Epoch 45: lr=1e-05
2024-05-18 18:24:04 [Epoch: 45] loss: 0.004988, mae: 0.050156, r2: 0.759951, val_loss: 0.006087, val_mae: 0.054496, val_r2: 0.707995
2024-05-18 18:24:04 Epoch 46: lr=1e-05
2024-05-18 18:25:15 [Epoch: 46] loss: 0.004983, mae: 0.050111, r2: 0.760338, val_loss: 0.006088, val_mae: 0.054445, val_r2: 0.708069
2024-05-18 18:25:15 Epoch 47: lr=1e-05
2024-05-18 18:26:27 [Epoch: 47] loss: 0.004964, mae: 0.050026, r2: 0.761172, val_loss: 0.006075, val_mae: 0.054477, val_r2: 0.708399
2024-05-18 18:26:27 Epoch 48: lr=1e-05
2024-05-18 18:27:39 [Epoch: 48] loss: 0.004959, mae: 0.050008, r2: 0.761291, val_loss: 0.006105, val_mae: 0.054544, val_r2: 0.707450
2024-05-18 18:27:39 Epoch 49: lr=1e-05
2024-05-18 18:28:51 [Epoch: 49] loss: 0.004957, mae: 0.050014, r2: 0.761635, val_loss: 0.006094, val_mae: 0.054511, val_r2: 0.707742
2024-05-18 18:28:51 Epoch 50: lr=1e-05
2024-05-18 18:30:02 [Epoch: 50] loss: 0.004954, mae: 0.050007, r2: 0.761626, val_loss: 0.006079, val_mae: 0.054491, val_r2: 0.708736
2024-05-18 18:30:02 Epoch 51: lr=1e-05
2024-05-18 18:31:14 [Epoch: 51] loss: 0.004953, mae: 0.049975, r2: 0.761599, val_loss: 0.006052, val_mae: 0.054309, val_r2: 0.709691
2024-05-18 18:31:14 Epoch 52: lr=1e-05
2024-05-18 18:32:26 [Epoch: 52] loss: 0.004939, mae: 0.049906, r2: 0.762343, val_loss: 0.006081, val_mae: 0.054544, val_r2: 0.708110
2024-05-18 18:32:26 Epoch 53: lr=1e-05
2024-05-18 18:33:37 [Epoch: 53] loss: 0.004935, mae: 0.049886, r2: 0.762729, val_loss: 0.006055, val_mae: 0.054404, val_r2: 0.709641
2024-05-18 18:33:37 Epoch 54: lr=1e-05
2024-05-18 18:34:48 [Epoch: 54] loss: 0.004939, mae: 0.049893, r2: 0.762365, val_loss: 0.006067, val_mae: 0.054281, val_r2: 0.708918
2024-05-18 18:34:48 Epoch 55: lr=1e-05
2024-05-18 18:35:59 [Epoch: 55] loss: 0.004917, mae: 0.049823, r2: 0.763459, val_loss: 0.006114, val_mae: 0.054504, val_r2: 0.707065
2024-05-18 18:35:59 Epoch 56: lr=1e-05
2024-05-18 18:37:11 [Epoch: 56] loss: 0.004923, mae: 0.049818, r2: 0.763063, val_loss: 0.006094, val_mae: 0.054218, val_r2: 0.708404
2024-05-18 18:37:11 Epoch 57: lr=1e-05
2024-05-18 18:38:22 [Epoch: 57] loss: 0.004911, mae: 0.049753, r2: 0.763649, val_loss: 0.006091, val_mae: 0.054441, val_r2: 0.707871
2024-05-18 18:38:22 Epoch 58: lr=1e-05
2024-05-18 18:39:34 [Epoch: 58] loss: 0.004907, mae: 0.049792, r2: 0.763914, val_loss: 0.006097, val_mae: 0.054633, val_r2: 0.707329
2024-05-18 18:39:34 Epoch 59: lr=1e-05
2024-05-18 18:40:45 [Epoch: 59] loss: 0.004908, mae: 0.049750, r2: 0.763679, val_loss: 0.006072, val_mae: 0.054404, val_r2: 0.709029
2024-05-18 18:40:45 Epoch 60: lr=1e-05
2024-05-18 18:41:56 [Epoch: 60] loss: 0.004899, mae: 0.049748, r2: 0.764217, val_loss: 0.006108, val_mae: 0.054606, val_r2: 0.707000
2024-05-18 18:41:56 Epoch 61: lr=1e-05
2024-05-18 18:43:08 [Epoch: 61] loss: 0.004889, mae: 0.049695, r2: 0.764740, val_loss: 0.006098, val_mae: 0.054536, val_r2: 0.707281
2024-05-18 18:43:08 history_length: 62
2024-05-18 18:43:08 stopping: early
2024-05-18 18:43:08 Comparing y_true and y_pred:
2024-05-18 18:43:08   mse: 0.00632019
2024-05-18 18:43:08   mae: 0.05777712
2024-05-18 18:43:08   r2: -0.14032878
2024-05-18 18:43:08   corr: 0.05677046
