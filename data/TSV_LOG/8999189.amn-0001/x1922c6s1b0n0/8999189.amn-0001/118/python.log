2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/118', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '118', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/118/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/118', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s1b0n0.118.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/118/5.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/118'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x1525f7481820>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/118/5.0.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04822959
2024-05-18 17:28:57   mae: 0.16082546
2024-05-18 17:28:57   r2: -1.00345267
2024-05-18 17:28:57   corr: -0.00172633
2024-05-18 17:28:57 Data points per epoch: train = 469201, val = 117301, test = 1207
2024-05-18 17:28:57 Steps per epoch: train = 14662, val = 3665, test = 37
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:10 [Epoch: 0] loss: 0.029967, mae: 0.079642, r2: -0.829319, val_loss: 0.008834, val_mae: 0.066280, val_r2: 0.578523
2024-05-18 17:30:11 Epoch 1: lr=0.00082
2024-05-18 17:31:24 [Epoch: 1] loss: 0.008011, mae: 0.063964, r2: 0.619957, val_loss: 0.007802, val_mae: 0.063062, val_r2: 0.634960
2024-05-18 17:31:24 Epoch 2: lr=0.00064
2024-05-18 17:32:36 [Epoch: 2] loss: 0.007323, mae: 0.060899, r2: 0.651420, val_loss: 0.007280, val_mae: 0.060495, val_r2: 0.657292
2024-05-18 17:32:36 Epoch 3: lr=0.00046
2024-05-18 17:33:48 [Epoch: 3] loss: 0.006850, mae: 0.058705, r2: 0.673047, val_loss: 0.006990, val_mae: 0.058203, val_r2: 0.668212
2024-05-18 17:33:48 Epoch 4: lr=0.00028
2024-05-18 17:35:01 [Epoch: 4] loss: 0.006458, mae: 0.056926, r2: 0.690922, val_loss: 0.006722, val_mae: 0.057286, val_r2: 0.682206
2024-05-18 17:35:02 Epoch 5: lr=0.0001
2024-05-18 17:36:14 [Epoch: 5] loss: 0.006110, mae: 0.055333, r2: 0.707262, val_loss: 0.006508, val_mae: 0.056842, val_r2: 0.692174
2024-05-18 17:36:14 Epoch 6: lr=0.0001
2024-05-18 17:37:26 [Epoch: 6] loss: 0.006009, mae: 0.054888, r2: 0.711607, val_loss: 0.006467, val_mae: 0.056647, val_r2: 0.693517
2024-05-18 17:37:27 Epoch 7: lr=0.0001
2024-05-18 17:38:39 [Epoch: 7] loss: 0.005934, mae: 0.054527, r2: 0.715216, val_loss: 0.006470, val_mae: 0.056220, val_r2: 0.694117
2024-05-18 17:38:39 Epoch 8: lr=0.0001
2024-05-18 17:39:52 [Epoch: 8] loss: 0.005865, mae: 0.054235, r2: 0.718471, val_loss: 0.006421, val_mae: 0.055983, val_r2: 0.696527
2024-05-18 17:39:52 Epoch 9: lr=0.0001
2024-05-18 17:41:05 [Epoch: 9] loss: 0.005796, mae: 0.053915, r2: 0.721666, val_loss: 0.006399, val_mae: 0.056154, val_r2: 0.696717
2024-05-18 17:41:05 Epoch 10: lr=0.0001
2024-05-18 17:42:17 [Epoch: 10] loss: 0.005733, mae: 0.053607, r2: 0.724683, val_loss: 0.006373, val_mae: 0.055829, val_r2: 0.698679
2024-05-18 17:42:17 Epoch 11: lr=0.0001
2024-05-18 17:43:30 [Epoch: 11] loss: 0.005682, mae: 0.053379, r2: 0.727175, val_loss: 0.006369, val_mae: 0.055695, val_r2: 0.697890
2024-05-18 17:43:30 Epoch 12: lr=0.0001
2024-05-18 17:44:42 [Epoch: 12] loss: 0.005621, mae: 0.053116, r2: 0.729791, val_loss: 0.006318, val_mae: 0.055834, val_r2: 0.701289
2024-05-18 17:44:42 Epoch 13: lr=0.0001
2024-05-18 17:45:55 [Epoch: 13] loss: 0.005564, mae: 0.052850, r2: 0.732354, val_loss: 0.006361, val_mae: 0.055464, val_r2: 0.699728
2024-05-18 17:45:55 Epoch 14: lr=0.0001
2024-05-18 17:47:08 [Epoch: 14] loss: 0.005519, mae: 0.052633, r2: 0.734721, val_loss: 0.006273, val_mae: 0.055236, val_r2: 0.702998
2024-05-18 17:47:08 Epoch 15: lr=0.0001
2024-05-18 17:48:21 [Epoch: 15] loss: 0.005462, mae: 0.052387, r2: 0.737207, val_loss: 0.006300, val_mae: 0.055948, val_r2: 0.701266
2024-05-18 17:48:21 Epoch 16: lr=0.0001
2024-05-18 17:49:33 [Epoch: 16] loss: 0.005416, mae: 0.052152, r2: 0.739427, val_loss: 0.006305, val_mae: 0.055037, val_r2: 0.699883
2024-05-18 17:49:33 Epoch 17: lr=0.0001
2024-05-18 17:50:45 [Epoch: 17] loss: 0.005351, mae: 0.051877, r2: 0.742278, val_loss: 0.006259, val_mae: 0.055560, val_r2: 0.702164
2024-05-18 17:50:45 Epoch 18: lr=0.0001
2024-05-18 17:51:58 [Epoch: 18] loss: 0.005309, mae: 0.051668, r2: 0.744411, val_loss: 0.006212, val_mae: 0.055161, val_r2: 0.704703
2024-05-18 17:51:58 Epoch 19: lr=0.0001
2024-05-18 17:53:11 [Epoch: 19] loss: 0.005267, mae: 0.051457, r2: 0.746473, val_loss: 0.006203, val_mae: 0.055247, val_r2: 0.704862
2024-05-18 17:53:11 Epoch 20: lr=5e-05
2024-05-18 17:54:23 [Epoch: 20] loss: 0.005157, mae: 0.050958, r2: 0.751312, val_loss: 0.006206, val_mae: 0.055452, val_r2: 0.705431
2024-05-18 17:54:23 Epoch 21: lr=5e-05
2024-05-18 17:55:36 [Epoch: 21] loss: 0.005113, mae: 0.050714, r2: 0.753479, val_loss: 0.006207, val_mae: 0.054956, val_r2: 0.703990
2024-05-18 17:55:36 Epoch 22: lr=5e-05
2024-05-18 17:56:49 [Epoch: 22] loss: 0.005075, mae: 0.050510, r2: 0.755578, val_loss: 0.006235, val_mae: 0.054885, val_r2: 0.703514
2024-05-18 17:56:49 Epoch 23: lr=5e-05
2024-05-18 17:58:02 [Epoch: 23] loss: 0.005050, mae: 0.050427, r2: 0.756419, val_loss: 0.006200, val_mae: 0.054685, val_r2: 0.705706
2024-05-18 17:58:02 Epoch 24: lr=5e-05
2024-05-18 17:59:14 [Epoch: 24] loss: 0.005025, mae: 0.050335, r2: 0.757609, val_loss: 0.006229, val_mae: 0.054891, val_r2: 0.704123
2024-05-18 17:59:15 Epoch 25: lr=2.5e-05
2024-05-18 18:00:27 [Epoch: 25] loss: 0.004963, mae: 0.049976, r2: 0.760404, val_loss: 0.006209, val_mae: 0.054933, val_r2: 0.704740
2024-05-18 18:00:27 Epoch 26: lr=2.5e-05
2024-05-18 18:01:40 [Epoch: 26] loss: 0.004941, mae: 0.049917, r2: 0.761498, val_loss: 0.006203, val_mae: 0.055286, val_r2: 0.704226
2024-05-18 18:01:40 Epoch 27: lr=2.5e-05
2024-05-18 18:02:53 [Epoch: 27] loss: 0.004920, mae: 0.049824, r2: 0.762497, val_loss: 0.006206, val_mae: 0.054851, val_r2: 0.705055
2024-05-18 18:02:53 Epoch 28: lr=2.5e-05
2024-05-18 18:04:06 [Epoch: 28] loss: 0.004907, mae: 0.049762, r2: 0.763061, val_loss: 0.006195, val_mae: 0.055215, val_r2: 0.705262
2024-05-18 18:04:06 Epoch 29: lr=2.5e-05
2024-05-18 18:05:19 [Epoch: 29] loss: 0.004904, mae: 0.049736, r2: 0.762967, val_loss: 0.006166, val_mae: 0.054785, val_r2: 0.707449
2024-05-18 18:05:19 Epoch 30: lr=2.5e-05
2024-05-18 18:06:31 [Epoch: 30] loss: 0.004892, mae: 0.049653, r2: 0.763737, val_loss: 0.006181, val_mae: 0.054862, val_r2: 0.705913
2024-05-18 18:06:31 Epoch 31: lr=2.5e-05
2024-05-18 18:07:44 [Epoch: 31] loss: 0.004878, mae: 0.049595, r2: 0.764504, val_loss: 0.006195, val_mae: 0.054833, val_r2: 0.705003
2024-05-18 18:07:44 Epoch 32: lr=2.5e-05
2024-05-18 18:08:57 [Epoch: 32] loss: 0.004861, mae: 0.049546, r2: 0.765114, val_loss: 0.006211, val_mae: 0.054647, val_r2: 0.704067
2024-05-18 18:08:57 Epoch 33: lr=2.5e-05
2024-05-18 18:10:09 [Epoch: 33] loss: 0.004855, mae: 0.049464, r2: 0.765439, val_loss: 0.006181, val_mae: 0.054646, val_r2: 0.706159
2024-05-18 18:10:09 Epoch 34: lr=2.5e-05
2024-05-18 18:11:22 [Epoch: 34] loss: 0.004840, mae: 0.049425, r2: 0.766146, val_loss: 0.006175, val_mae: 0.054746, val_r2: 0.705872
2024-05-18 18:11:22 Epoch 35: lr=1.25e-05
2024-05-18 18:12:35 [Epoch: 35] loss: 0.004803, mae: 0.049261, r2: 0.767607, val_loss: 0.006167, val_mae: 0.054759, val_r2: 0.706495
2024-05-18 18:12:35 Epoch 36: lr=1.25e-05
2024-05-18 18:13:47 [Epoch: 36] loss: 0.004797, mae: 0.049235, r2: 0.768255, val_loss: 0.006189, val_mae: 0.054645, val_r2: 0.705057
2024-05-18 18:13:48 Epoch 37: lr=1.25e-05
2024-05-18 18:15:00 [Epoch: 37] loss: 0.004790, mae: 0.049176, r2: 0.768518, val_loss: 0.006171, val_mae: 0.054514, val_r2: 0.705969
2024-05-18 18:15:00 Epoch 38: lr=1.25e-05
2024-05-18 18:16:12 [Epoch: 38] loss: 0.004786, mae: 0.049183, r2: 0.768713, val_loss: 0.006188, val_mae: 0.054725, val_r2: 0.705112
2024-05-18 18:16:13 Epoch 39: lr=1.25e-05
2024-05-18 18:17:25 [Epoch: 39] loss: 0.004784, mae: 0.049122, r2: 0.768954, val_loss: 0.006152, val_mae: 0.054648, val_r2: 0.706653
2024-05-18 18:17:25 Epoch 40: lr=1e-05
2024-05-18 18:18:37 [Epoch: 40] loss: 0.004763, mae: 0.049041, r2: 0.769749, val_loss: 0.006171, val_mae: 0.054669, val_r2: 0.707071
2024-05-18 18:18:38 Epoch 41: lr=1e-05
2024-05-18 18:19:50 [Epoch: 41] loss: 0.004776, mae: 0.049123, r2: 0.769295, val_loss: 0.006206, val_mae: 0.054626, val_r2: 0.705106
2024-05-18 18:19:50 Epoch 42: lr=1e-05
2024-05-18 18:21:03 [Epoch: 42] loss: 0.004756, mae: 0.049000, r2: 0.770075, val_loss: 0.006180, val_mae: 0.054636, val_r2: 0.706370
2024-05-18 18:21:03 Epoch 43: lr=1e-05
2024-05-18 18:22:15 [Epoch: 43] loss: 0.004747, mae: 0.048973, r2: 0.770408, val_loss: 0.006196, val_mae: 0.054662, val_r2: 0.705461
2024-05-18 18:22:15 Epoch 44: lr=1e-05
2024-05-18 18:23:28 [Epoch: 44] loss: 0.004742, mae: 0.048970, r2: 0.770901, val_loss: 0.006161, val_mae: 0.054626, val_r2: 0.706798
2024-05-18 18:23:28 Epoch 45: lr=1e-05
2024-05-18 18:24:40 [Epoch: 45] loss: 0.004746, mae: 0.048949, r2: 0.770602, val_loss: 0.006180, val_mae: 0.054653, val_r2: 0.705833
2024-05-18 18:24:40 Epoch 46: lr=1e-05
2024-05-18 18:25:52 [Epoch: 46] loss: 0.004733, mae: 0.048893, r2: 0.771181, val_loss: 0.006192, val_mae: 0.054650, val_r2: 0.705178
2024-05-18 18:25:52 Epoch 47: lr=1e-05
2024-05-18 18:27:04 [Epoch: 47] loss: 0.004727, mae: 0.048874, r2: 0.771459, val_loss: 0.006199, val_mae: 0.054569, val_r2: 0.705128
2024-05-18 18:27:05 Epoch 48: lr=1e-05
2024-05-18 18:28:17 [Epoch: 48] loss: 0.004729, mae: 0.048876, r2: 0.771474, val_loss: 0.006197, val_mae: 0.054701, val_r2: 0.705132
2024-05-18 18:28:17 Epoch 49: lr=1e-05
2024-05-18 18:29:29 [Epoch: 49] loss: 0.004724, mae: 0.048857, r2: 0.771448, val_loss: 0.006178, val_mae: 0.054544, val_r2: 0.706118
2024-05-18 18:29:30 history_length: 50
2024-05-18 18:29:30 stopping: early
2024-05-18 18:29:30 Comparing y_true and y_pred:
2024-05-18 18:29:30   mse: 0.00842303
2024-05-18 18:29:30   mae: 0.07607779
2024-05-18 18:29:30   r2: -0.05289020
2024-05-18 18:29:30   corr: 0.55540098
