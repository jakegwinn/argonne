2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/36', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '36', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/36/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/36', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c2s7b0n0.36.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/36/0.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/36'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x1483c32adb80>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/36/0.0.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04800105
2024-05-18 17:28:57   mae: 0.16031136
2024-05-18 17:28:57   r2: -1.00020772
2024-05-18 17:28:57   corr: -0.00010386
2024-05-18 17:28:57 Data points per epoch: train = 468344, val = 117086, test = 2279
2024-05-18 17:28:57 Steps per epoch: train = 14635, val = 3658, test = 71
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:10 [Epoch: 0] loss: 0.033411, mae: 0.079549, r2: -0.224516, val_loss: 0.008358, val_mae: 0.065059, val_r2: 0.606442
2024-05-18 17:30:10 Epoch 1: lr=0.00082
2024-05-18 17:31:22 [Epoch: 1] loss: 0.008000, mae: 0.063968, r2: 0.621604, val_loss: 0.007806, val_mae: 0.061820, val_r2: 0.627504
2024-05-18 17:31:22 Epoch 2: lr=0.00064
2024-05-18 17:32:33 [Epoch: 2] loss: 0.007301, mae: 0.060775, r2: 0.653366, val_loss: 0.007282, val_mae: 0.059566, val_r2: 0.657401
2024-05-18 17:32:33 Epoch 3: lr=0.00046
2024-05-18 17:33:45 [Epoch: 3] loss: 0.006848, mae: 0.058690, r2: 0.674227, val_loss: 0.006944, val_mae: 0.058313, val_r2: 0.666716
2024-05-18 17:33:45 Epoch 4: lr=0.00028
2024-05-18 17:34:57 [Epoch: 4] loss: 0.006435, mae: 0.056835, r2: 0.693175, val_loss: 0.006721, val_mae: 0.058944, val_r2: 0.679844
2024-05-18 17:34:57 Epoch 5: lr=0.0001
2024-05-18 17:36:08 [Epoch: 5] loss: 0.006116, mae: 0.055346, r2: 0.707869, val_loss: 0.006463, val_mae: 0.056899, val_r2: 0.691720
2024-05-18 17:36:08 Epoch 6: lr=0.0001
2024-05-18 17:37:20 [Epoch: 6] loss: 0.006011, mae: 0.054842, r2: 0.712819, val_loss: 0.006427, val_mae: 0.056683, val_r2: 0.694961
2024-05-18 17:37:20 Epoch 7: lr=0.0001
2024-05-18 17:38:31 [Epoch: 7] loss: 0.005925, mae: 0.054453, r2: 0.716685, val_loss: 0.006369, val_mae: 0.056043, val_r2: 0.696725
2024-05-18 17:38:31 Epoch 8: lr=0.0001
2024-05-18 17:39:43 [Epoch: 8] loss: 0.005864, mae: 0.054222, r2: 0.719564, val_loss: 0.006336, val_mae: 0.056222, val_r2: 0.698075
2024-05-18 17:39:43 Epoch 9: lr=0.0001
2024-05-18 17:40:54 [Epoch: 9] loss: 0.005790, mae: 0.053860, r2: 0.722964, val_loss: 0.006295, val_mae: 0.056158, val_r2: 0.699639
2024-05-18 17:40:54 Epoch 10: lr=0.0001
2024-05-18 17:42:06 [Epoch: 10] loss: 0.005716, mae: 0.053554, r2: 0.726603, val_loss: 0.006309, val_mae: 0.055767, val_r2: 0.698883
2024-05-18 17:42:06 Epoch 11: lr=0.0001
2024-05-18 17:43:18 [Epoch: 11] loss: 0.005667, mae: 0.053281, r2: 0.728831, val_loss: 0.006280, val_mae: 0.055509, val_r2: 0.701921
2024-05-18 17:43:18 Epoch 12: lr=0.0001
2024-05-18 17:44:29 [Epoch: 12] loss: 0.005615, mae: 0.053026, r2: 0.731272, val_loss: 0.006248, val_mae: 0.055395, val_r2: 0.702310
2024-05-18 17:44:29 Epoch 13: lr=0.0001
2024-05-18 17:45:41 [Epoch: 13] loss: 0.005551, mae: 0.052779, r2: 0.734424, val_loss: 0.006252, val_mae: 0.056035, val_r2: 0.701867
2024-05-18 17:45:41 Epoch 14: lr=5e-05
2024-05-18 17:46:52 [Epoch: 14] loss: 0.005441, mae: 0.052275, r2: 0.739401, val_loss: 0.006203, val_mae: 0.055307, val_r2: 0.703913
2024-05-18 17:46:52 Epoch 15: lr=5e-05
2024-05-18 17:48:04 [Epoch: 15] loss: 0.005398, mae: 0.052034, r2: 0.741366, val_loss: 0.006206, val_mae: 0.055631, val_r2: 0.703771
2024-05-18 17:48:04 Epoch 16: lr=5e-05
2024-05-18 17:49:16 [Epoch: 16] loss: 0.005359, mae: 0.051905, r2: 0.743238, val_loss: 0.006178, val_mae: 0.054875, val_r2: 0.705106
2024-05-18 17:49:16 Epoch 17: lr=5e-05
2024-05-18 17:50:27 [Epoch: 17] loss: 0.005327, mae: 0.051724, r2: 0.744751, val_loss: 0.006152, val_mae: 0.054938, val_r2: 0.707177
2024-05-18 17:50:27 Epoch 18: lr=5e-05
2024-05-18 17:51:39 [Epoch: 18] loss: 0.005302, mae: 0.051614, r2: 0.745943, val_loss: 0.006138, val_mae: 0.054838, val_r2: 0.707353
2024-05-18 17:51:39 Epoch 19: lr=5e-05
2024-05-18 17:52:50 [Epoch: 19] loss: 0.005273, mae: 0.051498, r2: 0.747051, val_loss: 0.006179, val_mae: 0.054504, val_r2: 0.704959
2024-05-18 17:52:51 Epoch 20: lr=2.5e-05
2024-05-18 17:54:02 [Epoch: 20] loss: 0.005218, mae: 0.051201, r2: 0.749777, val_loss: 0.006164, val_mae: 0.055264, val_r2: 0.705413
2024-05-18 17:54:02 Epoch 21: lr=2.5e-05
2024-05-18 17:55:14 [Epoch: 21] loss: 0.005188, mae: 0.051046, r2: 0.751382, val_loss: 0.006151, val_mae: 0.054715, val_r2: 0.706515
2024-05-18 17:55:14 Epoch 22: lr=2.5e-05
2024-05-18 17:56:25 [Epoch: 22] loss: 0.005182, mae: 0.051032, r2: 0.751466, val_loss: 0.006165, val_mae: 0.054541, val_r2: 0.707022
2024-05-18 17:56:25 Epoch 23: lr=2.5e-05
2024-05-18 17:57:37 [Epoch: 23] loss: 0.005167, mae: 0.051001, r2: 0.751967, val_loss: 0.006130, val_mae: 0.054524, val_r2: 0.708077
2024-05-18 17:57:37 Epoch 24: lr=2.5e-05
2024-05-18 17:58:48 [Epoch: 24] loss: 0.005138, mae: 0.050866, r2: 0.753315, val_loss: 0.006147, val_mae: 0.054800, val_r2: 0.706835
2024-05-18 17:58:48 Epoch 25: lr=1.25e-05
2024-05-18 18:00:00 [Epoch: 25] loss: 0.005110, mae: 0.050740, r2: 0.754802, val_loss: 0.006137, val_mae: 0.054819, val_r2: 0.707166
2024-05-18 18:00:00 Epoch 26: lr=1.25e-05
2024-05-18 18:01:12 [Epoch: 26] loss: 0.005101, mae: 0.050655, r2: 0.755239, val_loss: 0.006137, val_mae: 0.054714, val_r2: 0.707046
2024-05-18 18:01:12 Epoch 27: lr=1.25e-05
2024-05-18 18:02:23 [Epoch: 27] loss: 0.005095, mae: 0.050614, r2: 0.755625, val_loss: 0.006138, val_mae: 0.054627, val_r2: 0.707493
2024-05-18 18:02:23 Epoch 28: lr=1.25e-05
2024-05-18 18:03:35 [Epoch: 28] loss: 0.005086, mae: 0.050594, r2: 0.755831, val_loss: 0.006157, val_mae: 0.054677, val_r2: 0.706873
2024-05-18 18:03:35 Epoch 29: lr=1.25e-05
2024-05-18 18:04:47 [Epoch: 29] loss: 0.005079, mae: 0.050568, r2: 0.756234, val_loss: 0.006127, val_mae: 0.054630, val_r2: 0.707501
2024-05-18 18:04:47 Epoch 30: lr=1e-05
2024-05-18 18:05:58 [Epoch: 30] loss: 0.005058, mae: 0.050470, r2: 0.757213, val_loss: 0.006157, val_mae: 0.054544, val_r2: 0.705625
2024-05-18 18:05:58 Epoch 31: lr=1e-05
2024-05-18 18:07:10 [Epoch: 31] loss: 0.005059, mae: 0.050446, r2: 0.757156, val_loss: 0.006157, val_mae: 0.054611, val_r2: 0.706250
2024-05-18 18:07:10 Epoch 32: lr=1e-05
2024-05-18 18:08:21 [Epoch: 32] loss: 0.005048, mae: 0.050398, r2: 0.757568, val_loss: 0.006150, val_mae: 0.054905, val_r2: 0.706646
2024-05-18 18:08:21 Epoch 33: lr=1e-05
2024-05-18 18:09:33 [Epoch: 33] loss: 0.005040, mae: 0.050368, r2: 0.757746, val_loss: 0.006129, val_mae: 0.054601, val_r2: 0.707425
2024-05-18 18:09:33 Epoch 34: lr=1e-05
2024-05-18 18:10:44 [Epoch: 34] loss: 0.005039, mae: 0.050333, r2: 0.758118, val_loss: 0.006108, val_mae: 0.054589, val_r2: 0.708619
2024-05-18 18:10:45 Epoch 35: lr=1e-05
2024-05-18 18:11:56 [Epoch: 35] loss: 0.005040, mae: 0.050349, r2: 0.758179, val_loss: 0.006136, val_mae: 0.054800, val_r2: 0.707352
2024-05-18 18:11:56 Epoch 36: lr=1e-05
2024-05-18 18:13:08 [Epoch: 36] loss: 0.005028, mae: 0.050304, r2: 0.758490, val_loss: 0.006130, val_mae: 0.054680, val_r2: 0.707004
2024-05-18 18:13:08 Epoch 37: lr=1e-05
2024-05-18 18:14:19 [Epoch: 37] loss: 0.005032, mae: 0.050326, r2: 0.758415, val_loss: 0.006136, val_mae: 0.054573, val_r2: 0.707336
2024-05-18 18:14:19 Epoch 38: lr=1e-05
2024-05-18 18:15:30 [Epoch: 38] loss: 0.005014, mae: 0.050250, r2: 0.759429, val_loss: 0.006123, val_mae: 0.054635, val_r2: 0.707733
2024-05-18 18:15:31 Epoch 39: lr=1e-05
2024-05-18 18:16:42 [Epoch: 39] loss: 0.005021, mae: 0.050277, r2: 0.759122, val_loss: 0.006142, val_mae: 0.054630, val_r2: 0.706869
2024-05-18 18:16:42 Epoch 40: lr=1e-05
2024-05-18 18:17:53 [Epoch: 40] loss: 0.004994, mae: 0.050172, r2: 0.760106, val_loss: 0.006106, val_mae: 0.054457, val_r2: 0.708868
2024-05-18 18:17:53 Epoch 41: lr=1e-05
2024-05-18 18:19:04 [Epoch: 41] loss: 0.005012, mae: 0.050220, r2: 0.759365, val_loss: 0.006137, val_mae: 0.054660, val_r2: 0.706558
2024-05-18 18:19:04 Epoch 42: lr=1e-05
2024-05-18 18:20:15 [Epoch: 42] loss: 0.004987, mae: 0.050128, r2: 0.760500, val_loss: 0.006163, val_mae: 0.054775, val_r2: 0.706174
2024-05-18 18:20:15 Epoch 43: lr=1e-05
2024-05-18 18:21:26 [Epoch: 43] loss: 0.004982, mae: 0.050079, r2: 0.760861, val_loss: 0.006138, val_mae: 0.054751, val_r2: 0.707014
2024-05-18 18:21:26 Epoch 44: lr=1e-05
2024-05-18 18:22:37 [Epoch: 44] loss: 0.004973, mae: 0.050044, r2: 0.761239, val_loss: 0.006157, val_mae: 0.054695, val_r2: 0.706308
2024-05-18 18:22:37 Epoch 45: lr=1e-05
2024-05-18 18:23:48 [Epoch: 45] loss: 0.004987, mae: 0.050124, r2: 0.760635, val_loss: 0.006150, val_mae: 0.054649, val_r2: 0.706159
2024-05-18 18:23:48 Epoch 46: lr=1e-05
2024-05-18 18:24:59 [Epoch: 46] loss: 0.004974, mae: 0.050028, r2: 0.760910, val_loss: 0.006125, val_mae: 0.054475, val_r2: 0.707602
2024-05-18 18:24:59 Epoch 47: lr=1e-05
2024-05-18 18:26:10 [Epoch: 47] loss: 0.004959, mae: 0.049970, r2: 0.761839, val_loss: 0.006107, val_mae: 0.054479, val_r2: 0.708210
2024-05-18 18:26:10 Epoch 48: lr=1e-05
2024-05-18 18:27:20 [Epoch: 48] loss: 0.004956, mae: 0.049965, r2: 0.761862, val_loss: 0.006154, val_mae: 0.054733, val_r2: 0.706362
2024-05-18 18:27:20 Epoch 49: lr=1e-05
2024-05-18 18:28:30 [Epoch: 49] loss: 0.004957, mae: 0.049999, r2: 0.761901, val_loss: 0.006132, val_mae: 0.054458, val_r2: 0.707651
2024-05-18 18:28:31 Epoch 50: lr=1e-05
2024-05-18 18:29:41 [Epoch: 50] loss: 0.004960, mae: 0.049985, r2: 0.761650, val_loss: 0.006147, val_mae: 0.054545, val_r2: 0.706423
2024-05-18 18:29:41 history_length: 51
2024-05-18 18:29:41 stopping: early
2024-05-18 18:29:41 Comparing y_true and y_pred:
2024-05-18 18:29:41   mse: 0.00836783
2024-05-18 18:29:41   mae: 0.07224399
2024-05-18 18:29:41   r2: -0.07565338
2024-05-18 18:29:41   corr: 0.19788439
