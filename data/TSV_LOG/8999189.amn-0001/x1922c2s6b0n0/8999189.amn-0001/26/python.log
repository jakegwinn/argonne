2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/26', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '26', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/26/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/26', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c2s6b0n0.26.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/26/1.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/26'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x1488380fefd0>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/26/1.0.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04746575
2024-05-18 17:28:57   mae: 0.15958103
2024-05-18 17:28:57   r2: -1.00053676
2024-05-18 17:28:57   corr: -0.00026838
2024-05-18 17:28:57 Data points per epoch: train = 466697, val = 116675, test = 4337
2024-05-18 17:28:57 Steps per epoch: train = 14584, val = 3646, test = 135
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:10 [Epoch: 0] loss: 0.024616, mae: 0.079343, r2: -0.188008, val_loss: 0.008351, val_mae: 0.065608, val_r2: 0.604118
2024-05-18 17:30:10 Epoch 1: lr=0.00082
2024-05-18 17:31:21 [Epoch: 1] loss: 0.007986, mae: 0.063809, r2: 0.621741, val_loss: 0.007509, val_mae: 0.061283, val_r2: 0.641184
2024-05-18 17:31:21 Epoch 2: lr=0.00064
2024-05-18 17:32:32 [Epoch: 2] loss: 0.007339, mae: 0.060868, r2: 0.651719, val_loss: 0.007171, val_mae: 0.059988, val_r2: 0.655232
2024-05-18 17:32:32 Epoch 3: lr=0.00046
2024-05-18 17:33:43 [Epoch: 3] loss: 0.006874, mae: 0.058727, r2: 0.672942, val_loss: 0.006857, val_mae: 0.058842, val_r2: 0.672448
2024-05-18 17:33:43 Epoch 4: lr=0.00028
2024-05-18 17:34:54 [Epoch: 4] loss: 0.006469, mae: 0.056885, r2: 0.691498, val_loss: 0.006548, val_mae: 0.057486, val_r2: 0.684270
2024-05-18 17:34:54 Epoch 5: lr=0.0001
2024-05-18 17:36:05 [Epoch: 5] loss: 0.006142, mae: 0.055389, r2: 0.706529, val_loss: 0.006402, val_mae: 0.055986, val_r2: 0.691388
2024-05-18 17:36:05 Epoch 6: lr=0.0001
2024-05-18 17:37:15 [Epoch: 6] loss: 0.006023, mae: 0.054841, r2: 0.712023, val_loss: 0.006336, val_mae: 0.056049, val_r2: 0.695156
2024-05-18 17:37:15 Epoch 7: lr=0.0001
2024-05-18 17:38:27 [Epoch: 7] loss: 0.005946, mae: 0.054467, r2: 0.715393, val_loss: 0.006328, val_mae: 0.057051, val_r2: 0.693691
2024-05-18 17:38:27 Epoch 8: lr=0.0001
2024-05-18 17:39:38 [Epoch: 8] loss: 0.005880, mae: 0.054173, r2: 0.718384, val_loss: 0.006260, val_mae: 0.055509, val_r2: 0.697528
2024-05-18 17:39:38 Epoch 9: lr=0.0001
2024-05-18 17:40:49 [Epoch: 9] loss: 0.005807, mae: 0.053831, r2: 0.721874, val_loss: 0.006231, val_mae: 0.056310, val_r2: 0.698087
2024-05-18 17:40:50 Epoch 10: lr=0.0001
2024-05-18 17:42:01 [Epoch: 10] loss: 0.005750, mae: 0.053616, r2: 0.724497, val_loss: 0.006246, val_mae: 0.055164, val_r2: 0.697177
2024-05-18 17:42:01 Epoch 11: lr=0.0001
2024-05-18 17:43:12 [Epoch: 11] loss: 0.005687, mae: 0.053302, r2: 0.727410, val_loss: 0.006217, val_mae: 0.055029, val_r2: 0.698486
2024-05-18 17:43:12 Epoch 12: lr=0.0001
2024-05-18 17:44:23 [Epoch: 12] loss: 0.005630, mae: 0.053032, r2: 0.729833, val_loss: 0.006167, val_mae: 0.054828, val_r2: 0.701658
2024-05-18 17:44:23 Epoch 13: lr=0.0001
2024-05-18 17:45:34 [Epoch: 13] loss: 0.005577, mae: 0.052825, r2: 0.732473, val_loss: 0.006146, val_mae: 0.054940, val_r2: 0.703140
2024-05-18 17:45:34 Epoch 14: lr=0.0001
2024-05-18 17:46:45 [Epoch: 14] loss: 0.005520, mae: 0.052556, r2: 0.735215, val_loss: 0.006137, val_mae: 0.054676, val_r2: 0.704419
2024-05-18 17:46:45 Epoch 15: lr=0.0001
2024-05-18 17:47:55 [Epoch: 15] loss: 0.005471, mae: 0.052320, r2: 0.737382, val_loss: 0.006073, val_mae: 0.054610, val_r2: 0.706628
2024-05-18 17:47:55 Epoch 16: lr=0.0001
2024-05-18 17:49:06 [Epoch: 16] loss: 0.005418, mae: 0.052090, r2: 0.740136, val_loss: 0.006069, val_mae: 0.055012, val_r2: 0.707067
2024-05-18 17:49:06 Epoch 17: lr=0.0001
2024-05-18 17:50:17 [Epoch: 17] loss: 0.005377, mae: 0.051869, r2: 0.741921, val_loss: 0.006115, val_mae: 0.054344, val_r2: 0.704740
2024-05-18 17:50:18 Epoch 18: lr=0.0001
2024-05-18 17:51:29 [Epoch: 18] loss: 0.005320, mae: 0.051625, r2: 0.744446, val_loss: 0.006084, val_mae: 0.054422, val_r2: 0.705836
2024-05-18 17:51:29 Epoch 19: lr=5e-05
2024-05-18 17:52:40 [Epoch: 19] loss: 0.005210, mae: 0.051047, r2: 0.749662, val_loss: 0.006049, val_mae: 0.054446, val_r2: 0.707394
2024-05-18 17:52:40 Epoch 20: lr=5e-05
2024-05-18 17:53:51 [Epoch: 20] loss: 0.005172, mae: 0.050901, r2: 0.751390, val_loss: 0.006011, val_mae: 0.054380, val_r2: 0.709274
2024-05-18 17:53:51 Epoch 21: lr=5e-05
2024-05-18 17:55:02 [Epoch: 21] loss: 0.005140, mae: 0.050720, r2: 0.752760, val_loss: 0.006010, val_mae: 0.054016, val_r2: 0.709736
2024-05-18 17:55:02 Epoch 22: lr=5e-05
2024-05-18 17:56:13 [Epoch: 22] loss: 0.005110, mae: 0.050631, r2: 0.754335, val_loss: 0.006044, val_mae: 0.054235, val_r2: 0.707603
2024-05-18 17:56:13 Epoch 23: lr=5e-05
2024-05-18 17:57:24 [Epoch: 23] loss: 0.005080, mae: 0.050483, r2: 0.755667, val_loss: 0.006021, val_mae: 0.054200, val_r2: 0.708156
2024-05-18 17:57:25 Epoch 24: lr=5e-05
2024-05-18 17:58:35 [Epoch: 24] loss: 0.005062, mae: 0.050400, r2: 0.756663, val_loss: 0.006036, val_mae: 0.054539, val_r2: 0.707684
2024-05-18 17:58:35 Epoch 25: lr=5e-05
2024-05-18 17:59:46 [Epoch: 25] loss: 0.005042, mae: 0.050262, r2: 0.757468, val_loss: 0.006011, val_mae: 0.054125, val_r2: 0.708995
2024-05-18 17:59:46 Epoch 26: lr=2.5e-05
2024-05-18 18:00:57 [Epoch: 26] loss: 0.004969, mae: 0.049937, r2: 0.760818, val_loss: 0.006022, val_mae: 0.054141, val_r2: 0.708394
2024-05-18 18:00:57 Epoch 27: lr=2.5e-05
2024-05-18 18:02:09 [Epoch: 27] loss: 0.004952, mae: 0.049859, r2: 0.761441, val_loss: 0.006020, val_mae: 0.054171, val_r2: 0.708747
2024-05-18 18:02:09 Epoch 28: lr=2.5e-05
2024-05-18 18:03:20 [Epoch: 28] loss: 0.004956, mae: 0.049849, r2: 0.761517, val_loss: 0.006032, val_mae: 0.053965, val_r2: 0.708812
2024-05-18 18:03:20 Epoch 29: lr=2.5e-05
2024-05-18 18:04:31 [Epoch: 29] loss: 0.004931, mae: 0.049770, r2: 0.762496, val_loss: 0.006027, val_mae: 0.054207, val_r2: 0.708781
2024-05-18 18:04:31 Epoch 30: lr=2.5e-05
2024-05-18 18:05:42 [Epoch: 30] loss: 0.004925, mae: 0.049720, r2: 0.762891, val_loss: 0.006005, val_mae: 0.054175, val_r2: 0.709219
2024-05-18 18:05:42 Epoch 31: lr=1.25e-05
2024-05-18 18:06:53 [Epoch: 31] loss: 0.004887, mae: 0.049547, r2: 0.764445, val_loss: 0.006007, val_mae: 0.053965, val_r2: 0.709805
2024-05-18 18:06:53 Epoch 32: lr=1.25e-05
2024-05-18 18:08:04 [Epoch: 32] loss: 0.004883, mae: 0.049497, r2: 0.764772, val_loss: 0.005997, val_mae: 0.054057, val_r2: 0.709584
2024-05-18 18:08:04 Epoch 33: lr=1.25e-05
2024-05-18 18:09:15 [Epoch: 33] loss: 0.004864, mae: 0.049424, r2: 0.765585, val_loss: 0.005992, val_mae: 0.054087, val_r2: 0.709394
2024-05-18 18:09:15 Epoch 34: lr=1.25e-05
2024-05-18 18:10:26 [Epoch: 34] loss: 0.004860, mae: 0.049400, r2: 0.765829, val_loss: 0.006003, val_mae: 0.054055, val_r2: 0.709318
2024-05-18 18:10:26 Epoch 35: lr=1.25e-05
2024-05-18 18:11:37 [Epoch: 35] loss: 0.004845, mae: 0.049311, r2: 0.766674, val_loss: 0.006006, val_mae: 0.053978, val_r2: 0.708984
2024-05-18 18:11:37 Epoch 36: lr=1e-05
2024-05-18 18:12:48 [Epoch: 36] loss: 0.004840, mae: 0.049313, r2: 0.766743, val_loss: 0.006026, val_mae: 0.054112, val_r2: 0.708278
2024-05-18 18:12:48 Epoch 37: lr=1e-05
2024-05-18 18:13:59 [Epoch: 37] loss: 0.004838, mae: 0.049292, r2: 0.766621, val_loss: 0.006036, val_mae: 0.054095, val_r2: 0.707542
2024-05-18 18:13:59 Epoch 38: lr=1e-05
2024-05-18 18:15:10 [Epoch: 38] loss: 0.004829, mae: 0.049246, r2: 0.767279, val_loss: 0.006030, val_mae: 0.053963, val_r2: 0.708115
2024-05-18 18:15:10 Epoch 39: lr=1e-05
2024-05-18 18:16:21 [Epoch: 39] loss: 0.004819, mae: 0.049222, r2: 0.767652, val_loss: 0.006023, val_mae: 0.054157, val_r2: 0.707996
2024-05-18 18:16:21 Epoch 40: lr=1e-05
2024-05-18 18:17:32 [Epoch: 40] loss: 0.004824, mae: 0.049225, r2: 0.767503, val_loss: 0.005988, val_mae: 0.053914, val_r2: 0.710409
2024-05-18 18:17:32 Epoch 41: lr=1e-05
2024-05-18 18:18:43 [Epoch: 41] loss: 0.004813, mae: 0.049185, r2: 0.767784, val_loss: 0.005996, val_mae: 0.053975, val_r2: 0.709772
2024-05-18 18:18:43 Epoch 42: lr=1e-05
2024-05-18 18:19:54 [Epoch: 42] loss: 0.004804, mae: 0.049125, r2: 0.768180, val_loss: 0.006009, val_mae: 0.054113, val_r2: 0.708857
2024-05-18 18:19:55 Epoch 43: lr=1e-05
2024-05-18 18:21:05 [Epoch: 43] loss: 0.004807, mae: 0.049158, r2: 0.768427, val_loss: 0.005998, val_mae: 0.053926, val_r2: 0.709552
2024-05-18 18:21:05 Epoch 44: lr=1e-05
2024-05-18 18:22:16 [Epoch: 44] loss: 0.004803, mae: 0.049124, r2: 0.768631, val_loss: 0.006014, val_mae: 0.053992, val_r2: 0.709346
2024-05-18 18:22:16 Epoch 45: lr=1e-05
2024-05-18 18:23:27 [Epoch: 45] loss: 0.004799, mae: 0.049118, r2: 0.768870, val_loss: 0.006009, val_mae: 0.054064, val_r2: 0.709474
2024-05-18 18:23:27 Epoch 46: lr=1e-05
2024-05-18 18:24:38 [Epoch: 46] loss: 0.004797, mae: 0.049110, r2: 0.768822, val_loss: 0.006018, val_mae: 0.054023, val_r2: 0.709089
2024-05-18 18:24:38 Epoch 47: lr=1e-05
2024-05-18 18:25:49 [Epoch: 47] loss: 0.004795, mae: 0.049085, r2: 0.768920, val_loss: 0.006012, val_mae: 0.053902, val_r2: 0.709305
2024-05-18 18:25:49 Epoch 48: lr=1e-05
2024-05-18 18:27:00 [Epoch: 48] loss: 0.004779, mae: 0.049003, r2: 0.769408, val_loss: 0.006017, val_mae: 0.054046, val_r2: 0.708528
2024-05-18 18:27:00 Epoch 49: lr=1e-05
2024-05-18 18:28:11 [Epoch: 49] loss: 0.004778, mae: 0.048996, r2: 0.769695, val_loss: 0.005989, val_mae: 0.054028, val_r2: 0.709965
2024-05-18 18:28:11 Epoch 50: lr=1e-05
2024-05-18 18:29:22 [Epoch: 50] loss: 0.004774, mae: 0.048997, r2: 0.770012, val_loss: 0.006013, val_mae: 0.054295, val_r2: 0.708743
2024-05-18 18:29:22 history_length: 51
2024-05-18 18:29:22 stopping: early
2024-05-18 18:29:22 Comparing y_true and y_pred:
2024-05-18 18:29:22   mse: 0.01129607
2024-05-18 18:29:22   mae: 0.08478610
2024-05-18 18:29:22   r2: 0.19556291
2024-05-18 18:29:22   corr: 0.47797605
