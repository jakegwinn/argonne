2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/79', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '79', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/79/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/79', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s0b0n0.79.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/79/3.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/79'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x14f76cac0a90>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/79/3.1.model.h5
2024-05-18 17:28:56 Between random pairs in y_val:
2024-05-18 17:28:56   mse: 0.04768467
2024-05-18 17:28:56   mae: 0.15971605
2024-05-18 17:28:56   r2: -1.00155930
2024-05-18 17:28:56   corr: -0.00077965
2024-05-18 17:28:56 Data points per epoch: train = 469186, val = 117297, test = 1226
2024-05-18 17:28:56 Steps per epoch: train = 14662, val = 3665, test = 38
2024-05-18 17:28:56 Epoch 0: lr=0.001
2024-05-18 17:30:10 [Epoch: 0] loss: 0.031784, mae: 0.079620, r2: -0.607350, val_loss: 0.008740, val_mae: 0.066455, val_r2: 0.589795
2024-05-18 17:30:10 Epoch 1: lr=0.00082
2024-05-18 17:31:22 [Epoch: 1] loss: 0.008022, mae: 0.064037, r2: 0.621139, val_loss: 0.007603, val_mae: 0.062774, val_r2: 0.639176
2024-05-18 17:31:22 Epoch 2: lr=0.00064
2024-05-18 17:32:34 [Epoch: 2] loss: 0.007336, mae: 0.060905, r2: 0.652204, val_loss: 0.007204, val_mae: 0.060652, val_r2: 0.661137
2024-05-18 17:32:34 Epoch 3: lr=0.00046
2024-05-18 17:33:45 [Epoch: 3] loss: 0.006864, mae: 0.058702, r2: 0.674113, val_loss: 0.006859, val_mae: 0.058552, val_r2: 0.677478
2024-05-18 17:33:45 Epoch 4: lr=0.00028
2024-05-18 17:34:57 [Epoch: 4] loss: 0.006452, mae: 0.056895, r2: 0.692766, val_loss: 0.006700, val_mae: 0.059301, val_r2: 0.680337
2024-05-18 17:34:57 Epoch 5: lr=0.0001
2024-05-18 17:36:08 [Epoch: 5] loss: 0.006119, mae: 0.055330, r2: 0.708086, val_loss: 0.006417, val_mae: 0.056156, val_r2: 0.693766
2024-05-18 17:36:08 Epoch 6: lr=0.0001
2024-05-18 17:37:20 [Epoch: 6] loss: 0.006006, mae: 0.054860, r2: 0.713055, val_loss: 0.006375, val_mae: 0.056161, val_r2: 0.696487
2024-05-18 17:37:20 Epoch 7: lr=0.0001
2024-05-18 17:38:31 [Epoch: 7] loss: 0.005928, mae: 0.054511, r2: 0.716559, val_loss: 0.006320, val_mae: 0.055774, val_r2: 0.698714
2024-05-18 17:38:31 Epoch 8: lr=0.0001
2024-05-18 17:39:43 [Epoch: 8] loss: 0.005860, mae: 0.054165, r2: 0.719753, val_loss: 0.006283, val_mae: 0.055800, val_r2: 0.700986
2024-05-18 17:39:43 Epoch 9: lr=0.0001
2024-05-18 17:40:55 [Epoch: 9] loss: 0.005787, mae: 0.053863, r2: 0.723229, val_loss: 0.006246, val_mae: 0.055664, val_r2: 0.703005
2024-05-18 17:40:55 Epoch 10: lr=0.0001
2024-05-18 17:42:07 [Epoch: 10] loss: 0.005726, mae: 0.053561, r2: 0.725868, val_loss: 0.006274, val_mae: 0.055622, val_r2: 0.701746
2024-05-18 17:42:07 Epoch 11: lr=0.0001
2024-05-18 17:43:19 [Epoch: 11] loss: 0.005662, mae: 0.053279, r2: 0.728801, val_loss: 0.006241, val_mae: 0.055163, val_r2: 0.703530
2024-05-18 17:43:19 Epoch 12: lr=0.0001
2024-05-18 17:44:31 [Epoch: 12] loss: 0.005584, mae: 0.052968, r2: 0.732499, val_loss: 0.006203, val_mae: 0.055904, val_r2: 0.705372
2024-05-18 17:44:31 Epoch 13: lr=0.0001
2024-05-18 17:45:42 [Epoch: 13] loss: 0.005541, mae: 0.052755, r2: 0.734457, val_loss: 0.006197, val_mae: 0.056048, val_r2: 0.705076
2024-05-18 17:45:43 Epoch 14: lr=5e-05
2024-05-18 17:46:54 [Epoch: 14] loss: 0.005423, mae: 0.052175, r2: 0.739801, val_loss: 0.006147, val_mae: 0.055087, val_r2: 0.708288
2024-05-18 17:46:54 Epoch 15: lr=5e-05
2024-05-18 17:48:06 [Epoch: 15] loss: 0.005379, mae: 0.052008, r2: 0.741801, val_loss: 0.006118, val_mae: 0.054842, val_r2: 0.708860
2024-05-18 17:48:06 Epoch 16: lr=5e-05
2024-05-18 17:49:17 [Epoch: 16] loss: 0.005348, mae: 0.051810, r2: 0.743349, val_loss: 0.006120, val_mae: 0.055084, val_r2: 0.707367
2024-05-18 17:49:18 Epoch 17: lr=5e-05
2024-05-18 17:50:28 [Epoch: 17] loss: 0.005312, mae: 0.051694, r2: 0.745157, val_loss: 0.006128, val_mae: 0.055155, val_r2: 0.706546
2024-05-18 17:50:29 Epoch 18: lr=5e-05
2024-05-18 17:51:40 [Epoch: 18] loss: 0.005274, mae: 0.051495, r2: 0.746667, val_loss: 0.006132, val_mae: 0.054477, val_r2: 0.707219
2024-05-18 17:51:40 Epoch 19: lr=5e-05
2024-05-18 17:52:52 [Epoch: 19] loss: 0.005257, mae: 0.051406, r2: 0.747487, val_loss: 0.006119, val_mae: 0.054812, val_r2: 0.708303
2024-05-18 17:52:52 Epoch 20: lr=2.5e-05
2024-05-18 17:54:04 [Epoch: 20] loss: 0.005188, mae: 0.051118, r2: 0.750447, val_loss: 0.006098, val_mae: 0.054965, val_r2: 0.709283
2024-05-18 17:54:04 Epoch 21: lr=2.5e-05
2024-05-18 17:55:15 [Epoch: 21] loss: 0.005172, mae: 0.051003, r2: 0.751575, val_loss: 0.006127, val_mae: 0.054779, val_r2: 0.707596
2024-05-18 17:55:16 Epoch 22: lr=2.5e-05
2024-05-18 17:56:27 [Epoch: 22] loss: 0.005165, mae: 0.050969, r2: 0.751747, val_loss: 0.006116, val_mae: 0.054687, val_r2: 0.708167
2024-05-18 17:56:27 Epoch 23: lr=2.5e-05
2024-05-18 17:57:39 [Epoch: 23] loss: 0.005138, mae: 0.050820, r2: 0.753195, val_loss: 0.006099, val_mae: 0.054884, val_r2: 0.708689
2024-05-18 17:57:39 Epoch 24: lr=2.5e-05
2024-05-18 17:58:51 [Epoch: 24] loss: 0.005124, mae: 0.050830, r2: 0.753612, val_loss: 0.006084, val_mae: 0.054511, val_r2: 0.709568
2024-05-18 17:58:51 Epoch 25: lr=1.25e-05
2024-05-18 18:00:03 [Epoch: 25] loss: 0.005094, mae: 0.050670, r2: 0.755117, val_loss: 0.006115, val_mae: 0.054703, val_r2: 0.708068
2024-05-18 18:00:03 Epoch 26: lr=1.25e-05
2024-05-18 18:01:15 [Epoch: 26] loss: 0.005084, mae: 0.050597, r2: 0.755445, val_loss: 0.006094, val_mae: 0.054880, val_r2: 0.709273
2024-05-18 18:01:15 Epoch 27: lr=1.25e-05
2024-05-18 18:02:27 [Epoch: 27] loss: 0.005081, mae: 0.050625, r2: 0.755393, val_loss: 0.006102, val_mae: 0.054601, val_r2: 0.708810
2024-05-18 18:02:27 Epoch 28: lr=1.25e-05
2024-05-18 18:03:38 [Epoch: 28] loss: 0.005069, mae: 0.050517, r2: 0.756141, val_loss: 0.006091, val_mae: 0.054562, val_r2: 0.709319
2024-05-18 18:03:39 Epoch 29: lr=1.25e-05
2024-05-18 18:04:50 [Epoch: 29] loss: 0.005056, mae: 0.050468, r2: 0.756726, val_loss: 0.006095, val_mae: 0.054890, val_r2: 0.709031
2024-05-18 18:04:50 Epoch 30: lr=1e-05
2024-05-18 18:06:01 [Epoch: 30] loss: 0.005052, mae: 0.050443, r2: 0.756957, val_loss: 0.006083, val_mae: 0.054575, val_r2: 0.709821
2024-05-18 18:06:02 Epoch 31: lr=1e-05
2024-05-18 18:07:13 [Epoch: 31] loss: 0.005049, mae: 0.050409, r2: 0.757076, val_loss: 0.006099, val_mae: 0.054547, val_r2: 0.708633
2024-05-18 18:07:13 Epoch 32: lr=1e-05
2024-05-18 18:08:25 [Epoch: 32] loss: 0.005031, mae: 0.050330, r2: 0.758100, val_loss: 0.006095, val_mae: 0.054593, val_r2: 0.709281
2024-05-18 18:08:25 Epoch 33: lr=1e-05
2024-05-18 18:09:37 [Epoch: 33] loss: 0.005027, mae: 0.050331, r2: 0.758202, val_loss: 0.006092, val_mae: 0.054731, val_r2: 0.709237
2024-05-18 18:09:37 Epoch 34: lr=1e-05
2024-05-18 18:10:49 [Epoch: 34] loss: 0.005027, mae: 0.050324, r2: 0.758126, val_loss: 0.006083, val_mae: 0.054469, val_r2: 0.709790
2024-05-18 18:10:49 Epoch 35: lr=1e-05
2024-05-18 18:12:00 [Epoch: 35] loss: 0.005020, mae: 0.050305, r2: 0.758513, val_loss: 0.006088, val_mae: 0.054602, val_r2: 0.709441
2024-05-18 18:12:01 Epoch 36: lr=1e-05
2024-05-18 18:13:12 [Epoch: 36] loss: 0.005013, mae: 0.050260, r2: 0.758855, val_loss: 0.006100, val_mae: 0.054722, val_r2: 0.708951
2024-05-18 18:13:13 Epoch 37: lr=1e-05
2024-05-18 18:14:24 [Epoch: 37] loss: 0.005007, mae: 0.050255, r2: 0.759135, val_loss: 0.006077, val_mae: 0.054623, val_r2: 0.709928
2024-05-18 18:14:24 Epoch 38: lr=1e-05
2024-05-18 18:15:36 [Epoch: 38] loss: 0.004996, mae: 0.050215, r2: 0.759480, val_loss: 0.006109, val_mae: 0.054617, val_r2: 0.708497
2024-05-18 18:15:36 Epoch 39: lr=1e-05
2024-05-18 18:16:48 [Epoch: 39] loss: 0.004995, mae: 0.050173, r2: 0.759565, val_loss: 0.006108, val_mae: 0.054559, val_r2: 0.708482
2024-05-18 18:16:48 Epoch 40: lr=1e-05
2024-05-18 18:18:00 [Epoch: 40] loss: 0.004982, mae: 0.050123, r2: 0.760248, val_loss: 0.006081, val_mae: 0.054425, val_r2: 0.710039
2024-05-18 18:18:00 Epoch 41: lr=1e-05
2024-05-18 18:19:11 [Epoch: 41] loss: 0.004991, mae: 0.050141, r2: 0.759856, val_loss: 0.006093, val_mae: 0.054396, val_r2: 0.709533
2024-05-18 18:19:11 Epoch 42: lr=1e-05
2024-05-18 18:20:22 [Epoch: 42] loss: 0.004983, mae: 0.050105, r2: 0.760102, val_loss: 0.006104, val_mae: 0.054464, val_r2: 0.708644
2024-05-18 18:20:22 Epoch 43: lr=1e-05
2024-05-18 18:21:33 [Epoch: 43] loss: 0.004980, mae: 0.050096, r2: 0.760410, val_loss: 0.006092, val_mae: 0.054610, val_r2: 0.709295
2024-05-18 18:21:33 Epoch 44: lr=1e-05
2024-05-18 18:22:45 [Epoch: 44] loss: 0.004979, mae: 0.050095, r2: 0.760443, val_loss: 0.006082, val_mae: 0.054581, val_r2: 0.709951
2024-05-18 18:22:45 Epoch 45: lr=1e-05
2024-05-18 18:23:56 [Epoch: 45] loss: 0.004959, mae: 0.049966, r2: 0.761191, val_loss: 0.006080, val_mae: 0.054575, val_r2: 0.709780
2024-05-18 18:23:56 Epoch 46: lr=1e-05
2024-05-18 18:25:08 [Epoch: 46] loss: 0.004962, mae: 0.050007, r2: 0.761267, val_loss: 0.006065, val_mae: 0.054689, val_r2: 0.710384
2024-05-18 18:25:08 Epoch 47: lr=1e-05
2024-05-18 18:26:19 [Epoch: 47] loss: 0.004955, mae: 0.049982, r2: 0.761541, val_loss: 0.006053, val_mae: 0.054478, val_r2: 0.711020
2024-05-18 18:26:19 Epoch 48: lr=1e-05
2024-05-18 18:27:31 [Epoch: 48] loss: 0.004951, mae: 0.049964, r2: 0.761485, val_loss: 0.006079, val_mae: 0.054616, val_r2: 0.709616
2024-05-18 18:27:31 Epoch 49: lr=1e-05
2024-05-18 18:28:42 [Epoch: 49] loss: 0.004942, mae: 0.049931, r2: 0.762068, val_loss: 0.006106, val_mae: 0.054420, val_r2: 0.709159
2024-05-18 18:28:42 Epoch 50: lr=1e-05
2024-05-18 18:29:54 [Epoch: 50] loss: 0.004940, mae: 0.049896, r2: 0.762034, val_loss: 0.006096, val_mae: 0.054553, val_r2: 0.708890
2024-05-18 18:29:54 Epoch 51: lr=1e-05
2024-05-18 18:31:04 [Epoch: 51] loss: 0.004934, mae: 0.049873, r2: 0.762274, val_loss: 0.006091, val_mae: 0.054515, val_r2: 0.709210
2024-05-18 18:31:04 Epoch 52: lr=1e-05
2024-05-18 18:32:16 [Epoch: 52] loss: 0.004920, mae: 0.049819, r2: 0.762953, val_loss: 0.006100, val_mae: 0.054323, val_r2: 0.709138
2024-05-18 18:32:16 Epoch 53: lr=1e-05
2024-05-18 18:33:27 [Epoch: 53] loss: 0.004917, mae: 0.049784, r2: 0.763119, val_loss: 0.006085, val_mae: 0.054414, val_r2: 0.709109
2024-05-18 18:33:27 Epoch 54: lr=1e-05
2024-05-18 18:34:38 [Epoch: 54] loss: 0.004916, mae: 0.049794, r2: 0.763182, val_loss: 0.006064, val_mae: 0.054485, val_r2: 0.709877
2024-05-18 18:34:38 Epoch 55: lr=1e-05
2024-05-18 18:35:49 [Epoch: 55] loss: 0.004904, mae: 0.049727, r2: 0.763781, val_loss: 0.006088, val_mae: 0.054477, val_r2: 0.709512
2024-05-18 18:35:49 Epoch 56: lr=1e-05
2024-05-18 18:37:00 [Epoch: 56] loss: 0.004905, mae: 0.049772, r2: 0.763657, val_loss: 0.006092, val_mae: 0.054622, val_r2: 0.709107
2024-05-18 18:37:01 Epoch 57: lr=1e-05
2024-05-18 18:38:12 [Epoch: 57] loss: 0.004908, mae: 0.049755, r2: 0.763397, val_loss: 0.006094, val_mae: 0.054393, val_r2: 0.708897
2024-05-18 18:38:12 history_length: 58
2024-05-18 18:38:12 stopping: early
2024-05-18 18:38:12 Comparing y_true and y_pred:
2024-05-18 18:38:12   mse: 0.00257034
2024-05-18 18:38:12   mae: 0.03821775
2024-05-18 18:38:12   r2: -0.00800925
2024-05-18 18:38:12   corr: 0.27448647
