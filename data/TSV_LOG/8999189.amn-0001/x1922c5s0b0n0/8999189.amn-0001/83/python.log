2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/83', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '83', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/83/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/83', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s0b0n0.83.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/83/5.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/83'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x146034b7df10>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/83/5.1.model.h5
2024-05-18 17:28:56 Between random pairs in y_val:
2024-05-18 17:28:56   mse: 0.04788974
2024-05-18 17:28:56   mae: 0.16048249
2024-05-18 17:28:56   r2: -1.00262146
2024-05-18 17:28:56   corr: -0.00131073
2024-05-18 17:28:56 Data points per epoch: train = 469623, val = 117406, test = 680
2024-05-18 17:28:56 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-18 17:28:56 Epoch 0: lr=0.001
2024-05-18 17:30:09 [Epoch: 0] loss: 0.026654, mae: 0.079343, r2: -0.447118, val_loss: 0.008790, val_mae: 0.066584, val_r2: 0.591612
2024-05-18 17:30:09 Epoch 1: lr=0.00082
2024-05-18 17:31:21 [Epoch: 1] loss: 0.007964, mae: 0.063835, r2: 0.621559, val_loss: 0.007660, val_mae: 0.061916, val_r2: 0.637978
2024-05-18 17:31:21 Epoch 2: lr=0.00064
2024-05-18 17:32:32 [Epoch: 2] loss: 0.007291, mae: 0.060689, r2: 0.652641, val_loss: 0.007464, val_mae: 0.063074, val_r2: 0.647452
2024-05-18 17:32:32 Epoch 3: lr=0.00046
2024-05-18 17:33:44 [Epoch: 3] loss: 0.006839, mae: 0.058644, r2: 0.672974, val_loss: 0.006979, val_mae: 0.059184, val_r2: 0.671391
2024-05-18 17:33:44 Epoch 4: lr=0.00028
2024-05-18 17:34:56 [Epoch: 4] loss: 0.006451, mae: 0.056830, r2: 0.690933, val_loss: 0.006631, val_mae: 0.057053, val_r2: 0.685642
2024-05-18 17:34:56 Epoch 5: lr=0.0001
2024-05-18 17:36:07 [Epoch: 5] loss: 0.006111, mae: 0.055265, r2: 0.706686, val_loss: 0.006521, val_mae: 0.056575, val_r2: 0.688139
2024-05-18 17:36:07 Epoch 6: lr=0.0001
2024-05-18 17:37:19 [Epoch: 6] loss: 0.005997, mae: 0.054749, r2: 0.711967, val_loss: 0.006479, val_mae: 0.056204, val_r2: 0.691215
2024-05-18 17:37:19 Epoch 7: lr=0.0001
2024-05-18 17:38:30 [Epoch: 7] loss: 0.005929, mae: 0.054442, r2: 0.715122, val_loss: 0.006391, val_mae: 0.055998, val_r2: 0.695848
2024-05-18 17:38:31 Epoch 8: lr=0.0001
2024-05-18 17:39:42 [Epoch: 8] loss: 0.005846, mae: 0.054062, r2: 0.718835, val_loss: 0.006400, val_mae: 0.056342, val_r2: 0.694871
2024-05-18 17:39:42 Epoch 9: lr=0.0001
2024-05-18 17:40:55 [Epoch: 9] loss: 0.005788, mae: 0.053828, r2: 0.721424, val_loss: 0.006363, val_mae: 0.055806, val_r2: 0.696195
2024-05-18 17:40:55 Epoch 10: lr=0.0001
2024-05-18 17:42:06 [Epoch: 10] loss: 0.005728, mae: 0.053538, r2: 0.724428, val_loss: 0.006343, val_mae: 0.055933, val_r2: 0.697430
2024-05-18 17:42:06 Epoch 11: lr=0.0001
2024-05-18 17:43:18 [Epoch: 11] loss: 0.005673, mae: 0.053299, r2: 0.727242, val_loss: 0.006328, val_mae: 0.055542, val_r2: 0.697175
2024-05-18 17:43:18 Epoch 12: lr=0.0001
2024-05-18 17:44:30 [Epoch: 12] loss: 0.005613, mae: 0.053008, r2: 0.729832, val_loss: 0.006315, val_mae: 0.055840, val_r2: 0.698963
2024-05-18 17:44:30 Epoch 13: lr=5e-05
2024-05-18 17:45:42 [Epoch: 13] loss: 0.005506, mae: 0.052496, r2: 0.734849, val_loss: 0.006278, val_mae: 0.055400, val_r2: 0.701189
2024-05-18 17:45:42 Epoch 14: lr=5e-05
2024-05-18 17:46:53 [Epoch: 14] loss: 0.005455, mae: 0.052285, r2: 0.737361, val_loss: 0.006274, val_mae: 0.055354, val_r2: 0.701098
2024-05-18 17:46:53 Epoch 15: lr=5e-05
2024-05-18 17:48:04 [Epoch: 15] loss: 0.005423, mae: 0.052148, r2: 0.738721, val_loss: 0.006269, val_mae: 0.055514, val_r2: 0.700797
2024-05-18 17:48:04 Epoch 16: lr=5e-05
2024-05-18 17:49:15 [Epoch: 16] loss: 0.005385, mae: 0.051963, r2: 0.740235, val_loss: 0.006276, val_mae: 0.055962, val_r2: 0.700488
2024-05-18 17:49:15 Epoch 17: lr=5e-05
2024-05-18 17:50:27 [Epoch: 17] loss: 0.005369, mae: 0.051894, r2: 0.741072, val_loss: 0.006244, val_mae: 0.055045, val_r2: 0.702269
2024-05-18 17:50:27 Epoch 18: lr=5e-05
2024-05-18 17:51:38 [Epoch: 18] loss: 0.005335, mae: 0.051744, r2: 0.742899, val_loss: 0.006244, val_mae: 0.055168, val_r2: 0.703023
2024-05-18 17:51:38 Epoch 19: lr=2.5e-05
2024-05-18 17:52:49 [Epoch: 19] loss: 0.005288, mae: 0.051468, r2: 0.745021, val_loss: 0.006230, val_mae: 0.055058, val_r2: 0.702692
2024-05-18 17:52:49 Epoch 20: lr=2.5e-05
2024-05-18 17:54:01 [Epoch: 20] loss: 0.005248, mae: 0.051319, r2: 0.746816, val_loss: 0.006228, val_mae: 0.054853, val_r2: 0.703202
2024-05-18 17:54:01 Epoch 21: lr=2.5e-05
2024-05-18 17:55:12 [Epoch: 21] loss: 0.005233, mae: 0.051270, r2: 0.747848, val_loss: 0.006233, val_mae: 0.054891, val_r2: 0.702527
2024-05-18 17:55:12 Epoch 22: lr=2.5e-05
2024-05-18 17:56:24 [Epoch: 22] loss: 0.005215, mae: 0.051167, r2: 0.748237, val_loss: 0.006206, val_mae: 0.055052, val_r2: 0.703922
2024-05-18 17:56:25 Epoch 23: lr=2.5e-05
2024-05-18 17:57:36 [Epoch: 23] loss: 0.005193, mae: 0.051101, r2: 0.749373, val_loss: 0.006207, val_mae: 0.054676, val_r2: 0.704277
2024-05-18 17:57:36 Epoch 24: lr=1.25e-05
2024-05-18 17:58:48 [Epoch: 24] loss: 0.005170, mae: 0.050974, r2: 0.750477, val_loss: 0.006208, val_mae: 0.055054, val_r2: 0.703937
2024-05-18 17:58:48 Epoch 25: lr=1.25e-05
2024-05-18 18:00:00 [Epoch: 25] loss: 0.005157, mae: 0.050879, r2: 0.751031, val_loss: 0.006217, val_mae: 0.054896, val_r2: 0.703690
2024-05-18 18:00:00 Epoch 26: lr=1.25e-05
2024-05-18 18:01:11 [Epoch: 26] loss: 0.005145, mae: 0.050862, r2: 0.751458, val_loss: 0.006231, val_mae: 0.055033, val_r2: 0.703730
2024-05-18 18:01:11 Epoch 27: lr=1.25e-05
2024-05-18 18:02:23 [Epoch: 27] loss: 0.005135, mae: 0.050851, r2: 0.752082, val_loss: 0.006231, val_mae: 0.054932, val_r2: 0.702933
2024-05-18 18:02:24 Epoch 28: lr=1.25e-05
2024-05-18 18:03:35 [Epoch: 28] loss: 0.005138, mae: 0.050812, r2: 0.752025, val_loss: 0.006233, val_mae: 0.055055, val_r2: 0.702647
2024-05-18 18:03:35 Epoch 29: lr=1e-05
2024-05-18 18:04:46 [Epoch: 29] loss: 0.005129, mae: 0.050791, r2: 0.752174, val_loss: 0.006199, val_mae: 0.054914, val_r2: 0.704194
2024-05-18 18:04:46 Epoch 30: lr=1e-05
2024-05-18 18:05:58 [Epoch: 30] loss: 0.005109, mae: 0.050684, r2: 0.753461, val_loss: 0.006221, val_mae: 0.054895, val_r2: 0.703789
2024-05-18 18:05:58 Epoch 31: lr=1e-05
2024-05-18 18:07:10 [Epoch: 31] loss: 0.005113, mae: 0.050684, r2: 0.753374, val_loss: 0.006207, val_mae: 0.054836, val_r2: 0.703991
2024-05-18 18:07:10 Epoch 32: lr=1e-05
2024-05-18 18:08:22 [Epoch: 32] loss: 0.005104, mae: 0.050640, r2: 0.753647, val_loss: 0.006197, val_mae: 0.054753, val_r2: 0.704757
2024-05-18 18:08:22 Epoch 33: lr=1e-05
2024-05-18 18:09:33 [Epoch: 33] loss: 0.005093, mae: 0.050582, r2: 0.754148, val_loss: 0.006232, val_mae: 0.054985, val_r2: 0.702862
2024-05-18 18:09:33 Epoch 34: lr=1e-05
2024-05-18 18:10:45 [Epoch: 34] loss: 0.005101, mae: 0.050652, r2: 0.753672, val_loss: 0.006233, val_mae: 0.055001, val_r2: 0.703722
2024-05-18 18:10:45 Epoch 35: lr=1e-05
2024-05-18 18:11:57 [Epoch: 35] loss: 0.005087, mae: 0.050604, r2: 0.754330, val_loss: 0.006195, val_mae: 0.054789, val_r2: 0.704373
2024-05-18 18:11:57 Epoch 36: lr=1e-05
2024-05-18 18:13:09 [Epoch: 36] loss: 0.005084, mae: 0.050563, r2: 0.754523, val_loss: 0.006214, val_mae: 0.054895, val_r2: 0.703817
2024-05-18 18:13:09 Epoch 37: lr=1e-05
2024-05-18 18:14:21 [Epoch: 37] loss: 0.005071, mae: 0.050468, r2: 0.755192, val_loss: 0.006203, val_mae: 0.054714, val_r2: 0.704332
2024-05-18 18:14:21 Epoch 38: lr=1e-05
2024-05-18 18:15:32 [Epoch: 38] loss: 0.005065, mae: 0.050504, r2: 0.755282, val_loss: 0.006201, val_mae: 0.054725, val_r2: 0.704723
2024-05-18 18:15:32 Epoch 39: lr=1e-05
2024-05-18 18:16:44 [Epoch: 39] loss: 0.005054, mae: 0.050437, r2: 0.755776, val_loss: 0.006171, val_mae: 0.054823, val_r2: 0.705811
2024-05-18 18:16:44 Epoch 40: lr=1e-05
2024-05-18 18:17:56 [Epoch: 40] loss: 0.005053, mae: 0.050424, r2: 0.756063, val_loss: 0.006220, val_mae: 0.054941, val_r2: 0.704066
2024-05-18 18:17:56 Epoch 41: lr=1e-05
2024-05-18 18:19:07 [Epoch: 41] loss: 0.005047, mae: 0.050381, r2: 0.756217, val_loss: 0.006187, val_mae: 0.054709, val_r2: 0.704534
2024-05-18 18:19:07 Epoch 42: lr=1e-05
2024-05-18 18:20:19 [Epoch: 42] loss: 0.005043, mae: 0.050388, r2: 0.756225, val_loss: 0.006204, val_mae: 0.054858, val_r2: 0.704275
2024-05-18 18:20:19 Epoch 43: lr=1e-05
2024-05-18 18:21:30 [Epoch: 43] loss: 0.005045, mae: 0.050362, r2: 0.756445, val_loss: 0.006218, val_mae: 0.054726, val_r2: 0.703694
2024-05-18 18:21:30 Epoch 44: lr=1e-05
2024-05-18 18:22:42 [Epoch: 44] loss: 0.005027, mae: 0.050282, r2: 0.757148, val_loss: 0.006206, val_mae: 0.054631, val_r2: 0.703810
2024-05-18 18:22:42 Epoch 45: lr=1e-05
2024-05-18 18:23:54 [Epoch: 45] loss: 0.005031, mae: 0.050313, r2: 0.757093, val_loss: 0.006226, val_mae: 0.054794, val_r2: 0.703055
2024-05-18 18:23:54 Epoch 46: lr=1e-05
2024-05-18 18:25:05 [Epoch: 46] loss: 0.005023, mae: 0.050271, r2: 0.757341, val_loss: 0.006213, val_mae: 0.054765, val_r2: 0.703704
2024-05-18 18:25:05 Epoch 47: lr=1e-05
2024-05-18 18:26:17 [Epoch: 47] loss: 0.005016, mae: 0.050229, r2: 0.757663, val_loss: 0.006210, val_mae: 0.054758, val_r2: 0.704048
2024-05-18 18:26:17 Epoch 48: lr=1e-05
2024-05-18 18:27:28 [Epoch: 48] loss: 0.005007, mae: 0.050185, r2: 0.757961, val_loss: 0.006207, val_mae: 0.054853, val_r2: 0.703351
2024-05-18 18:27:28 Epoch 49: lr=1e-05
2024-05-18 18:28:39 [Epoch: 49] loss: 0.005015, mae: 0.050210, r2: 0.757559, val_loss: 0.006194, val_mae: 0.054726, val_r2: 0.704873
2024-05-18 18:28:39 history_length: 50
2024-05-18 18:28:39 stopping: early
2024-05-18 18:28:39 Comparing y_true and y_pred:
2024-05-18 18:28:39   mse: 0.00598412
2024-05-18 18:28:39   mae: 0.06551441
2024-05-18 18:28:39   r2: -1.32305165
2024-05-18 18:28:39   corr: 0.17027358
