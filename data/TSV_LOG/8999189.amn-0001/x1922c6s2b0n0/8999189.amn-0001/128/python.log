2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/128', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '128', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/128/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/128', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s2b0n0.128.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/128/4.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/128'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x153ab1e61cd0>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/128/4.0.model.h5
2024-05-18 17:28:57 Between random pairs in y_val:
2024-05-18 17:28:57   mse: 0.04761451
2024-05-18 17:28:57   mae: 0.15973088
2024-05-18 17:28:57   r2: -1.00444959
2024-05-18 17:28:57   corr: -0.00222480
2024-05-18 17:28:57 Data points per epoch: train = 469167, val = 117292, test = 1250
2024-05-18 17:28:57 Steps per epoch: train = 14661, val = 3665, test = 39
2024-05-18 17:28:57 Epoch 0: lr=0.001
2024-05-18 17:30:11 [Epoch: 0] loss: 0.026335, mae: 0.079738, r2: -2.347857, val_loss: 0.008591, val_mae: 0.066413, val_r2: 0.600250
2024-05-18 17:30:11 Epoch 1: lr=0.00082
2024-05-18 17:31:24 [Epoch: 1] loss: 0.007964, mae: 0.063780, r2: 0.621096, val_loss: 0.007588, val_mae: 0.061944, val_r2: 0.637081
2024-05-18 17:31:24 Epoch 2: lr=0.00064
2024-05-18 17:32:37 [Epoch: 2] loss: 0.007291, mae: 0.060691, r2: 0.652610, val_loss: 0.007184, val_mae: 0.059634, val_r2: 0.655501
2024-05-18 17:32:37 Epoch 3: lr=0.00046
2024-05-18 17:33:51 [Epoch: 3] loss: 0.006832, mae: 0.058606, r2: 0.673139, val_loss: 0.006828, val_mae: 0.058724, val_r2: 0.670550
2024-05-18 17:33:51 Epoch 4: lr=0.00028
2024-05-18 17:35:04 [Epoch: 4] loss: 0.006436, mae: 0.056740, r2: 0.691295, val_loss: 0.006575, val_mae: 0.056925, val_r2: 0.685413
2024-05-18 17:35:04 Epoch 5: lr=0.0001
2024-05-18 17:36:17 [Epoch: 5] loss: 0.006095, mae: 0.055176, r2: 0.707301, val_loss: 0.006369, val_mae: 0.056464, val_r2: 0.694150
2024-05-18 17:36:17 Epoch 6: lr=0.0001
2024-05-18 17:37:30 [Epoch: 6] loss: 0.005986, mae: 0.054701, r2: 0.712362, val_loss: 0.006351, val_mae: 0.056125, val_r2: 0.694580
2024-05-18 17:37:30 Epoch 7: lr=0.0001
2024-05-18 17:38:43 [Epoch: 7] loss: 0.005909, mae: 0.054387, r2: 0.715912, val_loss: 0.006316, val_mae: 0.055926, val_r2: 0.697895
2024-05-18 17:38:43 Epoch 8: lr=0.0001
2024-05-18 17:39:56 [Epoch: 8] loss: 0.005848, mae: 0.054084, r2: 0.718736, val_loss: 0.006300, val_mae: 0.055607, val_r2: 0.696639
2024-05-18 17:39:56 Epoch 9: lr=0.0001
2024-05-18 17:41:09 [Epoch: 9] loss: 0.005775, mae: 0.053770, r2: 0.721991, val_loss: 0.006292, val_mae: 0.055463, val_r2: 0.697419
2024-05-18 17:41:09 Epoch 10: lr=0.0001
2024-05-18 17:42:22 [Epoch: 10] loss: 0.005720, mae: 0.053525, r2: 0.724620, val_loss: 0.006227, val_mae: 0.055988, val_r2: 0.701017
2024-05-18 17:42:22 Epoch 11: lr=0.0001
2024-05-18 17:43:35 [Epoch: 11] loss: 0.005654, mae: 0.053215, r2: 0.727774, val_loss: 0.006218, val_mae: 0.055322, val_r2: 0.702361
2024-05-18 17:43:35 Epoch 12: lr=0.0001
2024-05-18 17:44:48 [Epoch: 12] loss: 0.005593, mae: 0.052937, r2: 0.730783, val_loss: 0.006184, val_mae: 0.055195, val_r2: 0.702493
2024-05-18 17:44:48 Epoch 13: lr=0.0001
2024-05-18 17:46:01 [Epoch: 13] loss: 0.005544, mae: 0.052727, r2: 0.733034, val_loss: 0.006198, val_mae: 0.055166, val_r2: 0.701866
2024-05-18 17:46:02 Epoch 14: lr=0.0001
2024-05-18 17:47:14 [Epoch: 14] loss: 0.005487, mae: 0.052476, r2: 0.735497, val_loss: 0.006179, val_mae: 0.055163, val_r2: 0.703162
2024-05-18 17:47:14 Epoch 15: lr=0.0001
2024-05-18 17:48:27 [Epoch: 15] loss: 0.005438, mae: 0.052264, r2: 0.738000, val_loss: 0.006160, val_mae: 0.055195, val_r2: 0.704540
2024-05-18 17:48:27 Epoch 16: lr=5e-05
2024-05-18 17:49:41 [Epoch: 16] loss: 0.005312, mae: 0.051646, r2: 0.743686, val_loss: 0.006104, val_mae: 0.054604, val_r2: 0.707285
2024-05-18 17:49:41 Epoch 17: lr=5e-05
2024-05-18 17:50:54 [Epoch: 17] loss: 0.005272, mae: 0.051422, r2: 0.745552, val_loss: 0.006134, val_mae: 0.054415, val_r2: 0.705840
2024-05-18 17:50:54 Epoch 18: lr=5e-05
2024-05-18 17:52:06 [Epoch: 18] loss: 0.005248, mae: 0.051337, r2: 0.746836, val_loss: 0.006127, val_mae: 0.054709, val_r2: 0.705513
2024-05-18 17:52:07 Epoch 19: lr=5e-05
2024-05-18 17:53:20 [Epoch: 19] loss: 0.005211, mae: 0.051195, r2: 0.748597, val_loss: 0.006127, val_mae: 0.054595, val_r2: 0.705958
2024-05-18 17:53:20 Epoch 20: lr=5e-05
2024-05-18 17:54:33 [Epoch: 20] loss: 0.005187, mae: 0.051056, r2: 0.749681, val_loss: 0.006097, val_mae: 0.054711, val_r2: 0.707641
2024-05-18 17:54:33 Epoch 21: lr=5e-05
2024-05-18 17:55:46 [Epoch: 21] loss: 0.005164, mae: 0.050966, r2: 0.750723, val_loss: 0.006120, val_mae: 0.054733, val_r2: 0.705767
2024-05-18 17:55:46 Epoch 22: lr=2.5e-05
2024-05-18 17:56:59 [Epoch: 22] loss: 0.005101, mae: 0.050688, r2: 0.753749, val_loss: 0.006140, val_mae: 0.054483, val_r2: 0.705189
2024-05-18 17:57:00 Epoch 23: lr=2.5e-05
2024-05-18 17:58:13 [Epoch: 23] loss: 0.005081, mae: 0.050573, r2: 0.754636, val_loss: 0.006119, val_mae: 0.054487, val_r2: 0.706092
2024-05-18 17:58:13 Epoch 24: lr=2.5e-05
2024-05-18 17:59:26 [Epoch: 24] loss: 0.005064, mae: 0.050457, r2: 0.755170, val_loss: 0.006100, val_mae: 0.054339, val_r2: 0.706634
2024-05-18 17:59:26 Epoch 25: lr=2.5e-05
2024-05-18 18:00:39 [Epoch: 25] loss: 0.005046, mae: 0.050403, r2: 0.756191, val_loss: 0.006095, val_mae: 0.054515, val_r2: 0.707258
2024-05-18 18:00:39 Epoch 26: lr=2.5e-05
2024-05-18 18:01:52 [Epoch: 26] loss: 0.005030, mae: 0.050314, r2: 0.756750, val_loss: 0.006082, val_mae: 0.054388, val_r2: 0.708034
2024-05-18 18:01:53 Epoch 27: lr=1.25e-05
2024-05-18 18:03:05 [Epoch: 27] loss: 0.005004, mae: 0.050188, r2: 0.758176, val_loss: 0.006103, val_mae: 0.054412, val_r2: 0.706943
2024-05-18 18:03:05 Epoch 28: lr=1.25e-05
2024-05-18 18:04:18 [Epoch: 28] loss: 0.004992, mae: 0.050165, r2: 0.758850, val_loss: 0.006093, val_mae: 0.054707, val_r2: 0.707338
2024-05-18 18:04:18 Epoch 29: lr=1.25e-05
2024-05-18 18:05:31 [Epoch: 29] loss: 0.004987, mae: 0.050098, r2: 0.758832, val_loss: 0.006072, val_mae: 0.054406, val_r2: 0.708596
2024-05-18 18:05:32 Epoch 30: lr=1.25e-05
2024-05-18 18:06:44 [Epoch: 30] loss: 0.004970, mae: 0.050001, r2: 0.759769, val_loss: 0.006103, val_mae: 0.054493, val_r2: 0.706831
2024-05-18 18:06:44 Epoch 31: lr=1.25e-05
2024-05-18 18:07:57 [Epoch: 31] loss: 0.004975, mae: 0.050077, r2: 0.759438, val_loss: 0.006082, val_mae: 0.054206, val_r2: 0.707891
2024-05-18 18:07:57 Epoch 32: lr=1e-05
2024-05-18 18:09:10 [Epoch: 32] loss: 0.004957, mae: 0.049954, r2: 0.760222, val_loss: 0.006067, val_mae: 0.054465, val_r2: 0.708503
2024-05-18 18:09:10 Epoch 33: lr=1e-05
2024-05-18 18:10:23 [Epoch: 33] loss: 0.004958, mae: 0.049981, r2: 0.760461, val_loss: 0.006099, val_mae: 0.054399, val_r2: 0.706748
2024-05-18 18:10:23 Epoch 34: lr=1e-05
2024-05-18 18:11:36 [Epoch: 34] loss: 0.004940, mae: 0.049914, r2: 0.761085, val_loss: 0.006096, val_mae: 0.054302, val_r2: 0.706631
2024-05-18 18:11:36 Epoch 35: lr=1e-05
2024-05-18 18:12:49 [Epoch: 35] loss: 0.004929, mae: 0.049835, r2: 0.761753, val_loss: 0.006087, val_mae: 0.054412, val_r2: 0.707891
2024-05-18 18:12:49 Epoch 36: lr=1e-05
2024-05-18 18:14:02 [Epoch: 36] loss: 0.004938, mae: 0.049857, r2: 0.761179, val_loss: 0.006090, val_mae: 0.054256, val_r2: 0.707383
2024-05-18 18:14:03 Epoch 37: lr=1e-05
2024-05-18 18:15:16 [Epoch: 37] loss: 0.004932, mae: 0.049852, r2: 0.761644, val_loss: 0.006114, val_mae: 0.054286, val_r2: 0.706138
2024-05-18 18:15:16 Epoch 38: lr=1e-05
2024-05-18 18:16:29 [Epoch: 38] loss: 0.004924, mae: 0.049818, r2: 0.761959, val_loss: 0.006104, val_mae: 0.054292, val_r2: 0.707134
2024-05-18 18:16:29 Epoch 39: lr=1e-05
2024-05-18 18:17:42 [Epoch: 39] loss: 0.004920, mae: 0.049784, r2: 0.762115, val_loss: 0.006092, val_mae: 0.054298, val_r2: 0.706772
2024-05-18 18:17:42 Epoch 40: lr=1e-05
2024-05-18 18:18:55 [Epoch: 40] loss: 0.004918, mae: 0.049795, r2: 0.762208, val_loss: 0.006108, val_mae: 0.054441, val_r2: 0.706320
2024-05-18 18:18:55 Epoch 41: lr=1e-05
2024-05-18 18:20:08 [Epoch: 41] loss: 0.004907, mae: 0.049744, r2: 0.762732, val_loss: 0.006059, val_mae: 0.054327, val_r2: 0.708386
2024-05-18 18:20:08 Epoch 42: lr=1e-05
2024-05-18 18:21:21 [Epoch: 42] loss: 0.004903, mae: 0.049729, r2: 0.762817, val_loss: 0.006074, val_mae: 0.054087, val_r2: 0.708167
2024-05-18 18:21:21 Epoch 43: lr=1e-05
2024-05-18 18:22:34 [Epoch: 43] loss: 0.004887, mae: 0.049632, r2: 0.763758, val_loss: 0.006099, val_mae: 0.054490, val_r2: 0.706553
2024-05-18 18:22:34 Epoch 44: lr=1e-05
2024-05-18 18:23:47 [Epoch: 44] loss: 0.004894, mae: 0.049689, r2: 0.763139, val_loss: 0.006095, val_mae: 0.054244, val_r2: 0.707230
2024-05-18 18:23:47 Epoch 45: lr=1e-05
2024-05-18 18:25:00 [Epoch: 45] loss: 0.004875, mae: 0.049613, r2: 0.764262, val_loss: 0.006108, val_mae: 0.054294, val_r2: 0.706408
2024-05-18 18:25:00 Epoch 46: lr=1e-05
2024-05-18 18:26:13 [Epoch: 46] loss: 0.004886, mae: 0.049627, r2: 0.763727, val_loss: 0.006070, val_mae: 0.054261, val_r2: 0.708641
2024-05-18 18:26:13 Epoch 47: lr=1e-05
2024-05-18 18:27:26 [Epoch: 47] loss: 0.004884, mae: 0.049596, r2: 0.763819, val_loss: 0.006046, val_mae: 0.054122, val_r2: 0.709577
2024-05-18 18:27:26 Epoch 48: lr=1e-05
2024-05-18 18:28:38 [Epoch: 48] loss: 0.004866, mae: 0.049544, r2: 0.764525, val_loss: 0.006092, val_mae: 0.054357, val_r2: 0.707275
2024-05-18 18:28:38 Epoch 49: lr=1e-05
2024-05-18 18:29:51 [Epoch: 49] loss: 0.004863, mae: 0.049526, r2: 0.764891, val_loss: 0.006083, val_mae: 0.054329, val_r2: 0.707969
2024-05-18 18:29:51 Epoch 50: lr=1e-05
2024-05-18 18:31:04 [Epoch: 50] loss: 0.004862, mae: 0.049513, r2: 0.764873, val_loss: 0.006074, val_mae: 0.054492, val_r2: 0.707574
2024-05-18 18:31:04 Epoch 51: lr=1e-05
2024-05-18 18:32:17 [Epoch: 51] loss: 0.004854, mae: 0.049478, r2: 0.765229, val_loss: 0.006102, val_mae: 0.054223, val_r2: 0.706881
2024-05-18 18:32:17 Epoch 52: lr=1e-05
2024-05-18 18:33:29 [Epoch: 52] loss: 0.004856, mae: 0.049503, r2: 0.765221, val_loss: 0.006106, val_mae: 0.054483, val_r2: 0.706721
2024-05-18 18:33:29 Epoch 53: lr=1e-05
2024-05-18 18:34:41 [Epoch: 53] loss: 0.004850, mae: 0.049460, r2: 0.765497, val_loss: 0.006076, val_mae: 0.054149, val_r2: 0.708551
2024-05-18 18:34:42 Epoch 54: lr=1e-05
2024-05-18 18:35:54 [Epoch: 54] loss: 0.004838, mae: 0.049412, r2: 0.765834, val_loss: 0.006106, val_mae: 0.054264, val_r2: 0.706242
2024-05-18 18:35:54 Epoch 55: lr=1e-05
2024-05-18 18:37:07 [Epoch: 55] loss: 0.004833, mae: 0.049369, r2: 0.766113, val_loss: 0.006114, val_mae: 0.054300, val_r2: 0.707020
2024-05-18 18:37:07 Epoch 56: lr=1e-05
2024-05-18 18:38:20 [Epoch: 56] loss: 0.004841, mae: 0.049399, r2: 0.765786, val_loss: 0.006096, val_mae: 0.054360, val_r2: 0.707036
2024-05-18 18:38:20 Epoch 57: lr=1e-05
2024-05-18 18:39:32 [Epoch: 57] loss: 0.004821, mae: 0.049328, r2: 0.766702, val_loss: 0.006094, val_mae: 0.054233, val_r2: 0.707189
2024-05-18 18:39:32 history_length: 58
2024-05-18 18:39:32 stopping: early
2024-05-18 18:39:32 Comparing y_true and y_pred:
2024-05-18 18:39:32   mse: 0.02576699
2024-05-18 18:39:32   mae: 0.12609191
2024-05-18 18:39:32   r2: -0.22555943
2024-05-18 18:39:32   corr: 0.34068868
