2024-05-18 17:28:38 UNO RUN ...
2024-05-18 17:28:38 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999189.amn-0001/123', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999189.amn-0001', 'run_id': '123', 'logfile': '/dev/shm/Uno/save/8999189.amn-0001/123/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999189.amn-0001/123', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s2b0n0.123.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999189.amn-0001/123/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999189.amn-0001/123'}
2024-05-18 17:28:38 Feature encoding submodel for cell.rnaseq:
2024-05-18 17:28:38 Model: "cell.rnaseq"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense (Dense)               (None, 1000)              959000    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 17:28:38  ntDropout)                                                      
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Trainable params: 2961000 (11.30 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Feature encoding submodel for drug.descriptors:
2024-05-18 17:28:38 Model: "drug.descriptors"
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape              Param #   
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 17:28:38  nentDropout)                                                    
2024-05-18 17:28:38                                                                  
2024-05-18 17:28:38 =================================================================
2024-05-18 17:28:38 Total params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Trainable params: 3616000 (13.79 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 _________________________________________________________________
2024-05-18 17:28:38 Combined model:
2024-05-18 17:28:38 Model: "model"
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 17:28:38  yer)                                                                                             
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 17:28:38  nputLayer)                                                                                       
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 17:28:38  al)                                                                ]']                           
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 17:28:38                                                                      'drug.descriptors[0][0]']    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 17:28:38  nentDropout)                                                                                     
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 17:28:38  anentDropout)                                                                                    
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 17:28:38                                                                                                   
2024-05-18 17:28:38 ==================================================================================================
2024-05-18 17:28:38 Total params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Trainable params: 12583001 (48.00 MB)
2024-05-18 17:28:38 Non-trainable params: 0 (0.00 Byte)
2024-05-18 17:28:38 __________________________________________________________________________________________________
2024-05-18 17:28:38 CKPT CONSTRUCT...
2024-05-18 17:28:38 CKPT CONSTRUCT OK.
2024-05-18 17:28:38 template model: <keras.src.engine.functional.Functional object at 0x146aeb7c9b50>
2024-05-18 17:28:40 COMPILE
2024-05-18 17:28:40 Will save weights to: /dev/shm/Uno/save/8999189.amn-0001/123/1.1.model.h5
2024-05-18 17:28:56 Between random pairs in y_val:
2024-05-18 17:28:56   mse: 0.04765444
2024-05-18 17:28:56   mae: 0.16000165
2024-05-18 17:28:56   r2: -1.00626192
2024-05-18 17:28:56   corr: -0.00313096
2024-05-18 17:28:56 Data points per epoch: train = 469608, val = 117403, test = 698
2024-05-18 17:28:56 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-18 17:28:56 Epoch 0: lr=0.001
2024-05-18 17:30:10 [Epoch: 0] loss: 0.026208, mae: 0.079436, r2: -0.119911, val_loss: 0.008456, val_mae: 0.065619, val_r2: 0.594425
2024-05-18 17:30:10 Epoch 1: lr=0.00082
2024-05-18 17:31:23 [Epoch: 1] loss: 0.008013, mae: 0.064052, r2: 0.619806, val_loss: 0.007634, val_mae: 0.062142, val_r2: 0.636022
2024-05-18 17:31:23 Epoch 2: lr=0.00064
2024-05-18 17:32:36 [Epoch: 2] loss: 0.007330, mae: 0.060934, r2: 0.651462, val_loss: 0.007189, val_mae: 0.059558, val_r2: 0.655397
2024-05-18 17:32:36 Epoch 3: lr=0.00046
2024-05-18 17:33:49 [Epoch: 3] loss: 0.006852, mae: 0.058763, r2: 0.673159, val_loss: 0.006773, val_mae: 0.057916, val_r2: 0.673443
2024-05-18 17:33:49 Epoch 4: lr=0.00028
2024-05-18 17:35:02 [Epoch: 4] loss: 0.006466, mae: 0.056989, r2: 0.690665, val_loss: 0.006590, val_mae: 0.057261, val_r2: 0.680371
2024-05-18 17:35:02 Epoch 5: lr=0.0001
2024-05-18 17:36:15 [Epoch: 5] loss: 0.006130, mae: 0.055432, r2: 0.706264, val_loss: 0.006431, val_mae: 0.057051, val_r2: 0.689863
2024-05-18 17:36:16 Epoch 6: lr=0.0001
2024-05-18 17:37:28 [Epoch: 6] loss: 0.006019, mae: 0.054897, r2: 0.711617, val_loss: 0.006362, val_mae: 0.055956, val_r2: 0.693353
2024-05-18 17:37:28 Epoch 7: lr=0.0001
2024-05-18 17:38:41 [Epoch: 7] loss: 0.005954, mae: 0.054624, r2: 0.714641, val_loss: 0.006343, val_mae: 0.056652, val_r2: 0.693507
2024-05-18 17:38:42 Epoch 8: lr=0.0001
2024-05-18 17:39:55 [Epoch: 8] loss: 0.005869, mae: 0.054259, r2: 0.718487, val_loss: 0.006318, val_mae: 0.056161, val_r2: 0.694671
2024-05-18 17:39:55 Epoch 9: lr=0.0001
2024-05-18 17:41:08 [Epoch: 9] loss: 0.005815, mae: 0.054049, r2: 0.721014, val_loss: 0.006288, val_mae: 0.055656, val_r2: 0.696519
2024-05-18 17:41:08 Epoch 10: lr=0.0001
2024-05-18 17:42:20 [Epoch: 10] loss: 0.005751, mae: 0.053730, r2: 0.723877, val_loss: 0.006253, val_mae: 0.055597, val_r2: 0.698580
2024-05-18 17:42:20 Epoch 11: lr=0.0001
2024-05-18 17:43:34 [Epoch: 11] loss: 0.005696, mae: 0.053478, r2: 0.726677, val_loss: 0.006254, val_mae: 0.056020, val_r2: 0.698763
2024-05-18 17:43:34 Epoch 12: lr=0.0001
2024-05-18 17:44:47 [Epoch: 12] loss: 0.005644, mae: 0.053253, r2: 0.728912, val_loss: 0.006224, val_mae: 0.055341, val_r2: 0.699566
2024-05-18 17:44:47 Epoch 13: lr=0.0001
2024-05-18 17:46:00 [Epoch: 13] loss: 0.005585, mae: 0.052979, r2: 0.731785, val_loss: 0.006176, val_mae: 0.055126, val_r2: 0.702273
2024-05-18 17:46:00 Epoch 14: lr=0.0001
2024-05-18 17:47:13 [Epoch: 14] loss: 0.005522, mae: 0.052678, r2: 0.734586, val_loss: 0.006189, val_mae: 0.055240, val_r2: 0.700866
2024-05-18 17:47:13 Epoch 15: lr=0.0001
2024-05-18 17:48:26 [Epoch: 15] loss: 0.005467, mae: 0.052427, r2: 0.737022, val_loss: 0.006135, val_mae: 0.054852, val_r2: 0.703382
2024-05-18 17:48:26 Epoch 16: lr=0.0001
2024-05-18 17:49:39 [Epoch: 16] loss: 0.005425, mae: 0.052244, r2: 0.739311, val_loss: 0.006163, val_mae: 0.054693, val_r2: 0.702856
2024-05-18 17:49:39 Epoch 17: lr=0.0001
2024-05-18 17:50:51 [Epoch: 17] loss: 0.005377, mae: 0.052022, r2: 0.741205, val_loss: 0.006156, val_mae: 0.055019, val_r2: 0.703068
2024-05-18 17:50:51 Epoch 18: lr=0.0001
2024-05-18 17:52:04 [Epoch: 18] loss: 0.005330, mae: 0.051847, r2: 0.743713, val_loss: 0.006113, val_mae: 0.054516, val_r2: 0.705544
2024-05-18 17:52:04 Epoch 19: lr=5e-05
2024-05-18 17:53:17 [Epoch: 19] loss: 0.005219, mae: 0.051279, r2: 0.748834, val_loss: 0.006100, val_mae: 0.054696, val_r2: 0.704991
2024-05-18 17:53:17 Epoch 20: lr=5e-05
2024-05-18 17:54:30 [Epoch: 20] loss: 0.005179, mae: 0.051102, r2: 0.750580, val_loss: 0.006115, val_mae: 0.054298, val_r2: 0.704393
2024-05-18 17:54:31 Epoch 21: lr=5e-05
2024-05-18 17:55:44 [Epoch: 21] loss: 0.005146, mae: 0.050913, r2: 0.751993, val_loss: 0.006112, val_mae: 0.054366, val_r2: 0.704721
2024-05-18 17:55:44 Epoch 22: lr=5e-05
2024-05-18 17:56:57 [Epoch: 22] loss: 0.005112, mae: 0.050774, r2: 0.753533, val_loss: 0.006108, val_mae: 0.054503, val_r2: 0.705612
2024-05-18 17:56:57 Epoch 23: lr=5e-05
2024-05-18 17:58:10 [Epoch: 23] loss: 0.005092, mae: 0.050671, r2: 0.754587, val_loss: 0.006074, val_mae: 0.054475, val_r2: 0.707176
2024-05-18 17:58:10 Epoch 24: lr=5e-05
2024-05-18 17:59:23 [Epoch: 24] loss: 0.005063, mae: 0.050542, r2: 0.755926, val_loss: 0.006103, val_mae: 0.054396, val_r2: 0.705647
2024-05-18 17:59:23 Epoch 25: lr=5e-05
2024-05-18 18:00:36 [Epoch: 25] loss: 0.005037, mae: 0.050410, r2: 0.757117, val_loss: 0.006073, val_mae: 0.054331, val_r2: 0.706314
2024-05-18 18:00:36 Epoch 26: lr=5e-05
2024-05-18 18:01:50 [Epoch: 26] loss: 0.005020, mae: 0.050351, r2: 0.758022, val_loss: 0.006074, val_mae: 0.054484, val_r2: 0.706695
2024-05-18 18:01:50 Epoch 27: lr=5e-05
2024-05-18 18:03:02 [Epoch: 27] loss: 0.004999, mae: 0.050211, r2: 0.759172, val_loss: 0.006103, val_mae: 0.054291, val_r2: 0.705237
2024-05-18 18:03:02 Epoch 28: lr=5e-05
2024-05-18 18:04:15 [Epoch: 28] loss: 0.004971, mae: 0.050105, r2: 0.760421, val_loss: 0.006084, val_mae: 0.054219, val_r2: 0.705914
2024-05-18 18:04:15 Epoch 29: lr=2.5e-05
2024-05-18 18:05:28 [Epoch: 29] loss: 0.004903, mae: 0.049770, r2: 0.763293, val_loss: 0.006091, val_mae: 0.054212, val_r2: 0.705149
2024-05-18 18:05:28 Epoch 30: lr=2.5e-05
2024-05-18 18:06:41 [Epoch: 30] loss: 0.004893, mae: 0.049717, r2: 0.764012, val_loss: 0.006085, val_mae: 0.054276, val_r2: 0.706385
2024-05-18 18:06:41 Epoch 31: lr=2.5e-05
2024-05-18 18:07:53 [Epoch: 31] loss: 0.004887, mae: 0.049672, r2: 0.764374, val_loss: 0.006080, val_mae: 0.054285, val_r2: 0.706163
2024-05-18 18:07:53 Epoch 32: lr=2.5e-05
2024-05-18 18:09:07 [Epoch: 32] loss: 0.004870, mae: 0.049609, r2: 0.765046, val_loss: 0.006077, val_mae: 0.054340, val_r2: 0.706371
2024-05-18 18:09:07 Epoch 33: lr=2.5e-05
2024-05-18 18:10:20 [Epoch: 33] loss: 0.004857, mae: 0.049527, r2: 0.765588, val_loss: 0.006084, val_mae: 0.054103, val_r2: 0.706313
2024-05-18 18:10:20 Epoch 34: lr=1.25e-05
2024-05-18 18:11:33 [Epoch: 34] loss: 0.004824, mae: 0.049402, r2: 0.767126, val_loss: 0.006093, val_mae: 0.054289, val_r2: 0.705661
2024-05-18 18:11:33 Epoch 35: lr=1.25e-05
2024-05-18 18:12:46 [Epoch: 35] loss: 0.004805, mae: 0.049323, r2: 0.767988, val_loss: 0.006070, val_mae: 0.054162, val_r2: 0.706683
2024-05-18 18:12:46 Epoch 36: lr=1.25e-05
2024-05-18 18:13:59 [Epoch: 36] loss: 0.004806, mae: 0.049288, r2: 0.768035, val_loss: 0.006066, val_mae: 0.054231, val_r2: 0.706647
2024-05-18 18:13:59 Epoch 37: lr=1.25e-05
2024-05-18 18:15:12 [Epoch: 37] loss: 0.004797, mae: 0.049252, r2: 0.768420, val_loss: 0.006086, val_mae: 0.054239, val_r2: 0.706565
2024-05-18 18:15:12 Epoch 38: lr=1.25e-05
2024-05-18 18:16:26 [Epoch: 38] loss: 0.004793, mae: 0.049220, r2: 0.768552, val_loss: 0.006080, val_mae: 0.054125, val_r2: 0.706443
2024-05-18 18:16:26 Epoch 39: lr=1e-05
2024-05-18 18:17:39 [Epoch: 39] loss: 0.004790, mae: 0.049210, r2: 0.768941, val_loss: 0.006041, val_mae: 0.054189, val_r2: 0.708551
2024-05-18 18:17:39 Epoch 40: lr=1e-05
2024-05-18 18:18:52 [Epoch: 40] loss: 0.004776, mae: 0.049144, r2: 0.769680, val_loss: 0.006085, val_mae: 0.054179, val_r2: 0.705513
2024-05-18 18:18:52 Epoch 41: lr=1e-05
2024-05-18 18:20:05 [Epoch: 41] loss: 0.004767, mae: 0.049099, r2: 0.769701, val_loss: 0.006091, val_mae: 0.054136, val_r2: 0.705923
2024-05-18 18:20:05 Epoch 42: lr=1e-05
2024-05-18 18:21:18 [Epoch: 42] loss: 0.004767, mae: 0.049123, r2: 0.769881, val_loss: 0.006092, val_mae: 0.054136, val_r2: 0.705848
2024-05-18 18:21:18 Epoch 43: lr=1e-05
2024-05-18 18:22:31 [Epoch: 43] loss: 0.004764, mae: 0.049080, r2: 0.769865, val_loss: 0.006088, val_mae: 0.053990, val_r2: 0.706112
2024-05-18 18:22:31 Epoch 44: lr=1e-05
2024-05-18 18:23:43 [Epoch: 44] loss: 0.004756, mae: 0.049057, r2: 0.770230, val_loss: 0.006081, val_mae: 0.054048, val_r2: 0.705617
2024-05-18 18:23:44 Epoch 45: lr=1e-05
2024-05-18 18:24:57 [Epoch: 45] loss: 0.004744, mae: 0.049008, r2: 0.770860, val_loss: 0.006049, val_mae: 0.054047, val_r2: 0.708064
2024-05-18 18:24:57 Epoch 46: lr=1e-05
2024-05-18 18:26:10 [Epoch: 46] loss: 0.004747, mae: 0.049004, r2: 0.770636, val_loss: 0.006099, val_mae: 0.054080, val_r2: 0.705671
2024-05-18 18:26:10 Epoch 47: lr=1e-05
2024-05-18 18:27:23 [Epoch: 47] loss: 0.004741, mae: 0.048950, r2: 0.771055, val_loss: 0.006063, val_mae: 0.053939, val_r2: 0.707226
2024-05-18 18:27:23 Epoch 48: lr=1e-05
2024-05-18 18:28:35 [Epoch: 48] loss: 0.004739, mae: 0.048970, r2: 0.771098, val_loss: 0.006069, val_mae: 0.054150, val_r2: 0.706715
2024-05-18 18:28:35 Epoch 49: lr=1e-05
2024-05-18 18:29:48 [Epoch: 49] loss: 0.004729, mae: 0.048945, r2: 0.771608, val_loss: 0.006079, val_mae: 0.054215, val_r2: 0.706472
2024-05-18 18:29:48 history_length: 50
2024-05-18 18:29:48 stopping: early
2024-05-18 18:29:48 Comparing y_true and y_pred:
2024-05-18 18:29:48   mse: 0.01298031
2024-05-18 18:29:48   mae: 0.10522532
2024-05-18 18:29:48   r2: -9.96213687
2024-05-18 18:29:48   corr: 0.21651592
