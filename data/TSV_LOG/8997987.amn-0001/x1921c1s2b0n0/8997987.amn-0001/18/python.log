2024-05-15 19:35:36 UNO RUN ...
2024-05-15 19:35:36 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8997987.amn-0001/18', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8997987.amn-0001', 'run_id': '18', 'logfile': '/dev/shm/Uno/save/8997987.amn-0001/18/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8997987.amn-0001/18', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1921c1s2b0n0.18.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8997987.amn-0001/18/3.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8997987.amn-0001/18'}
2024-05-15 19:35:36 Feature encoding submodel for cell.rnaseq:
2024-05-15 19:35:36 Model: "cell.rnaseq"
2024-05-15 19:35:36 _________________________________________________________________
2024-05-15 19:35:36  Layer (type)                Output Shape              Param #   
2024-05-15 19:35:36 =================================================================
2024-05-15 19:35:36  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense (Dense)               (None, 1000)              959000    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout (Permane  (None, 1000)              0         
2024-05-15 19:35:36  ntDropout)                                                      
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-15 19:35:36  nentDropout)                                                    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-15 19:35:36  nentDropout)                                                    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36 =================================================================
2024-05-15 19:35:36 Total params: 2961000 (11.30 MB)
2024-05-15 19:35:36 Trainable params: 2961000 (11.30 MB)
2024-05-15 19:35:36 Non-trainable params: 0 (0.00 Byte)
2024-05-15 19:35:36 _________________________________________________________________
2024-05-15 19:35:36 Feature encoding submodel for drug.descriptors:
2024-05-15 19:35:36 Model: "drug.descriptors"
2024-05-15 19:35:36 _________________________________________________________________
2024-05-15 19:35:36  Layer (type)                Output Shape              Param #   
2024-05-15 19:35:36 =================================================================
2024-05-15 19:35:36  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-15 19:35:36  nentDropout)                                                    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-15 19:35:36  nentDropout)                                                    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-15 19:35:36  nentDropout)                                                    
2024-05-15 19:35:36                                                                  
2024-05-15 19:35:36 =================================================================
2024-05-15 19:35:36 Total params: 3616000 (13.79 MB)
2024-05-15 19:35:36 Trainable params: 3616000 (13.79 MB)
2024-05-15 19:35:36 Non-trainable params: 0 (0.00 Byte)
2024-05-15 19:35:36 _________________________________________________________________
2024-05-15 19:35:36 Combined model:
2024-05-15 19:35:36 Model: "model"
2024-05-15 19:35:36 __________________________________________________________________________________________________
2024-05-15 19:35:36  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-15 19:35:36 ==================================================================================================
2024-05-15 19:35:36  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-15 19:35:36  yer)                                                                                             
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-15 19:35:36  nputLayer)                                                                                       
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-15 19:35:36  al)                                                                ]']                           
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-15 19:35:36                                                                      'drug.descriptors[0][0]']    
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-15 19:35:36  nentDropout)                                                                                     
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-15 19:35:36  nentDropout)                                                                                     
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-15 19:35:36  nentDropout)                                                                                     
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-15 19:35:36  nentDropout)                                                                                     
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-15 19:35:36  anentDropout)                                                                                    
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-15 19:35:36                                                                                                   
2024-05-15 19:35:36 ==================================================================================================
2024-05-15 19:35:36 Total params: 12583001 (48.00 MB)
2024-05-15 19:35:36 Trainable params: 12583001 (48.00 MB)
2024-05-15 19:35:36 Non-trainable params: 0 (0.00 Byte)
2024-05-15 19:35:36 __________________________________________________________________________________________________
2024-05-15 19:35:36 CKPT CONSTRUCT...
2024-05-15 19:35:36 CKPT CONSTRUCT OK.
2024-05-15 19:35:36 template model: <keras.src.engine.functional.Functional object at 0x14fe556056d0>
2024-05-15 19:35:38 COMPILE
2024-05-15 19:35:38 Will save weights to: /dev/shm/Uno/save/8997987.amn-0001/18/3.0.model.h5
2024-05-15 19:35:55 Between random pairs in y_val:
2024-05-15 19:35:55   mse: 0.04753559
2024-05-15 19:35:55   mae: 0.15938434
2024-05-15 19:35:55   r2: -0.99204994
2024-05-15 19:35:55   corr: 0.00397503
2024-05-15 19:35:55 Data points per epoch: train = 470167, val = 117542, test = 2711
2024-05-15 19:35:55 Steps per epoch: train = 14692, val = 3673, test = 84
2024-05-15 19:35:55 Epoch 0: lr=0.001
2024-05-15 19:37:07 [Epoch: 0] loss: 0.024521, mae: 0.079176, r2: -1.492327, val_loss: 0.008839, val_mae: 0.066980, val_r2: 0.593978
2024-05-15 19:37:07 Epoch 1: lr=0.00082
2024-05-15 19:38:17 [Epoch: 1] loss: 0.007982, mae: 0.063859, r2: 0.621987, val_loss: 0.008657, val_mae: 0.066488, val_r2: 0.585406
2024-05-15 19:38:17 Epoch 2: lr=0.00064
2024-05-15 19:39:27 [Epoch: 2] loss: 0.007301, mae: 0.060857, r2: 0.653089, val_loss: 0.007271, val_mae: 0.059641, val_r2: 0.654230
2024-05-15 19:39:27 Epoch 3: lr=0.00046
2024-05-15 19:40:37 [Epoch: 3] loss: 0.006831, mae: 0.058644, r2: 0.674823, val_loss: 0.006873, val_mae: 0.059235, val_r2: 0.672136
2024-05-15 19:40:37 Epoch 4: lr=0.00028
2024-05-15 19:41:48 [Epoch: 4] loss: 0.006442, mae: 0.056908, r2: 0.692539, val_loss: 0.006753, val_mae: 0.058579, val_r2: 0.673523
2024-05-15 19:41:48 Epoch 5: lr=0.0001
2024-05-15 19:42:58 [Epoch: 5] loss: 0.006104, mae: 0.055307, r2: 0.707996, val_loss: 0.006447, val_mae: 0.056749, val_r2: 0.691050
2024-05-15 19:42:58 Epoch 6: lr=0.0001
2024-05-15 19:44:08 [Epoch: 6] loss: 0.005999, mae: 0.054819, r2: 0.713048, val_loss: 0.006384, val_mae: 0.055884, val_r2: 0.694316
2024-05-15 19:44:09 Epoch 7: lr=0.0001
2024-05-15 19:45:19 [Epoch: 7] loss: 0.005925, mae: 0.054494, r2: 0.716652, val_loss: 0.006350, val_mae: 0.055834, val_r2: 0.696554
2024-05-15 19:45:19 Epoch 8: lr=0.0001
2024-05-15 19:46:29 [Epoch: 8] loss: 0.005851, mae: 0.054168, r2: 0.720051, val_loss: 0.006308, val_mae: 0.055732, val_r2: 0.698787
2024-05-15 19:46:29 Epoch 9: lr=0.0001
2024-05-15 19:47:39 [Epoch: 9] loss: 0.005795, mae: 0.053898, r2: 0.722332, val_loss: 0.006292, val_mae: 0.055627, val_r2: 0.698920
2024-05-15 19:47:39 Epoch 10: lr=0.0001
2024-05-15 19:48:49 [Epoch: 10] loss: 0.005713, mae: 0.053523, r2: 0.726143, val_loss: 0.006287, val_mae: 0.055448, val_r2: 0.697681
2024-05-15 19:48:49 Epoch 11: lr=0.0001
2024-05-15 19:49:59 [Epoch: 11] loss: 0.005660, mae: 0.053281, r2: 0.728852, val_loss: 0.006257, val_mae: 0.055212, val_r2: 0.700929
2024-05-15 19:50:00 Epoch 12: lr=0.0001
2024-05-15 19:51:10 [Epoch: 12] loss: 0.005616, mae: 0.053081, r2: 0.730738, val_loss: 0.006253, val_mae: 0.055044, val_r2: 0.699084
2024-05-15 19:51:10 Epoch 13: lr=0.0001
2024-05-15 19:52:20 [Epoch: 13] loss: 0.005555, mae: 0.052826, r2: 0.733911, val_loss: 0.006218, val_mae: 0.055180, val_r2: 0.701505
2024-05-15 19:52:20 Epoch 14: lr=5e-05
2024-05-15 19:53:30 [Epoch: 14] loss: 0.005437, mae: 0.052260, r2: 0.739213, val_loss: 0.006160, val_mae: 0.055176, val_r2: 0.704035
2024-05-15 19:53:30 Epoch 15: lr=5e-05
2024-05-15 19:54:40 [Epoch: 15] loss: 0.005395, mae: 0.052071, r2: 0.740945, val_loss: 0.006152, val_mae: 0.054564, val_r2: 0.706102
2024-05-15 19:54:40 Epoch 16: lr=5e-05
2024-05-15 19:55:50 [Epoch: 16] loss: 0.005360, mae: 0.051894, r2: 0.742755, val_loss: 0.006160, val_mae: 0.054742, val_r2: 0.704491
2024-05-15 19:55:51 Epoch 17: lr=5e-05
2024-05-15 19:57:01 [Epoch: 17] loss: 0.005330, mae: 0.051745, r2: 0.744100, val_loss: 0.006143, val_mae: 0.054839, val_r2: 0.705361
2024-05-15 19:57:01 Epoch 18: lr=5e-05
2024-05-15 19:58:12 [Epoch: 18] loss: 0.005303, mae: 0.051667, r2: 0.745588, val_loss: 0.006180, val_mae: 0.054437, val_r2: 0.702804
2024-05-15 19:58:12 Epoch 19: lr=5e-05
2024-05-15 19:59:22 [Epoch: 19] loss: 0.005279, mae: 0.051548, r2: 0.746484, val_loss: 0.006165, val_mae: 0.054517, val_r2: 0.705322
2024-05-15 19:59:23 Epoch 20: lr=2.5e-05
2024-05-15 20:00:33 [Epoch: 20] loss: 0.005205, mae: 0.051185, r2: 0.750036, val_loss: 0.006115, val_mae: 0.054702, val_r2: 0.706262
2024-05-15 20:00:33 Epoch 21: lr=2.5e-05
2024-05-15 20:01:44 [Epoch: 21] loss: 0.005194, mae: 0.051123, r2: 0.750515, val_loss: 0.006139, val_mae: 0.054500, val_r2: 0.706066
2024-05-15 20:01:44 Epoch 22: lr=2.5e-05
2024-05-15 20:02:54 [Epoch: 22] loss: 0.005171, mae: 0.051026, r2: 0.751517, val_loss: 0.006151, val_mae: 0.054875, val_r2: 0.706035
2024-05-15 20:02:54 Epoch 23: lr=2.5e-05
2024-05-15 20:04:04 [Epoch: 23] loss: 0.005169, mae: 0.051015, r2: 0.751592, val_loss: 0.006134, val_mae: 0.054776, val_r2: 0.705509
2024-05-15 20:04:05 Epoch 24: lr=2.5e-05
2024-05-15 20:05:15 [Epoch: 24] loss: 0.005154, mae: 0.050920, r2: 0.752239, val_loss: 0.006118, val_mae: 0.054733, val_r2: 0.706421
2024-05-15 20:05:16 Epoch 25: lr=1.25e-05
2024-05-15 20:06:26 [Epoch: 25] loss: 0.005120, mae: 0.050791, r2: 0.753995, val_loss: 0.006120, val_mae: 0.054630, val_r2: 0.706898
2024-05-15 20:06:27 Epoch 26: lr=1.25e-05
2024-05-15 20:07:37 [Epoch: 26] loss: 0.005108, mae: 0.050737, r2: 0.754313, val_loss: 0.006131, val_mae: 0.054352, val_r2: 0.706633
2024-05-15 20:07:37 Epoch 27: lr=1.25e-05
2024-05-15 20:08:48 [Epoch: 27] loss: 0.005098, mae: 0.050662, r2: 0.754846, val_loss: 0.006134, val_mae: 0.054602, val_r2: 0.705743
2024-05-15 20:08:48 Epoch 28: lr=1.25e-05
2024-05-15 20:09:58 [Epoch: 28] loss: 0.005095, mae: 0.050663, r2: 0.755083, val_loss: 0.006107, val_mae: 0.054431, val_r2: 0.707045
2024-05-15 20:09:58 Epoch 29: lr=1.25e-05
2024-05-15 20:11:09 [Epoch: 29] loss: 0.005088, mae: 0.050629, r2: 0.755393, val_loss: 0.006111, val_mae: 0.054519, val_r2: 0.706634
2024-05-15 20:11:09 Epoch 30: lr=1e-05
2024-05-15 20:12:19 [Epoch: 30] loss: 0.005075, mae: 0.050563, r2: 0.756146, val_loss: 0.006094, val_mae: 0.054356, val_r2: 0.708586
2024-05-15 20:12:19 Epoch 31: lr=1e-05
2024-05-15 20:13:29 [Epoch: 31] loss: 0.005072, mae: 0.050535, r2: 0.756087, val_loss: 0.006103, val_mae: 0.054684, val_r2: 0.707545
2024-05-15 20:13:29 Epoch 32: lr=1e-05
2024-05-15 20:14:39 [Epoch: 32] loss: 0.005068, mae: 0.050524, r2: 0.756237, val_loss: 0.006112, val_mae: 0.054435, val_r2: 0.707326
2024-05-15 20:14:39 Epoch 33: lr=1e-05
2024-05-15 20:15:49 [Epoch: 33] loss: 0.005067, mae: 0.050503, r2: 0.756215, val_loss: 0.006100, val_mae: 0.054381, val_r2: 0.707345
2024-05-15 20:15:49 Epoch 34: lr=1e-05
2024-05-15 20:16:59 [Epoch: 34] loss: 0.005043, mae: 0.050438, r2: 0.757459, val_loss: 0.006086, val_mae: 0.054456, val_r2: 0.708780
2024-05-15 20:16:59 Epoch 35: lr=1e-05
2024-05-15 20:18:09 [Epoch: 35] loss: 0.005041, mae: 0.050407, r2: 0.757511, val_loss: 0.006106, val_mae: 0.054518, val_r2: 0.707490
2024-05-15 20:18:09 Epoch 36: lr=1e-05
2024-05-15 20:19:19 [Epoch: 36] loss: 0.005032, mae: 0.050342, r2: 0.758065, val_loss: 0.006119, val_mae: 0.054498, val_r2: 0.705900
2024-05-15 20:19:19 Epoch 37: lr=1e-05
2024-05-15 20:20:29 [Epoch: 37] loss: 0.005024, mae: 0.050334, r2: 0.758158, val_loss: 0.006113, val_mae: 0.054565, val_r2: 0.707114
2024-05-15 20:20:29 Epoch 38: lr=1e-05
2024-05-15 20:21:39 [Epoch: 38] loss: 0.005038, mae: 0.050380, r2: 0.757729, val_loss: 0.006131, val_mae: 0.054470, val_r2: 0.705468
2024-05-15 20:21:39 Epoch 39: lr=1e-05
2024-05-15 20:22:49 [Epoch: 39] loss: 0.005017, mae: 0.050284, r2: 0.758600, val_loss: 0.006098, val_mae: 0.054392, val_r2: 0.708386
2024-05-15 20:22:49 Epoch 40: lr=1e-05
2024-05-15 20:23:59 [Epoch: 40] loss: 0.005017, mae: 0.050295, r2: 0.758686, val_loss: 0.006104, val_mae: 0.054457, val_r2: 0.707302
2024-05-15 20:23:59 Epoch 41: lr=1e-05
2024-05-15 20:25:09 [Epoch: 41] loss: 0.005003, mae: 0.050215, r2: 0.759251, val_loss: 0.006129, val_mae: 0.054394, val_r2: 0.706276
2024-05-15 20:25:09 Epoch 42: lr=1e-05
2024-05-15 20:26:19 [Epoch: 42] loss: 0.004993, mae: 0.050189, r2: 0.759955, val_loss: 0.006137, val_mae: 0.054286, val_r2: 0.706051
2024-05-15 20:26:19 Epoch 43: lr=1e-05
2024-05-15 20:27:29 [Epoch: 43] loss: 0.005003, mae: 0.050197, r2: 0.759225, val_loss: 0.006080, val_mae: 0.054354, val_r2: 0.708309
2024-05-15 20:27:29 Epoch 44: lr=1e-05
2024-05-15 20:28:39 [Epoch: 44] loss: 0.004991, mae: 0.050164, r2: 0.759917, val_loss: 0.006093, val_mae: 0.054588, val_r2: 0.707535
2024-05-15 20:28:39 Epoch 45: lr=1e-05
2024-05-15 20:29:48 [Epoch: 45] loss: 0.005000, mae: 0.050200, r2: 0.759585, val_loss: 0.006118, val_mae: 0.054502, val_r2: 0.706493
2024-05-15 20:29:48 Epoch 46: lr=1e-05
2024-05-15 20:30:58 [Epoch: 46] loss: 0.004978, mae: 0.050111, r2: 0.760534, val_loss: 0.006115, val_mae: 0.054601, val_r2: 0.706465
2024-05-15 20:30:58 Epoch 47: lr=1e-05
2024-05-15 20:32:08 [Epoch: 47] loss: 0.004980, mae: 0.050091, r2: 0.760182, val_loss: 0.006101, val_mae: 0.054321, val_r2: 0.707369
2024-05-15 20:32:08 Epoch 48: lr=1e-05
2024-05-15 20:33:18 [Epoch: 48] loss: 0.004968, mae: 0.050051, r2: 0.761071, val_loss: 0.006131, val_mae: 0.054502, val_r2: 0.706442
2024-05-15 20:33:18 Epoch 49: lr=1e-05
2024-05-15 20:34:27 [Epoch: 49] loss: 0.004971, mae: 0.050058, r2: 0.761142, val_loss: 0.006077, val_mae: 0.054236, val_r2: 0.708643
2024-05-15 20:34:28 Epoch 50: lr=1e-05
2024-05-15 20:35:37 [Epoch: 50] loss: 0.004960, mae: 0.050020, r2: 0.761554, val_loss: 0.006094, val_mae: 0.054428, val_r2: 0.708384
2024-05-15 20:35:37 Epoch 51: lr=1e-05
2024-05-15 20:36:47 [Epoch: 51] loss: 0.004952, mae: 0.049985, r2: 0.761554, val_loss: 0.006122, val_mae: 0.054213, val_r2: 0.706270
2024-05-15 20:36:47 Epoch 52: lr=1e-05
2024-05-15 20:37:57 [Epoch: 52] loss: 0.004951, mae: 0.049971, r2: 0.761664, val_loss: 0.006115, val_mae: 0.054356, val_r2: 0.707482
2024-05-15 20:37:57 Epoch 53: lr=1e-05
2024-05-15 20:39:07 [Epoch: 53] loss: 0.004955, mae: 0.049989, r2: 0.761600, val_loss: 0.006119, val_mae: 0.054415, val_r2: 0.706426
2024-05-15 20:39:07 Epoch 54: lr=1e-05
2024-05-15 20:40:17 [Epoch: 54] loss: 0.004940, mae: 0.049933, r2: 0.762312, val_loss: 0.006087, val_mae: 0.054295, val_r2: 0.708309
2024-05-15 20:40:17 Epoch 55: lr=1e-05
2024-05-15 20:41:26 [Epoch: 55] loss: 0.004935, mae: 0.049882, r2: 0.762446, val_loss: 0.006113, val_mae: 0.054382, val_r2: 0.707248
2024-05-15 20:41:27 Epoch 56: lr=1e-05
2024-05-15 20:42:36 [Epoch: 56] loss: 0.004929, mae: 0.049862, r2: 0.762926, val_loss: 0.006107, val_mae: 0.054449, val_r2: 0.707373
2024-05-15 20:42:37 Epoch 57: lr=1e-05
2024-05-15 20:43:47 [Epoch: 57] loss: 0.004930, mae: 0.049849, r2: 0.762571, val_loss: 0.006124, val_mae: 0.054335, val_r2: 0.706167
2024-05-15 20:43:47 Epoch 58: lr=1e-05
2024-05-15 20:44:56 [Epoch: 58] loss: 0.004913, mae: 0.049813, r2: 0.763663, val_loss: 0.006084, val_mae: 0.054256, val_r2: 0.708649
2024-05-15 20:44:56 Epoch 59: lr=1e-05
2024-05-15 20:46:07 [Epoch: 59] loss: 0.004906, mae: 0.049778, r2: 0.763794, val_loss: 0.006128, val_mae: 0.054236, val_r2: 0.706793
2024-05-15 20:46:07 history_length: 60
2024-05-15 20:46:07 stopping: early
2024-05-15 20:46:07 Comparing y_true and y_pred:
2024-05-15 20:46:07   mse: 0.00325672
2024-05-15 20:46:07   mae: 0.04337332
2024-05-15 20:46:07   r2: 0.23526645
2024-05-15 20:46:07   corr: 0.48653772
