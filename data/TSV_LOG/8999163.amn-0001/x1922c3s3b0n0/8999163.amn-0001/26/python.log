2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/26', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '26', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/26/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/26', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s3b0n0.26.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/26/1.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/26'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x150cc4502bb0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/26/1.0.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04777165
2024-05-18 13:20:02   mae: 0.15971067
2024-05-18 13:20:02   r2: -0.99490036
2024-05-18 13:20:02   corr: 0.00254982
2024-05-18 13:20:02 Data points per epoch: train = 466697, val = 116675, test = 4337
2024-05-18 13:20:02 Steps per epoch: train = 14584, val = 3646, test = 135
2024-05-18 13:20:03 Epoch 0: lr=0.001
2024-05-18 13:21:16 [Epoch: 0] loss: 0.026469, mae: 0.079419, r2: -0.314660, val_loss: 0.009202, val_mae: 0.073267, val_r2: 0.559391
2024-05-18 13:21:16 Epoch 1: lr=0.00082
2024-05-18 13:22:27 [Epoch: 1] loss: 0.007980, mae: 0.063817, r2: 0.624360, val_loss: 0.007747, val_mae: 0.061855, val_r2: 0.634717
2024-05-18 13:22:27 Epoch 2: lr=0.00064
2024-05-18 13:23:38 [Epoch: 2] loss: 0.007303, mae: 0.060747, r2: 0.654969, val_loss: 0.007379, val_mae: 0.061931, val_r2: 0.648266
2024-05-18 13:23:38 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006839, mae: 0.058616, r2: 0.676654, val_loss: 0.006799, val_mae: 0.058458, val_r2: 0.676970
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:01 [Epoch: 4] loss: 0.006442, mae: 0.056793, r2: 0.694440, val_loss: 0.006606, val_mae: 0.056634, val_r2: 0.681851
2024-05-18 13:26:01 Epoch 5: lr=0.0001
2024-05-18 13:27:13 [Epoch: 5] loss: 0.006106, mae: 0.055222, r2: 0.710191, val_loss: 0.006400, val_mae: 0.056459, val_r2: 0.692954
2024-05-18 13:27:13 Epoch 6: lr=0.0001
2024-05-18 13:28:25 [Epoch: 6] loss: 0.006003, mae: 0.054762, r2: 0.714929, val_loss: 0.006348, val_mae: 0.055848, val_r2: 0.695964
2024-05-18 13:28:25 Epoch 7: lr=0.0001
2024-05-18 13:29:36 [Epoch: 7] loss: 0.005924, mae: 0.054400, r2: 0.718536, val_loss: 0.006353, val_mae: 0.055925, val_r2: 0.694699
2024-05-18 13:29:36 Epoch 8: lr=0.0001
2024-05-18 13:30:46 [Epoch: 8] loss: 0.005849, mae: 0.054054, r2: 0.721813, val_loss: 0.006307, val_mae: 0.056242, val_r2: 0.698381
2024-05-18 13:30:47 Epoch 9: lr=0.0001
2024-05-18 13:31:58 [Epoch: 9] loss: 0.005785, mae: 0.053780, r2: 0.724906, val_loss: 0.006266, val_mae: 0.055603, val_r2: 0.700518
2024-05-18 13:31:58 Epoch 10: lr=0.0001
2024-05-18 13:33:10 [Epoch: 10] loss: 0.005728, mae: 0.053508, r2: 0.727521, val_loss: 0.006216, val_mae: 0.055032, val_r2: 0.703666
2024-05-18 13:33:10 Epoch 11: lr=0.0001
2024-05-18 13:34:21 [Epoch: 11] loss: 0.005669, mae: 0.053238, r2: 0.730232, val_loss: 0.006211, val_mae: 0.055345, val_r2: 0.701625
2024-05-18 13:34:21 Epoch 12: lr=0.0001
2024-05-18 13:35:33 [Epoch: 12] loss: 0.005608, mae: 0.052976, r2: 0.733098, val_loss: 0.006195, val_mae: 0.054719, val_r2: 0.703759
2024-05-18 13:35:33 Epoch 13: lr=0.0001
2024-05-18 13:36:44 [Epoch: 13] loss: 0.005555, mae: 0.052726, r2: 0.735449, val_loss: 0.006166, val_mae: 0.054718, val_r2: 0.706079
2024-05-18 13:36:44 Epoch 14: lr=0.0001
2024-05-18 13:37:56 [Epoch: 14] loss: 0.005507, mae: 0.052523, r2: 0.737574, val_loss: 0.006166, val_mae: 0.055103, val_r2: 0.703789
2024-05-18 13:37:56 Epoch 15: lr=0.0001
2024-05-18 13:39:08 [Epoch: 15] loss: 0.005453, mae: 0.052274, r2: 0.740419, val_loss: 0.006131, val_mae: 0.055295, val_r2: 0.706038
2024-05-18 13:39:08 Epoch 16: lr=0.0001
2024-05-18 13:40:19 [Epoch: 16] loss: 0.005405, mae: 0.052013, r2: 0.742596, val_loss: 0.006143, val_mae: 0.055029, val_r2: 0.704820
2024-05-18 13:40:19 Epoch 17: lr=0.0001
2024-05-18 13:41:31 [Epoch: 17] loss: 0.005350, mae: 0.051780, r2: 0.745203, val_loss: 0.006085, val_mae: 0.054482, val_r2: 0.709175
2024-05-18 13:41:31 Epoch 18: lr=0.0001
2024-05-18 13:42:43 [Epoch: 18] loss: 0.005301, mae: 0.051562, r2: 0.747435, val_loss: 0.006126, val_mae: 0.054223, val_r2: 0.706634
2024-05-18 13:42:43 Epoch 19: lr=5e-05
2024-05-18 13:43:54 [Epoch: 19] loss: 0.005186, mae: 0.050982, r2: 0.752911, val_loss: 0.006087, val_mae: 0.054366, val_r2: 0.707647
2024-05-18 13:43:54 Epoch 20: lr=5e-05
2024-05-18 13:45:05 [Epoch: 20] loss: 0.005148, mae: 0.050817, r2: 0.754510, val_loss: 0.006059, val_mae: 0.054106, val_r2: 0.709945
2024-05-18 13:45:05 Epoch 21: lr=5e-05
2024-05-18 13:46:16 [Epoch: 21] loss: 0.005119, mae: 0.050691, r2: 0.756051, val_loss: 0.006037, val_mae: 0.054330, val_r2: 0.710788
2024-05-18 13:46:16 Epoch 22: lr=5e-05
2024-05-18 13:47:28 [Epoch: 22] loss: 0.005092, mae: 0.050554, r2: 0.756957, val_loss: 0.006068, val_mae: 0.054214, val_r2: 0.708959
2024-05-18 13:47:28 Epoch 23: lr=5e-05
2024-05-18 13:48:40 [Epoch: 23] loss: 0.005067, mae: 0.050415, r2: 0.758233, val_loss: 0.006085, val_mae: 0.054376, val_r2: 0.707660
2024-05-18 13:48:40 Epoch 24: lr=5e-05
2024-05-18 13:49:51 [Epoch: 24] loss: 0.005030, mae: 0.050269, r2: 0.759908, val_loss: 0.006026, val_mae: 0.054180, val_r2: 0.711320
2024-05-18 13:49:51 Epoch 25: lr=5e-05
2024-05-18 13:51:02 [Epoch: 25] loss: 0.005013, mae: 0.050141, r2: 0.760602, val_loss: 0.006025, val_mae: 0.054074, val_r2: 0.711031
2024-05-18 13:51:03 Epoch 26: lr=2.5e-05
2024-05-18 13:52:14 [Epoch: 26] loss: 0.004960, mae: 0.049922, r2: 0.763101, val_loss: 0.006027, val_mae: 0.054436, val_r2: 0.710613
2024-05-18 13:52:14 Epoch 27: lr=2.5e-05
2024-05-18 13:53:26 [Epoch: 27] loss: 0.004937, mae: 0.049806, r2: 0.764137, val_loss: 0.006024, val_mae: 0.053932, val_r2: 0.711260
2024-05-18 13:53:26 Epoch 28: lr=2.5e-05
2024-05-18 13:54:38 [Epoch: 28] loss: 0.004923, mae: 0.049764, r2: 0.764778, val_loss: 0.006016, val_mae: 0.054108, val_r2: 0.711088
2024-05-18 13:54:38 Epoch 29: lr=2.5e-05
2024-05-18 13:55:48 [Epoch: 29] loss: 0.004902, mae: 0.049654, r2: 0.765850, val_loss: 0.006044, val_mae: 0.054167, val_r2: 0.709704
2024-05-18 13:55:49 Epoch 30: lr=2.5e-05
2024-05-18 13:57:00 [Epoch: 30] loss: 0.004890, mae: 0.049611, r2: 0.766403, val_loss: 0.006028, val_mae: 0.054027, val_r2: 0.710335
2024-05-18 13:57:00 Epoch 31: lr=1.25e-05
2024-05-18 13:58:12 [Epoch: 31] loss: 0.004865, mae: 0.049447, r2: 0.767573, val_loss: 0.006021, val_mae: 0.053971, val_r2: 0.711319
2024-05-18 13:58:12 Epoch 32: lr=1.25e-05
2024-05-18 13:59:23 [Epoch: 32] loss: 0.004843, mae: 0.049372, r2: 0.768717, val_loss: 0.006041, val_mae: 0.053981, val_r2: 0.710265
2024-05-18 13:59:23 Epoch 33: lr=1.25e-05
2024-05-18 14:00:34 [Epoch: 33] loss: 0.004844, mae: 0.049329, r2: 0.768452, val_loss: 0.006027, val_mae: 0.054082, val_r2: 0.710968
2024-05-18 14:00:34 Epoch 34: lr=1.25e-05
2024-05-18 14:01:46 [Epoch: 34] loss: 0.004845, mae: 0.049353, r2: 0.768419, val_loss: 0.006025, val_mae: 0.054004, val_r2: 0.710867
2024-05-18 14:01:46 Epoch 35: lr=1.25e-05
2024-05-18 14:02:57 [Epoch: 35] loss: 0.004828, mae: 0.049281, r2: 0.769216, val_loss: 0.006038, val_mae: 0.053906, val_r2: 0.710652
2024-05-18 14:02:57 Epoch 36: lr=1e-05
2024-05-18 14:04:09 [Epoch: 36] loss: 0.004828, mae: 0.049268, r2: 0.769264, val_loss: 0.006013, val_mae: 0.054006, val_r2: 0.711613
2024-05-18 14:04:09 Epoch 37: lr=1e-05
2024-05-18 14:05:20 [Epoch: 37] loss: 0.004816, mae: 0.049210, r2: 0.769751, val_loss: 0.006028, val_mae: 0.054072, val_r2: 0.710837
2024-05-18 14:05:20 Epoch 38: lr=1e-05
2024-05-18 14:06:32 [Epoch: 38] loss: 0.004808, mae: 0.049196, r2: 0.770028, val_loss: 0.006015, val_mae: 0.053895, val_r2: 0.711364
2024-05-18 14:06:32 Epoch 39: lr=1e-05
2024-05-18 14:07:44 [Epoch: 39] loss: 0.004806, mae: 0.049172, r2: 0.770242, val_loss: 0.006040, val_mae: 0.053996, val_r2: 0.710499
2024-05-18 14:07:44 Epoch 40: lr=1e-05
2024-05-18 14:08:55 [Epoch: 40] loss: 0.004806, mae: 0.049215, r2: 0.770296, val_loss: 0.006041, val_mae: 0.053948, val_r2: 0.710683
2024-05-18 14:08:56 Epoch 41: lr=1e-05
2024-05-18 14:10:07 [Epoch: 41] loss: 0.004799, mae: 0.049152, r2: 0.770549, val_loss: 0.006028, val_mae: 0.053966, val_r2: 0.710483
2024-05-18 14:10:07 Epoch 42: lr=1e-05
2024-05-18 14:11:18 [Epoch: 42] loss: 0.004795, mae: 0.049129, r2: 0.770936, val_loss: 0.006038, val_mae: 0.053936, val_r2: 0.709660
2024-05-18 14:11:18 Epoch 43: lr=1e-05
2024-05-18 14:12:29 [Epoch: 43] loss: 0.004791, mae: 0.049090, r2: 0.770920, val_loss: 0.006031, val_mae: 0.054068, val_r2: 0.710668
2024-05-18 14:12:30 Epoch 44: lr=1e-05
2024-05-18 14:13:40 [Epoch: 44] loss: 0.004772, mae: 0.049020, r2: 0.771832, val_loss: 0.006029, val_mae: 0.053947, val_r2: 0.710723
2024-05-18 14:13:40 Epoch 45: lr=1e-05
2024-05-18 14:14:52 [Epoch: 45] loss: 0.004763, mae: 0.048943, r2: 0.772327, val_loss: 0.006060, val_mae: 0.053985, val_r2: 0.709707
2024-05-18 14:14:52 Epoch 46: lr=1e-05
2024-05-18 14:16:03 [Epoch: 46] loss: 0.004766, mae: 0.048998, r2: 0.772134, val_loss: 0.006012, val_mae: 0.053908, val_r2: 0.711729
2024-05-18 14:16:03 Epoch 47: lr=1e-05
2024-05-18 14:17:14 [Epoch: 47] loss: 0.004772, mae: 0.048974, r2: 0.771672, val_loss: 0.006035, val_mae: 0.054079, val_r2: 0.710877
2024-05-18 14:17:14 Epoch 48: lr=1e-05
2024-05-18 14:18:25 [Epoch: 48] loss: 0.004765, mae: 0.049002, r2: 0.771919, val_loss: 0.006038, val_mae: 0.054008, val_r2: 0.710403
2024-05-18 14:18:25 Epoch 49: lr=1e-05
2024-05-18 14:19:36 [Epoch: 49] loss: 0.004761, mae: 0.048975, r2: 0.772363, val_loss: 0.006012, val_mae: 0.053938, val_r2: 0.711948
2024-05-18 14:19:36 Epoch 50: lr=1e-05
2024-05-18 14:20:47 [Epoch: 50] loss: 0.004755, mae: 0.048929, r2: 0.772751, val_loss: 0.006067, val_mae: 0.053971, val_r2: 0.708978
2024-05-18 14:20:47 Epoch 51: lr=1e-05
2024-05-18 14:21:59 [Epoch: 51] loss: 0.004741, mae: 0.048849, r2: 0.773349, val_loss: 0.006030, val_mae: 0.053978, val_r2: 0.710949
2024-05-18 14:21:59 Epoch 52: lr=1e-05
2024-05-18 14:23:10 [Epoch: 52] loss: 0.004731, mae: 0.048812, r2: 0.773896, val_loss: 0.006030, val_mae: 0.053867, val_r2: 0.711204
2024-05-18 14:23:10 Epoch 53: lr=1e-05
2024-05-18 14:24:21 [Epoch: 53] loss: 0.004732, mae: 0.048812, r2: 0.773705, val_loss: 0.006013, val_mae: 0.053934, val_r2: 0.711539
2024-05-18 14:24:21 Epoch 54: lr=1e-05
2024-05-18 14:25:32 [Epoch: 54] loss: 0.004725, mae: 0.048785, r2: 0.774154, val_loss: 0.006036, val_mae: 0.054026, val_r2: 0.710015
2024-05-18 14:25:32 Epoch 55: lr=1e-05
2024-05-18 14:26:43 [Epoch: 55] loss: 0.004719, mae: 0.048777, r2: 0.774260, val_loss: 0.006044, val_mae: 0.054007, val_r2: 0.709982
2024-05-18 14:26:43 Epoch 56: lr=1e-05
2024-05-18 14:27:53 [Epoch: 56] loss: 0.004722, mae: 0.048761, r2: 0.773960, val_loss: 0.006023, val_mae: 0.053850, val_r2: 0.711428
2024-05-18 14:27:54 history_length: 57
2024-05-18 14:27:54 stopping: early
2024-05-18 14:27:54 Comparing y_true and y_pred:
2024-05-18 14:27:54   mse: 0.01093734
2024-05-18 14:27:54   mae: 0.08410347
2024-05-18 14:27:54   r2: 0.22110935
2024-05-18 14:27:54   corr: 0.50585177
