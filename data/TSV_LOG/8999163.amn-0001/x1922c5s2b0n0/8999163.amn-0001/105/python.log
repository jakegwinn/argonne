2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/105', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '105', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/105/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/105', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s2b0n0.105.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/105/4.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/105'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x14bb1fcaec40>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/105/4.1.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04674215
2024-05-18 13:20:01   mae: 0.15829718
2024-05-18 13:20:01   r2: -0.99962151
2024-05-18 13:20:01   corr: 0.00018925
2024-05-18 13:20:01 Data points per epoch: train = 469286, val = 117322, test = 1101
2024-05-18 13:20:01 Steps per epoch: train = 14665, val = 3666, test = 34
2024-05-18 13:20:01 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.027559, mae: 0.079474, r2: 0.068102, val_loss: 0.009578, val_mae: 0.071797, val_r2: 0.538660
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:26 [Epoch: 1] loss: 0.007930, mae: 0.063828, r2: 0.618525, val_loss: 0.007668, val_mae: 0.062644, val_r2: 0.634564
2024-05-18 13:22:26 Epoch 2: lr=0.00064
2024-05-18 13:23:38 [Epoch: 2] loss: 0.007262, mae: 0.060751, r2: 0.649825, val_loss: 0.007042, val_mae: 0.060127, val_r2: 0.660205
2024-05-18 13:23:38 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006771, mae: 0.058503, r2: 0.672387, val_loss: 0.006884, val_mae: 0.060082, val_r2: 0.669195
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:01 [Epoch: 4] loss: 0.006375, mae: 0.056636, r2: 0.691031, val_loss: 0.006488, val_mae: 0.057935, val_r2: 0.687779
2024-05-18 13:26:01 Epoch 5: lr=0.0001
2024-05-18 13:27:13 [Epoch: 5] loss: 0.006041, mae: 0.055122, r2: 0.706773, val_loss: 0.006307, val_mae: 0.055682, val_r2: 0.694860
2024-05-18 13:27:13 Epoch 6: lr=0.0001
2024-05-18 13:28:25 [Epoch: 6] loss: 0.005946, mae: 0.054683, r2: 0.711004, val_loss: 0.006261, val_mae: 0.055665, val_r2: 0.696596
2024-05-18 13:28:25 Epoch 7: lr=0.0001
2024-05-18 13:29:37 [Epoch: 7] loss: 0.005863, mae: 0.054273, r2: 0.715250, val_loss: 0.006302, val_mae: 0.056464, val_r2: 0.693228
2024-05-18 13:29:37 Epoch 8: lr=0.0001
2024-05-18 13:30:49 [Epoch: 8] loss: 0.005784, mae: 0.053921, r2: 0.718721, val_loss: 0.006212, val_mae: 0.055210, val_r2: 0.699508
2024-05-18 13:30:49 Epoch 9: lr=0.0001
2024-05-18 13:32:01 [Epoch: 9] loss: 0.005719, mae: 0.053629, r2: 0.721754, val_loss: 0.006205, val_mae: 0.055255, val_r2: 0.700547
2024-05-18 13:32:01 Epoch 10: lr=0.0001
2024-05-18 13:33:12 [Epoch: 10] loss: 0.005668, mae: 0.053413, r2: 0.724374, val_loss: 0.006176, val_mae: 0.055413, val_r2: 0.701156
2024-05-18 13:33:12 Epoch 11: lr=0.0001
2024-05-18 13:34:24 [Epoch: 11] loss: 0.005598, mae: 0.053090, r2: 0.727657, val_loss: 0.006139, val_mae: 0.055470, val_r2: 0.702855
2024-05-18 13:34:24 Epoch 12: lr=0.0001
2024-05-18 13:35:36 [Epoch: 12] loss: 0.005556, mae: 0.052885, r2: 0.729344, val_loss: 0.006107, val_mae: 0.055145, val_r2: 0.704198
2024-05-18 13:35:36 Epoch 13: lr=0.0001
2024-05-18 13:36:48 [Epoch: 13] loss: 0.005496, mae: 0.052625, r2: 0.732207, val_loss: 0.006093, val_mae: 0.054968, val_r2: 0.705089
2024-05-18 13:36:48 Epoch 14: lr=0.0001
2024-05-18 13:38:00 [Epoch: 14] loss: 0.005434, mae: 0.052344, r2: 0.735242, val_loss: 0.006097, val_mae: 0.055327, val_r2: 0.705387
2024-05-18 13:38:00 Epoch 15: lr=0.0001
2024-05-18 13:39:12 [Epoch: 15] loss: 0.005385, mae: 0.052132, r2: 0.737299, val_loss: 0.006076, val_mae: 0.054472, val_r2: 0.705265
2024-05-18 13:39:12 Epoch 16: lr=0.0001
2024-05-18 13:40:23 [Epoch: 16] loss: 0.005330, mae: 0.051848, r2: 0.739816, val_loss: 0.006064, val_mae: 0.054344, val_r2: 0.706622
2024-05-18 13:40:23 Epoch 17: lr=0.0001
2024-05-18 13:41:35 [Epoch: 17] loss: 0.005292, mae: 0.051671, r2: 0.741739, val_loss: 0.006042, val_mae: 0.055095, val_r2: 0.705849
2024-05-18 13:41:35 Epoch 18: lr=0.0001
2024-05-18 13:42:47 [Epoch: 18] loss: 0.005227, mae: 0.051379, r2: 0.744786, val_loss: 0.006038, val_mae: 0.054254, val_r2: 0.705926
2024-05-18 13:42:47 Epoch 19: lr=5e-05
2024-05-18 13:43:58 [Epoch: 19] loss: 0.005119, mae: 0.050836, r2: 0.750060, val_loss: 0.006028, val_mae: 0.054277, val_r2: 0.707444
2024-05-18 13:43:58 Epoch 20: lr=5e-05
2024-05-18 13:45:10 [Epoch: 20] loss: 0.005076, mae: 0.050681, r2: 0.751830, val_loss: 0.005990, val_mae: 0.054386, val_r2: 0.708707
2024-05-18 13:45:10 Epoch 21: lr=5e-05
2024-05-18 13:46:21 [Epoch: 21] loss: 0.005054, mae: 0.050539, r2: 0.752935, val_loss: 0.006003, val_mae: 0.053901, val_r2: 0.708273
2024-05-18 13:46:21 Epoch 22: lr=5e-05
2024-05-18 13:47:33 [Epoch: 22] loss: 0.005021, mae: 0.050375, r2: 0.754505, val_loss: 0.006006, val_mae: 0.053920, val_r2: 0.709372
2024-05-18 13:47:33 Epoch 23: lr=5e-05
2024-05-18 13:48:45 [Epoch: 23] loss: 0.004992, mae: 0.050271, r2: 0.755800, val_loss: 0.006015, val_mae: 0.054071, val_r2: 0.709009
2024-05-18 13:48:45 Epoch 24: lr=5e-05
2024-05-18 13:49:57 [Epoch: 24] loss: 0.004971, mae: 0.050150, r2: 0.756970, val_loss: 0.005987, val_mae: 0.054322, val_r2: 0.709206
2024-05-18 13:49:57 Epoch 25: lr=5e-05
2024-05-18 13:51:09 [Epoch: 25] loss: 0.004957, mae: 0.050073, r2: 0.757476, val_loss: 0.006002, val_mae: 0.054101, val_r2: 0.708603
2024-05-18 13:51:09 Epoch 26: lr=2.5e-05
2024-05-18 13:52:20 [Epoch: 26] loss: 0.004884, mae: 0.049769, r2: 0.761122, val_loss: 0.005990, val_mae: 0.054167, val_r2: 0.708935
2024-05-18 13:52:20 Epoch 27: lr=2.5e-05
2024-05-18 13:53:32 [Epoch: 27] loss: 0.004871, mae: 0.049678, r2: 0.761594, val_loss: 0.005990, val_mae: 0.053947, val_r2: 0.709054
2024-05-18 13:53:32 Epoch 28: lr=2.5e-05
2024-05-18 13:54:44 [Epoch: 28] loss: 0.004864, mae: 0.049606, r2: 0.761910, val_loss: 0.006001, val_mae: 0.054007, val_r2: 0.708673
2024-05-18 13:54:44 Epoch 29: lr=2.5e-05
2024-05-18 13:55:56 [Epoch: 29] loss: 0.004835, mae: 0.049515, r2: 0.763154, val_loss: 0.005996, val_mae: 0.053765, val_r2: 0.708721
2024-05-18 13:55:56 Epoch 30: lr=2.5e-05
2024-05-18 13:57:07 [Epoch: 30] loss: 0.004828, mae: 0.049435, r2: 0.763690, val_loss: 0.005990, val_mae: 0.053947, val_r2: 0.708875
2024-05-18 13:57:07 Epoch 31: lr=1.25e-05
2024-05-18 13:58:19 [Epoch: 31] loss: 0.004791, mae: 0.049266, r2: 0.765060, val_loss: 0.006019, val_mae: 0.054058, val_r2: 0.707248
2024-05-18 13:58:19 Epoch 32: lr=1.25e-05
2024-05-18 13:59:31 [Epoch: 32] loss: 0.004784, mae: 0.049254, r2: 0.765659, val_loss: 0.005995, val_mae: 0.053999, val_r2: 0.709141
2024-05-18 13:59:31 Epoch 33: lr=1.25e-05
2024-05-18 14:00:43 [Epoch: 33] loss: 0.004777, mae: 0.049204, r2: 0.765995, val_loss: 0.006015, val_mae: 0.054005, val_r2: 0.708163
2024-05-18 14:00:43 Epoch 34: lr=1.25e-05
2024-05-18 14:01:55 [Epoch: 34] loss: 0.004765, mae: 0.049148, r2: 0.766347, val_loss: 0.005977, val_mae: 0.053707, val_r2: 0.709972
2024-05-18 14:01:55 Epoch 35: lr=1.25e-05
2024-05-18 14:03:06 [Epoch: 35] loss: 0.004761, mae: 0.049146, r2: 0.766522, val_loss: 0.006003, val_mae: 0.054135, val_r2: 0.707896
2024-05-18 14:03:06 Epoch 36: lr=1e-05
2024-05-18 14:04:18 [Epoch: 36] loss: 0.004754, mae: 0.049122, r2: 0.767135, val_loss: 0.005989, val_mae: 0.053967, val_r2: 0.708839
2024-05-18 14:04:18 Epoch 37: lr=1e-05
2024-05-18 14:05:29 [Epoch: 37] loss: 0.004749, mae: 0.049066, r2: 0.767320, val_loss: 0.005974, val_mae: 0.053915, val_r2: 0.709477
2024-05-18 14:05:30 Epoch 38: lr=1e-05
2024-05-18 14:06:41 [Epoch: 38] loss: 0.004745, mae: 0.049073, r2: 0.767424, val_loss: 0.005976, val_mae: 0.053932, val_r2: 0.709973
2024-05-18 14:06:41 Epoch 39: lr=1e-05
2024-05-18 14:07:53 [Epoch: 39] loss: 0.004740, mae: 0.049041, r2: 0.767789, val_loss: 0.005994, val_mae: 0.053941, val_r2: 0.708377
2024-05-18 14:07:53 Epoch 40: lr=1e-05
2024-05-18 14:09:04 [Epoch: 40] loss: 0.004743, mae: 0.049028, r2: 0.767518, val_loss: 0.005964, val_mae: 0.053711, val_r2: 0.709968
2024-05-18 14:09:04 Epoch 41: lr=1e-05
2024-05-18 14:10:16 [Epoch: 41] loss: 0.004715, mae: 0.048897, r2: 0.768893, val_loss: 0.005953, val_mae: 0.053967, val_r2: 0.710723
2024-05-18 14:10:16 Epoch 42: lr=1e-05
2024-05-18 14:11:28 [Epoch: 42] loss: 0.004726, mae: 0.048952, r2: 0.768309, val_loss: 0.005998, val_mae: 0.053961, val_r2: 0.708665
2024-05-18 14:11:28 Epoch 43: lr=1e-05
2024-05-18 14:12:40 [Epoch: 43] loss: 0.004717, mae: 0.048913, r2: 0.769080, val_loss: 0.005976, val_mae: 0.053756, val_r2: 0.709604
2024-05-18 14:12:40 Epoch 44: lr=1e-05
2024-05-18 14:13:51 [Epoch: 44] loss: 0.004709, mae: 0.048841, r2: 0.769159, val_loss: 0.005987, val_mae: 0.053953, val_r2: 0.708706
2024-05-18 14:13:51 Epoch 45: lr=1e-05
2024-05-18 14:15:03 [Epoch: 45] loss: 0.004705, mae: 0.048836, r2: 0.769533, val_loss: 0.005987, val_mae: 0.053995, val_r2: 0.708974
2024-05-18 14:15:03 Epoch 46: lr=1e-05
2024-05-18 14:16:15 [Epoch: 46] loss: 0.004708, mae: 0.048872, r2: 0.769234, val_loss: 0.005982, val_mae: 0.053853, val_r2: 0.709654
2024-05-18 14:16:15 Epoch 47: lr=1e-05
2024-05-18 14:17:26 [Epoch: 47] loss: 0.004700, mae: 0.048826, r2: 0.769527, val_loss: 0.006003, val_mae: 0.054008, val_r2: 0.708198
2024-05-18 14:17:26 Epoch 48: lr=1e-05
2024-05-18 14:18:38 [Epoch: 48] loss: 0.004687, mae: 0.048782, r2: 0.770176, val_loss: 0.005999, val_mae: 0.053855, val_r2: 0.708491
2024-05-18 14:18:38 Epoch 49: lr=1e-05
2024-05-18 14:19:49 [Epoch: 49] loss: 0.004684, mae: 0.048742, r2: 0.770469, val_loss: 0.006000, val_mae: 0.053892, val_r2: 0.707680
2024-05-18 14:19:49 Epoch 50: lr=1e-05
2024-05-18 14:21:01 [Epoch: 50] loss: 0.004696, mae: 0.048798, r2: 0.769895, val_loss: 0.006002, val_mae: 0.053825, val_r2: 0.708767
2024-05-18 14:21:01 Epoch 51: lr=1e-05
2024-05-18 14:22:12 [Epoch: 51] loss: 0.004670, mae: 0.048696, r2: 0.771096, val_loss: 0.006014, val_mae: 0.053924, val_r2: 0.707986
2024-05-18 14:22:13 history_length: 52
2024-05-18 14:22:13 stopping: early
2024-05-18 14:22:13 Comparing y_true and y_pred:
2024-05-18 14:22:13   mse: 0.12347965
2024-05-18 14:22:13   mae: 0.31376119
2024-05-18 14:22:13   r2: -1.26353848
2024-05-18 14:22:13   corr: 0.14697807
