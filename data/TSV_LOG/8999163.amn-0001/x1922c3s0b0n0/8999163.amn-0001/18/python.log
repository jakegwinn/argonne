2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/18', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '18', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/18/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/18', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s0b0n0.18.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/18/3.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/18'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x15223a780730>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/18/3.0.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04757616
2024-05-18 13:20:02   mae: 0.15978125
2024-05-18 13:20:02   r2: -1.00333141
2024-05-18 13:20:02   corr: -0.00166570
2024-05-18 13:20:02 Data points per epoch: train = 467379, val = 116845, test = 3485
2024-05-18 13:20:02 Steps per epoch: train = 14605, val = 3651, test = 108
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.024873, mae: 0.079568, r2: -0.169465, val_loss: 0.008763, val_mae: 0.069211, val_r2: 0.578678
2024-05-18 13:21:14 Epoch 1: lr=0.00082
2024-05-18 13:22:24 [Epoch: 1] loss: 0.008016, mae: 0.064018, r2: 0.621395, val_loss: 0.007579, val_mae: 0.063045, val_r2: 0.640851
2024-05-18 13:22:24 Epoch 2: lr=0.00064
2024-05-18 13:23:34 [Epoch: 2] loss: 0.007345, mae: 0.060884, r2: 0.651998, val_loss: 0.007138, val_mae: 0.059170, val_r2: 0.661706
2024-05-18 13:23:34 Epoch 3: lr=0.00046
2024-05-18 13:24:44 [Epoch: 3] loss: 0.006878, mae: 0.058809, r2: 0.673412, val_loss: 0.006806, val_mae: 0.058688, val_r2: 0.678045
2024-05-18 13:24:44 Epoch 4: lr=0.00028
2024-05-18 13:25:54 [Epoch: 4] loss: 0.006480, mae: 0.057018, r2: 0.691537, val_loss: 0.006558, val_mae: 0.056694, val_r2: 0.690314
2024-05-18 13:25:54 Epoch 5: lr=0.0001
2024-05-18 13:27:04 [Epoch: 5] loss: 0.006149, mae: 0.055469, r2: 0.706810, val_loss: 0.006379, val_mae: 0.055922, val_r2: 0.695133
2024-05-18 13:27:04 Epoch 6: lr=0.0001
2024-05-18 13:28:14 [Epoch: 6] loss: 0.006035, mae: 0.054954, r2: 0.711938, val_loss: 0.006343, val_mae: 0.056422, val_r2: 0.697290
2024-05-18 13:28:14 Epoch 7: lr=0.0001
2024-05-18 13:29:24 [Epoch: 7] loss: 0.005959, mae: 0.054649, r2: 0.715464, val_loss: 0.006303, val_mae: 0.055839, val_r2: 0.699545
2024-05-18 13:29:24 Epoch 8: lr=0.0001
2024-05-18 13:30:34 [Epoch: 8] loss: 0.005891, mae: 0.054304, r2: 0.718667, val_loss: 0.006278, val_mae: 0.055319, val_r2: 0.701408
2024-05-18 13:30:34 Epoch 9: lr=0.0001
2024-05-18 13:31:44 [Epoch: 9] loss: 0.005819, mae: 0.053996, r2: 0.721805, val_loss: 0.006237, val_mae: 0.055213, val_r2: 0.702305
2024-05-18 13:31:44 Epoch 10: lr=0.0001
2024-05-18 13:32:54 [Epoch: 10] loss: 0.005761, mae: 0.053730, r2: 0.724754, val_loss: 0.006210, val_mae: 0.055145, val_r2: 0.703511
2024-05-18 13:32:54 Epoch 11: lr=0.0001
2024-05-18 13:34:05 [Epoch: 11] loss: 0.005689, mae: 0.053401, r2: 0.728021, val_loss: 0.006215, val_mae: 0.055602, val_r2: 0.704627
2024-05-18 13:34:05 Epoch 12: lr=0.0001
2024-05-18 13:35:15 [Epoch: 12] loss: 0.005633, mae: 0.053143, r2: 0.730524, val_loss: 0.006182, val_mae: 0.054756, val_r2: 0.705309
2024-05-18 13:35:15 Epoch 13: lr=0.0001
2024-05-18 13:36:25 [Epoch: 13] loss: 0.005583, mae: 0.052911, r2: 0.732713, val_loss: 0.006153, val_mae: 0.055189, val_r2: 0.706948
2024-05-18 13:36:25 Epoch 14: lr=0.0001
2024-05-18 13:37:35 [Epoch: 14] loss: 0.005533, mae: 0.052675, r2: 0.735273, val_loss: 0.006150, val_mae: 0.054703, val_r2: 0.706530
2024-05-18 13:37:35 Epoch 15: lr=0.0001
2024-05-18 13:38:45 [Epoch: 15] loss: 0.005467, mae: 0.052393, r2: 0.738358, val_loss: 0.006144, val_mae: 0.055062, val_r2: 0.705951
2024-05-18 13:38:45 Epoch 16: lr=0.0001
2024-05-18 13:39:55 [Epoch: 16] loss: 0.005434, mae: 0.052212, r2: 0.739796, val_loss: 0.006138, val_mae: 0.054640, val_r2: 0.707126
2024-05-18 13:39:55 Epoch 17: lr=0.0001
2024-05-18 13:41:05 [Epoch: 17] loss: 0.005376, mae: 0.051951, r2: 0.742646, val_loss: 0.006128, val_mae: 0.054442, val_r2: 0.708007
2024-05-18 13:41:05 Epoch 18: lr=0.0001
2024-05-18 13:42:15 [Epoch: 18] loss: 0.005320, mae: 0.051672, r2: 0.745210, val_loss: 0.006094, val_mae: 0.054354, val_r2: 0.709443
2024-05-18 13:42:15 Epoch 19: lr=5e-05
2024-05-18 13:43:25 [Epoch: 19] loss: 0.005210, mae: 0.051170, r2: 0.750308, val_loss: 0.006106, val_mae: 0.054440, val_r2: 0.707723
2024-05-18 13:43:25 Epoch 20: lr=5e-05
2024-05-18 13:44:35 [Epoch: 20] loss: 0.005166, mae: 0.050959, r2: 0.752380, val_loss: 0.006065, val_mae: 0.054087, val_r2: 0.709762
2024-05-18 13:44:35 Epoch 21: lr=5e-05
2024-05-18 13:45:45 [Epoch: 21] loss: 0.005133, mae: 0.050808, r2: 0.753742, val_loss: 0.006085, val_mae: 0.054512, val_r2: 0.709433
2024-05-18 13:45:45 Epoch 22: lr=5e-05
2024-05-18 13:46:56 [Epoch: 22] loss: 0.005117, mae: 0.050742, r2: 0.754386, val_loss: 0.006055, val_mae: 0.054212, val_r2: 0.711447
2024-05-18 13:46:56 Epoch 23: lr=5e-05
2024-05-18 13:48:06 [Epoch: 23] loss: 0.005081, mae: 0.050578, r2: 0.756255, val_loss: 0.006058, val_mae: 0.054227, val_r2: 0.710717
2024-05-18 13:48:06 Epoch 24: lr=2.5e-05
2024-05-18 13:49:16 [Epoch: 24] loss: 0.005025, mae: 0.050296, r2: 0.758683, val_loss: 0.006058, val_mae: 0.054310, val_r2: 0.710665
2024-05-18 13:49:16 Epoch 25: lr=2.5e-05
2024-05-18 13:50:26 [Epoch: 25] loss: 0.005000, mae: 0.050184, r2: 0.759775, val_loss: 0.006066, val_mae: 0.053934, val_r2: 0.711071
2024-05-18 13:50:26 Epoch 26: lr=2.5e-05
2024-05-18 13:51:36 [Epoch: 26] loss: 0.004989, mae: 0.050119, r2: 0.760489, val_loss: 0.006072, val_mae: 0.054120, val_r2: 0.710318
2024-05-18 13:51:37 Epoch 27: lr=2.5e-05
2024-05-18 13:52:47 [Epoch: 27] loss: 0.004971, mae: 0.050063, r2: 0.761168, val_loss: 0.006057, val_mae: 0.054218, val_r2: 0.710363
2024-05-18 13:52:47 Epoch 28: lr=2.5e-05
2024-05-18 13:53:57 [Epoch: 28] loss: 0.004958, mae: 0.049956, r2: 0.761944, val_loss: 0.006074, val_mae: 0.054322, val_r2: 0.709820
2024-05-18 13:53:57 Epoch 29: lr=1.25e-05
2024-05-18 13:55:06 [Epoch: 29] loss: 0.004939, mae: 0.049881, r2: 0.762542, val_loss: 0.006062, val_mae: 0.054045, val_r2: 0.710543
2024-05-18 13:55:07 Epoch 30: lr=1.25e-05
2024-05-18 13:56:16 [Epoch: 30] loss: 0.004916, mae: 0.049768, r2: 0.763849, val_loss: 0.006059, val_mae: 0.054178, val_r2: 0.710993
2024-05-18 13:56:16 Epoch 31: lr=1.25e-05
2024-05-18 13:57:27 [Epoch: 31] loss: 0.004912, mae: 0.049795, r2: 0.764038, val_loss: 0.006057, val_mae: 0.054090, val_r2: 0.710570
2024-05-18 13:57:27 Epoch 32: lr=1.25e-05
2024-05-18 13:58:37 [Epoch: 32] loss: 0.004897, mae: 0.049678, r2: 0.764714, val_loss: 0.006043, val_mae: 0.054327, val_r2: 0.711457
2024-05-18 13:58:37 Epoch 33: lr=1.25e-05
2024-05-18 13:59:47 [Epoch: 33] loss: 0.004892, mae: 0.049676, r2: 0.764882, val_loss: 0.006078, val_mae: 0.054086, val_r2: 0.709515
2024-05-18 13:59:48 Epoch 34: lr=1.25e-05
2024-05-18 14:00:58 [Epoch: 34] loss: 0.004882, mae: 0.049629, r2: 0.765332, val_loss: 0.006062, val_mae: 0.054168, val_r2: 0.710607
2024-05-18 14:00:58 Epoch 35: lr=1.25e-05
2024-05-18 14:02:08 [Epoch: 35] loss: 0.004885, mae: 0.049606, r2: 0.765180, val_loss: 0.006066, val_mae: 0.054305, val_r2: 0.709677
2024-05-18 14:02:08 Epoch 36: lr=1.25e-05
2024-05-18 14:03:18 [Epoch: 36] loss: 0.004880, mae: 0.049621, r2: 0.765494, val_loss: 0.006077, val_mae: 0.054055, val_r2: 0.709671
2024-05-18 14:03:18 Epoch 37: lr=1.25e-05
2024-05-18 14:04:28 [Epoch: 37] loss: 0.004872, mae: 0.049597, r2: 0.765906, val_loss: 0.006058, val_mae: 0.054166, val_r2: 0.711540
2024-05-18 14:04:28 Epoch 38: lr=1e-05
2024-05-18 14:05:38 [Epoch: 38] loss: 0.004849, mae: 0.049488, r2: 0.767141, val_loss: 0.006068, val_mae: 0.054052, val_r2: 0.710179
2024-05-18 14:05:38 Epoch 39: lr=1e-05
2024-05-18 14:06:48 [Epoch: 39] loss: 0.004855, mae: 0.049504, r2: 0.766487, val_loss: 0.006034, val_mae: 0.054023, val_r2: 0.711918
2024-05-18 14:06:48 Epoch 40: lr=1e-05
2024-05-18 14:07:58 [Epoch: 40] loss: 0.004846, mae: 0.049453, r2: 0.766974, val_loss: 0.006065, val_mae: 0.054132, val_r2: 0.709988
2024-05-18 14:07:58 Epoch 41: lr=1e-05
2024-05-18 14:09:08 [Epoch: 41] loss: 0.004842, mae: 0.049405, r2: 0.767226, val_loss: 0.006047, val_mae: 0.053968, val_r2: 0.711131
2024-05-18 14:09:08 Epoch 42: lr=1e-05
2024-05-18 14:10:18 [Epoch: 42] loss: 0.004835, mae: 0.049395, r2: 0.767745, val_loss: 0.006049, val_mae: 0.054089, val_r2: 0.711039
2024-05-18 14:10:18 Epoch 43: lr=1e-05
2024-05-18 14:11:28 [Epoch: 43] loss: 0.004834, mae: 0.049377, r2: 0.767707, val_loss: 0.006074, val_mae: 0.054126, val_r2: 0.709269
2024-05-18 14:11:28 Epoch 44: lr=1e-05
2024-05-18 14:12:38 [Epoch: 44] loss: 0.004828, mae: 0.049366, r2: 0.767903, val_loss: 0.006048, val_mae: 0.053982, val_r2: 0.711013
2024-05-18 14:12:38 Epoch 45: lr=1e-05
2024-05-18 14:13:48 [Epoch: 45] loss: 0.004816, mae: 0.049317, r2: 0.768304, val_loss: 0.006048, val_mae: 0.053969, val_r2: 0.711235
2024-05-18 14:13:48 Epoch 46: lr=1e-05
2024-05-18 14:14:58 [Epoch: 46] loss: 0.004816, mae: 0.049316, r2: 0.768636, val_loss: 0.006052, val_mae: 0.053999, val_r2: 0.711241
2024-05-18 14:14:58 Epoch 47: lr=1e-05
2024-05-18 14:16:08 [Epoch: 47] loss: 0.004812, mae: 0.049276, r2: 0.768533, val_loss: 0.006071, val_mae: 0.054128, val_r2: 0.710757
2024-05-18 14:16:08 Epoch 48: lr=1e-05
2024-05-18 14:17:18 [Epoch: 48] loss: 0.004809, mae: 0.049274, r2: 0.768846, val_loss: 0.006067, val_mae: 0.053970, val_r2: 0.710863
2024-05-18 14:17:18 Epoch 49: lr=1e-05
2024-05-18 14:18:28 [Epoch: 49] loss: 0.004798, mae: 0.049219, r2: 0.769396, val_loss: 0.006064, val_mae: 0.053972, val_r2: 0.710575
2024-05-18 14:18:28 history_length: 50
2024-05-18 14:18:28 stopping: early
2024-05-18 14:18:28 Comparing y_true and y_pred:
2024-05-18 14:18:28   mse: 0.01149779
2024-05-18 14:18:28   mae: 0.08420702
2024-05-18 14:18:28   r2: -0.17595532
2024-05-18 14:18:28   corr: 0.30261407
