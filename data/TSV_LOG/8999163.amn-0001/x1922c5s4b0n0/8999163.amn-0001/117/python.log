2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/117', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '117', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/117/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/117', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s4b0n0.117.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/117/4.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/117'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x1464b8a817f0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/117/4.1.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04752066
2024-05-18 13:20:01   mae: 0.15977810
2024-05-18 13:20:01   r2: -0.98993248
2024-05-18 13:20:01   corr: 0.00503376
2024-05-18 13:20:01 Data points per epoch: train = 469179, val = 117295, test = 1235
2024-05-18 13:20:01 Steps per epoch: train = 14661, val = 3665, test = 38
2024-05-18 13:20:01 Epoch 0: lr=0.001
2024-05-18 13:21:15 [Epoch: 0] loss: 0.025265, mae: 0.079680, r2: 0.035956, val_loss: 0.008750, val_mae: 0.067972, val_r2: 0.592584
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:27 [Epoch: 1] loss: 0.008004, mae: 0.064000, r2: 0.620094, val_loss: 0.007756, val_mae: 0.061876, val_r2: 0.627100
2024-05-18 13:22:27 Epoch 2: lr=0.00064
2024-05-18 13:23:38 [Epoch: 2] loss: 0.007324, mae: 0.060803, r2: 0.651828, val_loss: 0.007222, val_mae: 0.059789, val_r2: 0.654941
2024-05-18 13:23:38 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006841, mae: 0.058689, r2: 0.673863, val_loss: 0.007371, val_mae: 0.059725, val_r2: 0.651788
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:01 [Epoch: 4] loss: 0.006439, mae: 0.056821, r2: 0.692307, val_loss: 0.006583, val_mae: 0.057468, val_r2: 0.684100
2024-05-18 13:26:02 Epoch 5: lr=0.0001
2024-05-18 13:27:13 [Epoch: 5] loss: 0.006116, mae: 0.055320, r2: 0.707236, val_loss: 0.006426, val_mae: 0.056786, val_r2: 0.690427
2024-05-18 13:27:13 Epoch 6: lr=0.0001
2024-05-18 13:28:25 [Epoch: 6] loss: 0.006009, mae: 0.054811, r2: 0.712226, val_loss: 0.006375, val_mae: 0.056200, val_r2: 0.694454
2024-05-18 13:28:25 Epoch 7: lr=0.0001
2024-05-18 13:29:37 [Epoch: 7] loss: 0.005932, mae: 0.054508, r2: 0.715813, val_loss: 0.006380, val_mae: 0.055675, val_r2: 0.694207
2024-05-18 13:29:37 Epoch 8: lr=0.0001
2024-05-18 13:30:48 [Epoch: 8] loss: 0.005860, mae: 0.054159, r2: 0.719007, val_loss: 0.006318, val_mae: 0.055535, val_r2: 0.697405
2024-05-18 13:30:48 Epoch 9: lr=0.0001
2024-05-18 13:32:00 [Epoch: 9] loss: 0.005787, mae: 0.053851, r2: 0.722421, val_loss: 0.006283, val_mae: 0.055630, val_r2: 0.698726
2024-05-18 13:32:00 Epoch 10: lr=0.0001
2024-05-18 13:33:12 [Epoch: 10] loss: 0.005728, mae: 0.053565, r2: 0.725248, val_loss: 0.006260, val_mae: 0.055174, val_r2: 0.699799
2024-05-18 13:33:12 Epoch 11: lr=0.0001
2024-05-18 13:34:23 [Epoch: 11] loss: 0.005666, mae: 0.053266, r2: 0.728216, val_loss: 0.006261, val_mae: 0.055286, val_r2: 0.698767
2024-05-18 13:34:23 Epoch 12: lr=0.0001
2024-05-18 13:35:35 [Epoch: 12] loss: 0.005607, mae: 0.053052, r2: 0.730936, val_loss: 0.006224, val_mae: 0.055082, val_r2: 0.699837
2024-05-18 13:35:35 Epoch 13: lr=0.0001
2024-05-18 13:36:47 [Epoch: 13] loss: 0.005553, mae: 0.052788, r2: 0.733511, val_loss: 0.006200, val_mae: 0.055763, val_r2: 0.700927
2024-05-18 13:36:47 Epoch 14: lr=0.0001
2024-05-18 13:37:59 [Epoch: 14] loss: 0.005507, mae: 0.052545, r2: 0.735411, val_loss: 0.006177, val_mae: 0.055079, val_r2: 0.704008
2024-05-18 13:37:59 Epoch 15: lr=0.0001
2024-05-18 13:39:11 [Epoch: 15] loss: 0.005455, mae: 0.052321, r2: 0.737986, val_loss: 0.006146, val_mae: 0.054765, val_r2: 0.704739
2024-05-18 13:39:11 Epoch 16: lr=0.0001
2024-05-18 13:40:22 [Epoch: 16] loss: 0.005401, mae: 0.052060, r2: 0.740521, val_loss: 0.006184, val_mae: 0.055211, val_r2: 0.701510
2024-05-18 13:40:22 Epoch 17: lr=0.0001
2024-05-18 13:41:34 [Epoch: 17] loss: 0.005347, mae: 0.051804, r2: 0.743214, val_loss: 0.006143, val_mae: 0.054652, val_r2: 0.704617
2024-05-18 13:41:34 Epoch 18: lr=0.0001
2024-05-18 13:42:46 [Epoch: 18] loss: 0.005305, mae: 0.051593, r2: 0.744906, val_loss: 0.006137, val_mae: 0.054483, val_r2: 0.705230
2024-05-18 13:42:46 Epoch 19: lr=5e-05
2024-05-18 13:43:57 [Epoch: 19] loss: 0.005187, mae: 0.051068, r2: 0.750520, val_loss: 0.006120, val_mae: 0.054312, val_r2: 0.705015
2024-05-18 13:43:57 Epoch 20: lr=5e-05
2024-05-18 13:45:09 [Epoch: 20] loss: 0.005152, mae: 0.050891, r2: 0.752161, val_loss: 0.006101, val_mae: 0.054440, val_r2: 0.706621
2024-05-18 13:45:09 Epoch 21: lr=5e-05
2024-05-18 13:46:20 [Epoch: 21] loss: 0.005125, mae: 0.050776, r2: 0.753482, val_loss: 0.006073, val_mae: 0.054392, val_r2: 0.708622
2024-05-18 13:46:21 Epoch 22: lr=5e-05
2024-05-18 13:47:32 [Epoch: 22] loss: 0.005084, mae: 0.050579, r2: 0.755060, val_loss: 0.006079, val_mae: 0.054282, val_r2: 0.707200
2024-05-18 13:47:32 Epoch 23: lr=5e-05
2024-05-18 13:48:43 [Epoch: 23] loss: 0.005071, mae: 0.050496, r2: 0.755939, val_loss: 0.006094, val_mae: 0.054447, val_r2: 0.706681
2024-05-18 13:48:44 Epoch 24: lr=5e-05
2024-05-18 13:49:55 [Epoch: 24] loss: 0.005045, mae: 0.050341, r2: 0.757239, val_loss: 0.006077, val_mae: 0.054325, val_r2: 0.708364
2024-05-18 13:49:55 Epoch 25: lr=5e-05
2024-05-18 13:51:07 [Epoch: 25] loss: 0.005024, mae: 0.050261, r2: 0.758193, val_loss: 0.006069, val_mae: 0.054348, val_r2: 0.707752
2024-05-18 13:51:07 Epoch 26: lr=5e-05
2024-05-18 13:52:18 [Epoch: 26] loss: 0.005004, mae: 0.050126, r2: 0.758859, val_loss: 0.006076, val_mae: 0.054176, val_r2: 0.707846
2024-05-18 13:52:19 Epoch 27: lr=2.5e-05
2024-05-18 13:53:30 [Epoch: 27] loss: 0.004947, mae: 0.049895, r2: 0.761840, val_loss: 0.006069, val_mae: 0.054573, val_r2: 0.707597
2024-05-18 13:53:30 Epoch 28: lr=2.5e-05
2024-05-18 13:54:42 [Epoch: 28] loss: 0.004919, mae: 0.049758, r2: 0.763199, val_loss: 0.006076, val_mae: 0.054435, val_r2: 0.707657
2024-05-18 13:54:42 Epoch 29: lr=2.5e-05
2024-05-18 13:55:53 [Epoch: 29] loss: 0.004901, mae: 0.049694, r2: 0.763821, val_loss: 0.006065, val_mae: 0.054136, val_r2: 0.707648
2024-05-18 13:55:54 Epoch 30: lr=2.5e-05
2024-05-18 13:57:05 [Epoch: 30] loss: 0.004890, mae: 0.049642, r2: 0.764472, val_loss: 0.006055, val_mae: 0.054463, val_r2: 0.708323
2024-05-18 13:57:06 Epoch 31: lr=2.5e-05
2024-05-18 13:58:16 [Epoch: 31] loss: 0.004882, mae: 0.049562, r2: 0.764632, val_loss: 0.006079, val_mae: 0.054271, val_r2: 0.707564
2024-05-18 13:58:17 Epoch 32: lr=1.25e-05
2024-05-18 13:59:28 [Epoch: 32] loss: 0.004843, mae: 0.049410, r2: 0.766582, val_loss: 0.006070, val_mae: 0.054458, val_r2: 0.708241
2024-05-18 13:59:29 Epoch 33: lr=1.25e-05
2024-05-18 14:00:40 [Epoch: 33] loss: 0.004839, mae: 0.049385, r2: 0.766784, val_loss: 0.006083, val_mae: 0.054339, val_r2: 0.706847
2024-05-18 14:00:40 Epoch 34: lr=1.25e-05
2024-05-18 14:01:52 [Epoch: 34] loss: 0.004828, mae: 0.049363, r2: 0.767068, val_loss: 0.006094, val_mae: 0.054490, val_r2: 0.706335
2024-05-18 14:01:52 Epoch 35: lr=1.25e-05
2024-05-18 14:03:03 [Epoch: 35] loss: 0.004820, mae: 0.049298, r2: 0.767487, val_loss: 0.006073, val_mae: 0.054224, val_r2: 0.707428
2024-05-18 14:03:03 Epoch 36: lr=1.25e-05
2024-05-18 14:04:15 [Epoch: 36] loss: 0.004817, mae: 0.049266, r2: 0.767959, val_loss: 0.006092, val_mae: 0.054501, val_r2: 0.706527
2024-05-18 14:04:15 Epoch 37: lr=1e-05
2024-05-18 14:05:26 [Epoch: 37] loss: 0.004793, mae: 0.049181, r2: 0.768953, val_loss: 0.006077, val_mae: 0.054230, val_r2: 0.707295
2024-05-18 14:05:26 Epoch 38: lr=1e-05
2024-05-18 14:06:38 [Epoch: 38] loss: 0.004794, mae: 0.049166, r2: 0.768983, val_loss: 0.006059, val_mae: 0.054069, val_r2: 0.708164
2024-05-18 14:06:38 Epoch 39: lr=1e-05
2024-05-18 14:07:50 [Epoch: 39] loss: 0.004796, mae: 0.049163, r2: 0.768929, val_loss: 0.006022, val_mae: 0.054065, val_r2: 0.709381
2024-05-18 14:07:50 Epoch 40: lr=1e-05
2024-05-18 14:09:02 [Epoch: 40] loss: 0.004790, mae: 0.049140, r2: 0.769233, val_loss: 0.006094, val_mae: 0.054368, val_r2: 0.706986
2024-05-18 14:09:02 Epoch 41: lr=1e-05
2024-05-18 14:10:14 [Epoch: 41] loss: 0.004782, mae: 0.049056, r2: 0.769621, val_loss: 0.006072, val_mae: 0.054180, val_r2: 0.707330
2024-05-18 14:10:14 Epoch 42: lr=1e-05
2024-05-18 14:11:25 [Epoch: 42] loss: 0.004773, mae: 0.049056, r2: 0.769840, val_loss: 0.006085, val_mae: 0.054162, val_r2: 0.707174
2024-05-18 14:11:25 Epoch 43: lr=1e-05
2024-05-18 14:12:37 [Epoch: 43] loss: 0.004773, mae: 0.049053, r2: 0.770125, val_loss: 0.006061, val_mae: 0.054158, val_r2: 0.708088
2024-05-18 14:12:37 Epoch 44: lr=1e-05
2024-05-18 14:13:49 [Epoch: 44] loss: 0.004769, mae: 0.048988, r2: 0.770066, val_loss: 0.006078, val_mae: 0.054227, val_r2: 0.707333
2024-05-18 14:13:49 Epoch 45: lr=1e-05
2024-05-18 14:15:01 [Epoch: 45] loss: 0.004773, mae: 0.049031, r2: 0.769887, val_loss: 0.006068, val_mae: 0.054033, val_r2: 0.707834
2024-05-18 14:15:01 Epoch 46: lr=1e-05
2024-05-18 14:16:12 [Epoch: 46] loss: 0.004747, mae: 0.048952, r2: 0.770965, val_loss: 0.006078, val_mae: 0.054033, val_r2: 0.707755
2024-05-18 14:16:12 Epoch 47: lr=1e-05
2024-05-18 14:17:23 [Epoch: 47] loss: 0.004751, mae: 0.048945, r2: 0.771061, val_loss: 0.006082, val_mae: 0.054383, val_r2: 0.706879
2024-05-18 14:17:24 Epoch 48: lr=1e-05
2024-05-18 14:18:35 [Epoch: 48] loss: 0.004745, mae: 0.048924, r2: 0.770926, val_loss: 0.006071, val_mae: 0.054212, val_r2: 0.707465
2024-05-18 14:18:35 Epoch 49: lr=1e-05
2024-05-18 14:19:47 [Epoch: 49] loss: 0.004746, mae: 0.048933, r2: 0.770985, val_loss: 0.006064, val_mae: 0.054133, val_r2: 0.708060
2024-05-18 14:19:47 history_length: 50
2024-05-18 14:19:47 stopping: early
2024-05-18 14:19:47 Comparing y_true and y_pred:
2024-05-18 14:19:47   mse: 0.00677100
2024-05-18 14:19:47   mae: 0.05844541
2024-05-18 14:19:47   r2: -0.22166836
2024-05-18 14:19:47   corr: 0.07967632
