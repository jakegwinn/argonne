2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/109', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '109', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/109/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/109', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s4b0n0.109.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/109/0.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/109'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x151de0781af0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/109/0.1.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04758512
2024-05-18 13:20:01   mae: 0.15957395
2024-05-18 13:20:01   r2: -1.00280054
2024-05-18 13:20:01   corr: -0.00140027
2024-05-18 13:20:01 Data points per epoch: train = 469631, val = 117408, test = 670
2024-05-18 13:20:01 Steps per epoch: train = 14675, val = 3669, test = 20
2024-05-18 13:20:01 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.025665, mae: 0.079681, r2: -0.428138, val_loss: 0.008376, val_mae: 0.064971, val_r2: 0.596905
2024-05-18 13:21:14 Epoch 1: lr=0.00082
2024-05-18 13:22:25 [Epoch: 1] loss: 0.007988, mae: 0.063910, r2: 0.620640, val_loss: 0.007757, val_mae: 0.061740, val_r2: 0.631665
2024-05-18 13:22:25 Epoch 2: lr=0.00064
2024-05-18 13:23:37 [Epoch: 2] loss: 0.007295, mae: 0.060675, r2: 0.652185, val_loss: 0.007203, val_mae: 0.060279, val_r2: 0.661505
2024-05-18 13:23:37 Epoch 3: lr=0.00046
2024-05-18 13:24:47 [Epoch: 3] loss: 0.006815, mae: 0.058473, r2: 0.674364, val_loss: 0.006862, val_mae: 0.059063, val_r2: 0.675929
2024-05-18 13:24:47 Epoch 4: lr=0.00028
2024-05-18 13:25:58 [Epoch: 4] loss: 0.006423, mae: 0.056698, r2: 0.692550, val_loss: 0.006546, val_mae: 0.057850, val_r2: 0.686027
2024-05-18 13:25:58 Epoch 5: lr=0.0001
2024-05-18 13:27:09 [Epoch: 5] loss: 0.006086, mae: 0.055106, r2: 0.708135, val_loss: 0.006359, val_mae: 0.056537, val_r2: 0.696822
2024-05-18 13:27:09 Epoch 6: lr=0.0001
2024-05-18 13:28:20 [Epoch: 6] loss: 0.005975, mae: 0.054592, r2: 0.713578, val_loss: 0.006307, val_mae: 0.055647, val_r2: 0.700160
2024-05-18 13:28:20 Epoch 7: lr=0.0001
2024-05-18 13:29:31 [Epoch: 7] loss: 0.005897, mae: 0.054291, r2: 0.717237, val_loss: 0.006291, val_mae: 0.055761, val_r2: 0.698310
2024-05-18 13:29:31 Epoch 8: lr=0.0001
2024-05-18 13:30:41 [Epoch: 8] loss: 0.005815, mae: 0.053926, r2: 0.720845, val_loss: 0.006254, val_mae: 0.055308, val_r2: 0.700887
2024-05-18 13:30:41 Epoch 9: lr=0.0001
2024-05-18 13:31:52 [Epoch: 9] loss: 0.005754, mae: 0.053655, r2: 0.723728, val_loss: 0.006239, val_mae: 0.055104, val_r2: 0.701519
2024-05-18 13:31:52 Epoch 10: lr=0.0001
2024-05-18 13:33:02 [Epoch: 10] loss: 0.005697, mae: 0.053393, r2: 0.726032, val_loss: 0.006195, val_mae: 0.055168, val_r2: 0.703318
2024-05-18 13:33:02 Epoch 11: lr=0.0001
2024-05-18 13:34:12 [Epoch: 11] loss: 0.005628, mae: 0.053086, r2: 0.729700, val_loss: 0.006137, val_mae: 0.054719, val_r2: 0.706847
2024-05-18 13:34:13 Epoch 12: lr=0.0001
2024-05-18 13:35:23 [Epoch: 12] loss: 0.005583, mae: 0.052842, r2: 0.732013, val_loss: 0.006132, val_mae: 0.054699, val_r2: 0.706712
2024-05-18 13:35:23 Epoch 13: lr=0.0001
2024-05-18 13:36:33 [Epoch: 13] loss: 0.005525, mae: 0.052566, r2: 0.734464, val_loss: 0.006130, val_mae: 0.054905, val_r2: 0.707118
2024-05-18 13:36:33 Epoch 14: lr=0.0001
2024-05-18 13:37:43 [Epoch: 14] loss: 0.005470, mae: 0.052325, r2: 0.737104, val_loss: 0.006121, val_mae: 0.054493, val_r2: 0.707385
2024-05-18 13:37:44 Epoch 15: lr=0.0001
2024-05-18 13:38:54 [Epoch: 15] loss: 0.005423, mae: 0.052137, r2: 0.739268, val_loss: 0.006086, val_mae: 0.054489, val_r2: 0.708711
2024-05-18 13:38:54 Epoch 16: lr=0.0001
2024-05-18 13:40:04 [Epoch: 16] loss: 0.005369, mae: 0.051861, r2: 0.741988, val_loss: 0.006070, val_mae: 0.054405, val_r2: 0.708985
2024-05-18 13:40:04 Epoch 17: lr=5e-05
2024-05-18 13:41:15 [Epoch: 17] loss: 0.005256, mae: 0.051339, r2: 0.747353, val_loss: 0.006067, val_mae: 0.054648, val_r2: 0.709376
2024-05-18 13:41:15 Epoch 18: lr=5e-05
2024-05-18 13:42:25 [Epoch: 18] loss: 0.005200, mae: 0.051104, r2: 0.749641, val_loss: 0.006056, val_mae: 0.054546, val_r2: 0.710631
2024-05-18 13:42:25 Epoch 19: lr=5e-05
2024-05-18 13:43:35 [Epoch: 19] loss: 0.005182, mae: 0.050976, r2: 0.750682, val_loss: 0.006105, val_mae: 0.054342, val_r2: 0.708095
2024-05-18 13:43:35 Epoch 20: lr=5e-05
2024-05-18 13:44:46 [Epoch: 20] loss: 0.005149, mae: 0.050808, r2: 0.752328, val_loss: 0.006066, val_mae: 0.054530, val_r2: 0.709267
2024-05-18 13:44:46 Epoch 21: lr=5e-05
2024-05-18 13:45:56 [Epoch: 21] loss: 0.005123, mae: 0.050745, r2: 0.753442, val_loss: 0.006054, val_mae: 0.054233, val_r2: 0.709165
2024-05-18 13:45:56 Epoch 22: lr=2.5e-05
2024-05-18 13:47:06 [Epoch: 22] loss: 0.005077, mae: 0.050491, r2: 0.755621, val_loss: 0.006056, val_mae: 0.054130, val_r2: 0.710430
2024-05-18 13:47:07 Epoch 23: lr=2.5e-05
2024-05-18 13:48:17 [Epoch: 23] loss: 0.005047, mae: 0.050326, r2: 0.756944, val_loss: 0.006066, val_mae: 0.054519, val_r2: 0.708811
2024-05-18 13:48:17 Epoch 24: lr=2.5e-05
2024-05-18 13:49:27 [Epoch: 24] loss: 0.005032, mae: 0.050285, r2: 0.757573, val_loss: 0.006059, val_mae: 0.054115, val_r2: 0.710078
2024-05-18 13:49:27 Epoch 25: lr=2.5e-05
2024-05-18 13:50:38 [Epoch: 25] loss: 0.005017, mae: 0.050220, r2: 0.758331, val_loss: 0.006057, val_mae: 0.054010, val_r2: 0.710199
2024-05-18 13:50:38 Epoch 26: lr=2.5e-05
2024-05-18 13:51:48 [Epoch: 26] loss: 0.005002, mae: 0.050110, r2: 0.758827, val_loss: 0.006054, val_mae: 0.053896, val_r2: 0.710100
2024-05-18 13:51:48 Epoch 27: lr=1.25e-05
2024-05-18 13:52:58 [Epoch: 27] loss: 0.004958, mae: 0.049952, r2: 0.761105, val_loss: 0.006036, val_mae: 0.054091, val_r2: 0.711155
2024-05-18 13:52:58 Epoch 28: lr=1.25e-05
2024-05-18 13:54:09 [Epoch: 28] loss: 0.004957, mae: 0.049953, r2: 0.761130, val_loss: 0.006037, val_mae: 0.054181, val_r2: 0.710905
2024-05-18 13:54:09 Epoch 29: lr=1.25e-05
2024-05-18 13:55:19 [Epoch: 29] loss: 0.004964, mae: 0.049954, r2: 0.760642, val_loss: 0.006031, val_mae: 0.054152, val_r2: 0.711193
2024-05-18 13:55:19 Epoch 30: lr=1.25e-05
2024-05-18 13:56:30 [Epoch: 30] loss: 0.004951, mae: 0.049890, r2: 0.761492, val_loss: 0.006039, val_mae: 0.054092, val_r2: 0.710685
2024-05-18 13:56:30 Epoch 31: lr=1.25e-05
2024-05-18 13:57:40 [Epoch: 31] loss: 0.004952, mae: 0.049874, r2: 0.761388, val_loss: 0.006060, val_mae: 0.054467, val_r2: 0.710177
2024-05-18 13:57:40 Epoch 32: lr=1.25e-05
2024-05-18 13:58:50 [Epoch: 32] loss: 0.004932, mae: 0.049801, r2: 0.762057, val_loss: 0.006059, val_mae: 0.054057, val_r2: 0.709605
2024-05-18 13:58:50 Epoch 33: lr=1e-05
2024-05-18 14:00:01 [Epoch: 33] loss: 0.004921, mae: 0.049750, r2: 0.762735, val_loss: 0.006058, val_mae: 0.054067, val_r2: 0.709716
2024-05-18 14:00:01 Epoch 34: lr=1e-05
2024-05-18 14:01:11 [Epoch: 34] loss: 0.004923, mae: 0.049757, r2: 0.762647, val_loss: 0.006041, val_mae: 0.053957, val_r2: 0.711147
2024-05-18 14:01:11 Epoch 35: lr=1e-05
2024-05-18 14:02:22 [Epoch: 35] loss: 0.004925, mae: 0.049743, r2: 0.762681, val_loss: 0.006067, val_mae: 0.054173, val_r2: 0.709994
2024-05-18 14:02:22 Epoch 36: lr=1e-05
2024-05-18 14:03:32 [Epoch: 36] loss: 0.004898, mae: 0.049645, r2: 0.763816, val_loss: 0.006034, val_mae: 0.054031, val_r2: 0.710546
2024-05-18 14:03:32 Epoch 37: lr=1e-05
2024-05-18 14:04:43 [Epoch: 37] loss: 0.004899, mae: 0.049620, r2: 0.763826, val_loss: 0.006060, val_mae: 0.054012, val_r2: 0.710171
2024-05-18 14:04:43 Epoch 38: lr=1e-05
2024-05-18 14:05:53 [Epoch: 38] loss: 0.004885, mae: 0.049586, r2: 0.764417, val_loss: 0.006027, val_mae: 0.053844, val_r2: 0.711414
2024-05-18 14:05:53 Epoch 39: lr=1e-05
2024-05-18 14:07:03 [Epoch: 39] loss: 0.004890, mae: 0.049604, r2: 0.764322, val_loss: 0.006034, val_mae: 0.053963, val_r2: 0.710947
2024-05-18 14:07:04 Epoch 40: lr=1e-05
2024-05-18 14:08:14 [Epoch: 40] loss: 0.004877, mae: 0.049540, r2: 0.764713, val_loss: 0.006024, val_mae: 0.054075, val_r2: 0.711847
2024-05-18 14:08:14 Epoch 41: lr=1e-05
2024-05-18 14:09:24 [Epoch: 41] loss: 0.004886, mae: 0.049551, r2: 0.764379, val_loss: 0.006039, val_mae: 0.054064, val_r2: 0.710714
2024-05-18 14:09:24 Epoch 42: lr=1e-05
2024-05-18 14:10:35 [Epoch: 42] loss: 0.004875, mae: 0.049496, r2: 0.765194, val_loss: 0.006034, val_mae: 0.054011, val_r2: 0.711325
2024-05-18 14:10:35 Epoch 43: lr=1e-05
2024-05-18 14:11:45 [Epoch: 43] loss: 0.004864, mae: 0.049469, r2: 0.765413, val_loss: 0.006057, val_mae: 0.053970, val_r2: 0.709891
2024-05-18 14:11:45 Epoch 44: lr=1e-05
2024-05-18 14:12:56 [Epoch: 44] loss: 0.004856, mae: 0.049443, r2: 0.765772, val_loss: 0.006028, val_mae: 0.053924, val_r2: 0.711224
2024-05-18 14:12:56 Epoch 45: lr=1e-05
2024-05-18 14:14:06 [Epoch: 45] loss: 0.004857, mae: 0.049442, r2: 0.765692, val_loss: 0.006029, val_mae: 0.053920, val_r2: 0.711468
2024-05-18 14:14:06 Epoch 46: lr=1e-05
2024-05-18 14:15:16 [Epoch: 46] loss: 0.004868, mae: 0.049502, r2: 0.765163, val_loss: 0.006032, val_mae: 0.053951, val_r2: 0.711777
2024-05-18 14:15:17 Epoch 47: lr=1e-05
2024-05-18 14:16:27 [Epoch: 47] loss: 0.004845, mae: 0.049370, r2: 0.766229, val_loss: 0.006080, val_mae: 0.054177, val_r2: 0.709069
2024-05-18 14:16:27 Epoch 48: lr=1e-05
2024-05-18 14:17:37 [Epoch: 48] loss: 0.004841, mae: 0.049339, r2: 0.766366, val_loss: 0.006057, val_mae: 0.053985, val_r2: 0.710210
2024-05-18 14:17:37 Epoch 49: lr=1e-05
2024-05-18 14:18:48 [Epoch: 49] loss: 0.004843, mae: 0.049383, r2: 0.766378, val_loss: 0.006051, val_mae: 0.054066, val_r2: 0.710193
2024-05-18 14:18:48 Epoch 50: lr=1e-05
2024-05-18 14:19:58 [Epoch: 50] loss: 0.004836, mae: 0.049353, r2: 0.766577, val_loss: 0.006017, val_mae: 0.053917, val_r2: 0.712417
2024-05-18 14:19:58 Epoch 51: lr=1e-05
2024-05-18 14:21:08 [Epoch: 51] loss: 0.004835, mae: 0.049358, r2: 0.766730, val_loss: 0.006036, val_mae: 0.054142, val_r2: 0.711509
2024-05-18 14:21:09 Epoch 52: lr=1e-05
2024-05-18 14:22:19 [Epoch: 52] loss: 0.004813, mae: 0.049241, r2: 0.767979, val_loss: 0.006041, val_mae: 0.053978, val_r2: 0.711061
2024-05-18 14:22:19 Epoch 53: lr=1e-05
2024-05-18 14:23:29 [Epoch: 53] loss: 0.004819, mae: 0.049251, r2: 0.767391, val_loss: 0.006050, val_mae: 0.054115, val_r2: 0.709952
2024-05-18 14:23:29 Epoch 54: lr=1e-05
2024-05-18 14:24:39 [Epoch: 54] loss: 0.004814, mae: 0.049251, r2: 0.767846, val_loss: 0.006069, val_mae: 0.053877, val_r2: 0.709056
2024-05-18 14:24:39 Epoch 55: lr=1e-05
2024-05-18 14:25:49 [Epoch: 55] loss: 0.004824, mae: 0.049261, r2: 0.767170, val_loss: 0.006050, val_mae: 0.053906, val_r2: 0.710490
2024-05-18 14:25:49 Epoch 56: lr=1e-05
2024-05-18 14:26:59 [Epoch: 56] loss: 0.004802, mae: 0.049170, r2: 0.768411, val_loss: 0.006044, val_mae: 0.054074, val_r2: 0.710640
2024-05-18 14:26:59 Epoch 57: lr=1e-05
2024-05-18 14:28:09 [Epoch: 57] loss: 0.004802, mae: 0.049167, r2: 0.768223, val_loss: 0.006045, val_mae: 0.054064, val_r2: 0.710922
2024-05-18 14:28:09 Epoch 58: lr=1e-05
2024-05-18 14:29:20 [Epoch: 58] loss: 0.004795, mae: 0.049122, r2: 0.768756, val_loss: 0.006057, val_mae: 0.054031, val_r2: 0.710103
2024-05-18 14:29:20 Epoch 59: lr=1e-05
2024-05-18 14:30:30 [Epoch: 59] loss: 0.004792, mae: 0.049095, r2: 0.768928, val_loss: 0.006050, val_mae: 0.054099, val_r2: 0.710435
2024-05-18 14:30:30 Epoch 60: lr=1e-05
2024-05-18 14:31:40 [Epoch: 60] loss: 0.004784, mae: 0.049094, r2: 0.769219, val_loss: 0.006027, val_mae: 0.053904, val_r2: 0.711856
2024-05-18 14:31:40 history_length: 61
2024-05-18 14:31:40 stopping: early
2024-05-18 14:31:40 Comparing y_true and y_pred:
2024-05-18 14:31:40   mse: 0.03220243
2024-05-18 14:31:40   mae: 0.14924948
2024-05-18 14:31:40   r2: -0.90853217
2024-05-18 14:31:40   corr: 0.41047672
