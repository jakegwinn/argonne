2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/115', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '115', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/115/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/115', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s4b0n0.115.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/115/3.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/115'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x14813705cee0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/115/3.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04727462
2024-05-18 13:20:02   mae: 0.15923714
2024-05-18 13:20:02   r2: -0.99401518
2024-05-18 13:20:02   corr: 0.00299241
2024-05-18 13:20:02 Data points per epoch: train = 469599, val = 117400, test = 710
2024-05-18 13:20:02 Steps per epoch: train = 14674, val = 3668, test = 22
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:16 [Epoch: 0] loss: 0.025020, mae: 0.079063, r2: -0.062156, val_loss: 0.008524, val_mae: 0.065854, val_r2: 0.596508
2024-05-18 13:21:16 Epoch 1: lr=0.00082
2024-05-18 13:22:29 [Epoch: 1] loss: 0.007978, mae: 0.063815, r2: 0.620365, val_loss: 0.007569, val_mae: 0.062290, val_r2: 0.640571
2024-05-18 13:22:29 Epoch 2: lr=0.00064
2024-05-18 13:23:41 [Epoch: 2] loss: 0.007293, mae: 0.060738, r2: 0.651687, val_loss: 0.007180, val_mae: 0.059933, val_r2: 0.653612
2024-05-18 13:23:41 Epoch 3: lr=0.00046
2024-05-18 13:24:52 [Epoch: 3] loss: 0.006827, mae: 0.058615, r2: 0.672886, val_loss: 0.006928, val_mae: 0.059072, val_r2: 0.666255
2024-05-18 13:24:53 Epoch 4: lr=0.00028
2024-05-18 13:26:05 [Epoch: 4] loss: 0.006435, mae: 0.056828, r2: 0.690849, val_loss: 0.006720, val_mae: 0.057104, val_r2: 0.676157
2024-05-18 13:26:05 Epoch 5: lr=0.0001
2024-05-18 13:27:17 [Epoch: 5] loss: 0.006107, mae: 0.055250, r2: 0.706095, val_loss: 0.006466, val_mae: 0.056749, val_r2: 0.688775
2024-05-18 13:27:17 Epoch 6: lr=0.0001
2024-05-18 13:28:30 [Epoch: 6] loss: 0.005999, mae: 0.054747, r2: 0.711077, val_loss: 0.006457, val_mae: 0.056314, val_r2: 0.689264
2024-05-18 13:28:30 Epoch 7: lr=0.0001
2024-05-18 13:29:42 [Epoch: 7] loss: 0.005922, mae: 0.054423, r2: 0.714604, val_loss: 0.006390, val_mae: 0.055925, val_r2: 0.692733
2024-05-18 13:29:42 Epoch 8: lr=0.0001
2024-05-18 13:30:54 [Epoch: 8] loss: 0.005837, mae: 0.054047, r2: 0.718894, val_loss: 0.006368, val_mae: 0.056067, val_r2: 0.694269
2024-05-18 13:30:54 Epoch 9: lr=0.0001
2024-05-18 13:32:07 [Epoch: 9] loss: 0.005785, mae: 0.053820, r2: 0.721132, val_loss: 0.006325, val_mae: 0.055531, val_r2: 0.696148
2024-05-18 13:32:07 Epoch 10: lr=0.0001
2024-05-18 13:33:19 [Epoch: 10] loss: 0.005727, mae: 0.053554, r2: 0.724064, val_loss: 0.006322, val_mae: 0.055623, val_r2: 0.695578
2024-05-18 13:33:19 Epoch 11: lr=0.0001
2024-05-18 13:34:31 [Epoch: 11] loss: 0.005660, mae: 0.053239, r2: 0.726948, val_loss: 0.006323, val_mae: 0.055430, val_r2: 0.694759
2024-05-18 13:34:31 Epoch 12: lr=0.0001
2024-05-18 13:35:43 [Epoch: 12] loss: 0.005603, mae: 0.052953, r2: 0.729903, val_loss: 0.006275, val_mae: 0.055203, val_r2: 0.698823
2024-05-18 13:35:43 Epoch 13: lr=0.0001
2024-05-18 13:36:55 [Epoch: 13] loss: 0.005548, mae: 0.052722, r2: 0.732280, val_loss: 0.006262, val_mae: 0.055046, val_r2: 0.699940
2024-05-18 13:36:55 Epoch 14: lr=0.0001
2024-05-18 13:38:08 [Epoch: 14] loss: 0.005485, mae: 0.052433, r2: 0.735252, val_loss: 0.006199, val_mae: 0.055122, val_r2: 0.701626
2024-05-18 13:38:08 Epoch 15: lr=0.0001
2024-05-18 13:39:20 [Epoch: 15] loss: 0.005438, mae: 0.052215, r2: 0.737703, val_loss: 0.006213, val_mae: 0.054878, val_r2: 0.701442
2024-05-18 13:39:20 Epoch 16: lr=0.0001
2024-05-18 13:40:32 [Epoch: 16] loss: 0.005388, mae: 0.051955, r2: 0.739909, val_loss: 0.006193, val_mae: 0.054911, val_r2: 0.703110
2024-05-18 13:40:32 Epoch 17: lr=0.0001
2024-05-18 13:41:44 [Epoch: 17] loss: 0.005341, mae: 0.051763, r2: 0.742062, val_loss: 0.006172, val_mae: 0.055534, val_r2: 0.703099
2024-05-18 13:41:45 Epoch 18: lr=0.0001
2024-05-18 13:42:57 [Epoch: 18] loss: 0.005303, mae: 0.051592, r2: 0.743831, val_loss: 0.006152, val_mae: 0.054725, val_r2: 0.703825
2024-05-18 13:42:57 Epoch 19: lr=0.0001
2024-05-18 13:44:09 [Epoch: 19] loss: 0.005242, mae: 0.051312, r2: 0.746664, val_loss: 0.006178, val_mae: 0.055119, val_r2: 0.702277
2024-05-18 13:44:09 Epoch 20: lr=5e-05
2024-05-18 13:45:21 [Epoch: 20] loss: 0.005135, mae: 0.050800, r2: 0.751794, val_loss: 0.006126, val_mae: 0.054737, val_r2: 0.705585
2024-05-18 13:45:21 Epoch 21: lr=5e-05
2024-05-18 13:46:33 [Epoch: 21] loss: 0.005104, mae: 0.050640, r2: 0.753096, val_loss: 0.006142, val_mae: 0.054518, val_r2: 0.703688
2024-05-18 13:46:33 Epoch 22: lr=5e-05
2024-05-18 13:47:45 [Epoch: 22] loss: 0.005067, mae: 0.050464, r2: 0.754583, val_loss: 0.006130, val_mae: 0.054884, val_r2: 0.705828
2024-05-18 13:47:46 Epoch 23: lr=5e-05
2024-05-18 13:48:57 [Epoch: 23] loss: 0.005037, mae: 0.050331, r2: 0.756221, val_loss: 0.006119, val_mae: 0.054696, val_r2: 0.705440
2024-05-18 13:48:57 Epoch 24: lr=5e-05
2024-05-18 13:50:09 [Epoch: 24] loss: 0.005021, mae: 0.050254, r2: 0.757081, val_loss: 0.006127, val_mae: 0.054502, val_r2: 0.705689
2024-05-18 13:50:09 Epoch 25: lr=2.5e-05
2024-05-18 13:51:22 [Epoch: 25] loss: 0.004954, mae: 0.049890, r2: 0.760261, val_loss: 0.006122, val_mae: 0.054346, val_r2: 0.705665
2024-05-18 13:51:22 Epoch 26: lr=2.5e-05
2024-05-18 13:52:34 [Epoch: 26] loss: 0.004930, mae: 0.049784, r2: 0.761164, val_loss: 0.006127, val_mae: 0.054327, val_r2: 0.705658
2024-05-18 13:52:34 Epoch 27: lr=2.5e-05
2024-05-18 13:53:46 [Epoch: 27] loss: 0.004917, mae: 0.049761, r2: 0.761745, val_loss: 0.006120, val_mae: 0.054573, val_r2: 0.706062
2024-05-18 13:53:46 Epoch 28: lr=2.5e-05
2024-05-18 13:54:58 [Epoch: 28] loss: 0.004906, mae: 0.049706, r2: 0.762349, val_loss: 0.006119, val_mae: 0.054410, val_r2: 0.706028
2024-05-18 13:54:59 Epoch 29: lr=2.5e-05
2024-05-18 13:56:10 [Epoch: 29] loss: 0.004880, mae: 0.049597, r2: 0.763402, val_loss: 0.006125, val_mae: 0.054365, val_r2: 0.705708
2024-05-18 13:56:10 Epoch 30: lr=1.25e-05
2024-05-18 13:57:22 [Epoch: 30] loss: 0.004855, mae: 0.049470, r2: 0.764613, val_loss: 0.006130, val_mae: 0.054476, val_r2: 0.705303
2024-05-18 13:57:22 Epoch 31: lr=1.25e-05
2024-05-18 13:58:35 [Epoch: 31] loss: 0.004845, mae: 0.049414, r2: 0.765269, val_loss: 0.006139, val_mae: 0.054574, val_r2: 0.704574
2024-05-18 13:58:35 Epoch 32: lr=1.25e-05
2024-05-18 13:59:47 [Epoch: 32] loss: 0.004844, mae: 0.049396, r2: 0.765197, val_loss: 0.006132, val_mae: 0.054349, val_r2: 0.704830
2024-05-18 13:59:47 Epoch 33: lr=1.25e-05
2024-05-18 14:00:59 [Epoch: 33] loss: 0.004841, mae: 0.049344, r2: 0.765434, val_loss: 0.006124, val_mae: 0.054357, val_r2: 0.704981
2024-05-18 14:00:59 Epoch 34: lr=1.25e-05
2024-05-18 14:02:11 [Epoch: 34] loss: 0.004833, mae: 0.049320, r2: 0.765815, val_loss: 0.006145, val_mae: 0.054540, val_r2: 0.704239
2024-05-18 14:02:11 Epoch 35: lr=1e-05
2024-05-18 14:03:23 [Epoch: 35] loss: 0.004809, mae: 0.049252, r2: 0.767045, val_loss: 0.006137, val_mae: 0.054465, val_r2: 0.705011
2024-05-18 14:03:23 Epoch 36: lr=1e-05
2024-05-18 14:04:36 [Epoch: 36] loss: 0.004817, mae: 0.049285, r2: 0.766523, val_loss: 0.006112, val_mae: 0.054253, val_r2: 0.706082
2024-05-18 14:04:36 Epoch 37: lr=1e-05
2024-05-18 14:05:48 [Epoch: 37] loss: 0.004808, mae: 0.049241, r2: 0.766962, val_loss: 0.006117, val_mae: 0.054200, val_r2: 0.705832
2024-05-18 14:05:48 Epoch 38: lr=1e-05
2024-05-18 14:07:00 [Epoch: 38] loss: 0.004797, mae: 0.049179, r2: 0.767390, val_loss: 0.006111, val_mae: 0.054205, val_r2: 0.706638
2024-05-18 14:07:00 Epoch 39: lr=1e-05
2024-05-18 14:08:12 [Epoch: 39] loss: 0.004792, mae: 0.049162, r2: 0.767677, val_loss: 0.006135, val_mae: 0.054584, val_r2: 0.705139
2024-05-18 14:08:12 Epoch 40: lr=1e-05
2024-05-18 14:09:25 [Epoch: 40] loss: 0.004793, mae: 0.049168, r2: 0.767677, val_loss: 0.006136, val_mae: 0.054526, val_r2: 0.705091
2024-05-18 14:09:25 Epoch 41: lr=1e-05
2024-05-18 14:10:37 [Epoch: 41] loss: 0.004787, mae: 0.049140, r2: 0.767910, val_loss: 0.006137, val_mae: 0.054542, val_r2: 0.705040
2024-05-18 14:10:37 Epoch 42: lr=1e-05
2024-05-18 14:11:49 [Epoch: 42] loss: 0.004790, mae: 0.049129, r2: 0.767916, val_loss: 0.006113, val_mae: 0.054500, val_r2: 0.705823
2024-05-18 14:11:49 Epoch 43: lr=1e-05
2024-05-18 14:13:02 [Epoch: 43] loss: 0.004774, mae: 0.049074, r2: 0.768668, val_loss: 0.006134, val_mae: 0.054718, val_r2: 0.704517
2024-05-18 14:13:02 Epoch 44: lr=1e-05
2024-05-18 14:14:14 [Epoch: 44] loss: 0.004774, mae: 0.049070, r2: 0.768558, val_loss: 0.006128, val_mae: 0.054560, val_r2: 0.705093
2024-05-18 14:14:14 Epoch 45: lr=1e-05
2024-05-18 14:15:26 [Epoch: 45] loss: 0.004766, mae: 0.049032, r2: 0.769083, val_loss: 0.006145, val_mae: 0.054329, val_r2: 0.704623
2024-05-18 14:15:27 Epoch 46: lr=1e-05
2024-05-18 14:16:38 [Epoch: 46] loss: 0.004756, mae: 0.048982, r2: 0.769619, val_loss: 0.006139, val_mae: 0.054245, val_r2: 0.704457
2024-05-18 14:16:38 Epoch 47: lr=1e-05
2024-05-18 14:17:50 [Epoch: 47] loss: 0.004752, mae: 0.048985, r2: 0.769700, val_loss: 0.006116, val_mae: 0.054292, val_r2: 0.705758
2024-05-18 14:17:50 Epoch 48: lr=1e-05
2024-05-18 14:19:03 [Epoch: 48] loss: 0.004743, mae: 0.048921, r2: 0.769977, val_loss: 0.006141, val_mae: 0.054324, val_r2: 0.704747
2024-05-18 14:19:03 history_length: 49
2024-05-18 14:19:03 stopping: early
2024-05-18 14:19:03 Comparing y_true and y_pred:
2024-05-18 14:19:03   mse: 0.01025940
2024-05-18 14:19:03   mae: 0.08084340
2024-05-18 14:19:03   r2: 0.43907644
2024-05-18 14:19:03   corr: 0.82094151
