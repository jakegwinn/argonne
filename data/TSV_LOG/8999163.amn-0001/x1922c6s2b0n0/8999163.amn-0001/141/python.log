2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/141', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '141', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/141/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/141', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c6s2b0n0.141.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/141/4.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/141'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x146f8f26f820>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/141/4.1.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04774764
2024-05-18 13:20:01   mae: 0.15981667
2024-05-18 13:20:01   r2: -1.00077756
2024-05-18 13:20:01   corr: -0.00038878
2024-05-18 13:20:01 Data points per epoch: train = 469613, val = 117404, test = 692
2024-05-18 13:20:01 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.030549, mae: 0.079833, r2: -0.376101, val_loss: 0.008977, val_mae: 0.066952, val_r2: 0.586656
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:26 [Epoch: 1] loss: 0.008059, mae: 0.064208, r2: 0.618975, val_loss: 0.007791, val_mae: 0.061704, val_r2: 0.632570
2024-05-18 13:22:26 Epoch 2: lr=0.00064
2024-05-18 13:23:38 [Epoch: 2] loss: 0.007346, mae: 0.060971, r2: 0.651007, val_loss: 0.007280, val_mae: 0.060921, val_r2: 0.650375
2024-05-18 13:23:38 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006871, mae: 0.058830, r2: 0.672984, val_loss: 0.006807, val_mae: 0.058671, val_r2: 0.674641
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:02 [Epoch: 4] loss: 0.006471, mae: 0.056977, r2: 0.691418, val_loss: 0.006644, val_mae: 0.057372, val_r2: 0.688806
2024-05-18 13:26:02 Epoch 5: lr=0.0001
2024-05-18 13:27:14 [Epoch: 5] loss: 0.006131, mae: 0.055388, r2: 0.707293, val_loss: 0.006371, val_mae: 0.055977, val_r2: 0.697121
2024-05-18 13:27:14 Epoch 6: lr=0.0001
2024-05-18 13:28:26 [Epoch: 6] loss: 0.006022, mae: 0.054907, r2: 0.712007, val_loss: 0.006324, val_mae: 0.056043, val_r2: 0.698883
2024-05-18 13:28:26 Epoch 7: lr=0.0001
2024-05-18 13:29:38 [Epoch: 7] loss: 0.005950, mae: 0.054588, r2: 0.715296, val_loss: 0.006296, val_mae: 0.056095, val_r2: 0.700119
2024-05-18 13:29:38 Epoch 8: lr=0.0001
2024-05-18 13:30:50 [Epoch: 8] loss: 0.005873, mae: 0.054213, r2: 0.719034, val_loss: 0.006283, val_mae: 0.056058, val_r2: 0.700472
2024-05-18 13:30:51 Epoch 9: lr=0.0001
2024-05-18 13:32:03 [Epoch: 9] loss: 0.005816, mae: 0.053982, r2: 0.721578, val_loss: 0.006220, val_mae: 0.055172, val_r2: 0.704044
2024-05-18 13:32:03 Epoch 10: lr=0.0001
2024-05-18 13:33:14 [Epoch: 10] loss: 0.005751, mae: 0.053691, r2: 0.724456, val_loss: 0.006198, val_mae: 0.055152, val_r2: 0.706030
2024-05-18 13:33:14 Epoch 11: lr=0.0001
2024-05-18 13:34:26 [Epoch: 11] loss: 0.005687, mae: 0.053401, r2: 0.727581, val_loss: 0.006187, val_mae: 0.055109, val_r2: 0.706038
2024-05-18 13:34:26 Epoch 12: lr=0.0001
2024-05-18 13:35:37 [Epoch: 12] loss: 0.005633, mae: 0.053191, r2: 0.729834, val_loss: 0.006170, val_mae: 0.054964, val_r2: 0.706242
2024-05-18 13:35:37 Epoch 13: lr=0.0001
2024-05-18 13:36:49 [Epoch: 13] loss: 0.005578, mae: 0.052922, r2: 0.732678, val_loss: 0.006175, val_mae: 0.054942, val_r2: 0.705396
2024-05-18 13:36:49 Epoch 14: lr=0.0001
2024-05-18 13:38:01 [Epoch: 14] loss: 0.005515, mae: 0.052640, r2: 0.735398, val_loss: 0.006146, val_mae: 0.054615, val_r2: 0.707249
2024-05-18 13:38:01 Epoch 15: lr=5e-05
2024-05-18 13:39:13 [Epoch: 15] loss: 0.005397, mae: 0.052114, r2: 0.740816, val_loss: 0.006122, val_mae: 0.054573, val_r2: 0.707812
2024-05-18 13:39:13 Epoch 16: lr=5e-05
2024-05-18 13:40:25 [Epoch: 16] loss: 0.005361, mae: 0.051887, r2: 0.742584, val_loss: 0.006097, val_mae: 0.055012, val_r2: 0.708986
2024-05-18 13:40:25 Epoch 17: lr=5e-05
2024-05-18 13:41:37 [Epoch: 17] loss: 0.005331, mae: 0.051809, r2: 0.743785, val_loss: 0.006055, val_mae: 0.055036, val_r2: 0.711600
2024-05-18 13:41:37 Epoch 18: lr=5e-05
2024-05-18 13:42:49 [Epoch: 18] loss: 0.005294, mae: 0.051600, r2: 0.745822, val_loss: 0.006107, val_mae: 0.054824, val_r2: 0.708719
2024-05-18 13:42:49 Epoch 19: lr=5e-05
2024-05-18 13:44:01 [Epoch: 19] loss: 0.005256, mae: 0.051449, r2: 0.747199, val_loss: 0.006067, val_mae: 0.054485, val_r2: 0.710968
2024-05-18 13:44:01 Epoch 20: lr=5e-05
2024-05-18 13:45:13 [Epoch: 20] loss: 0.005242, mae: 0.051343, r2: 0.748089, val_loss: 0.006104, val_mae: 0.054714, val_r2: 0.709096
2024-05-18 13:45:13 Epoch 21: lr=5e-05
2024-05-18 13:46:25 [Epoch: 21] loss: 0.005211, mae: 0.051235, r2: 0.749639, val_loss: 0.006068, val_mae: 0.054397, val_r2: 0.711045
2024-05-18 13:46:25 Epoch 22: lr=2.5e-05
2024-05-18 13:47:37 [Epoch: 22] loss: 0.005148, mae: 0.050917, r2: 0.752513, val_loss: 0.006052, val_mae: 0.054337, val_r2: 0.711592
2024-05-18 13:47:37 Epoch 23: lr=2.5e-05
2024-05-18 13:48:48 [Epoch: 23] loss: 0.005139, mae: 0.050871, r2: 0.752888, val_loss: 0.006077, val_mae: 0.054587, val_r2: 0.709701
2024-05-18 13:48:48 Epoch 24: lr=2.5e-05
2024-05-18 13:49:59 [Epoch: 24] loss: 0.005113, mae: 0.050793, r2: 0.753888, val_loss: 0.006053, val_mae: 0.054476, val_r2: 0.711668
2024-05-18 13:50:00 Epoch 25: lr=2.5e-05
2024-05-18 13:51:12 [Epoch: 25] loss: 0.005098, mae: 0.050733, r2: 0.754920, val_loss: 0.006088, val_mae: 0.054212, val_r2: 0.709495
2024-05-18 13:51:12 Epoch 26: lr=2.5e-05
2024-05-18 13:52:24 [Epoch: 26] loss: 0.005084, mae: 0.050637, r2: 0.755159, val_loss: 0.006069, val_mae: 0.054504, val_r2: 0.710434
2024-05-18 13:52:24 Epoch 27: lr=1.25e-05
2024-05-18 13:53:35 [Epoch: 27] loss: 0.005050, mae: 0.050438, r2: 0.757185, val_loss: 0.006098, val_mae: 0.054347, val_r2: 0.709654
2024-05-18 13:53:35 Epoch 28: lr=1.25e-05
2024-05-18 13:54:47 [Epoch: 28] loss: 0.005045, mae: 0.050459, r2: 0.757105, val_loss: 0.006069, val_mae: 0.054544, val_r2: 0.711190
2024-05-18 13:54:47 Epoch 29: lr=1.25e-05
2024-05-18 13:55:59 [Epoch: 29] loss: 0.005032, mae: 0.050391, r2: 0.757897, val_loss: 0.006064, val_mae: 0.054363, val_r2: 0.710950
2024-05-18 13:55:59 Epoch 30: lr=1.25e-05
2024-05-18 13:57:11 [Epoch: 30] loss: 0.005014, mae: 0.050284, r2: 0.758900, val_loss: 0.006065, val_mae: 0.054376, val_r2: 0.710742
2024-05-18 13:57:11 Epoch 31: lr=1.25e-05
2024-05-18 13:58:23 [Epoch: 31] loss: 0.005019, mae: 0.050338, r2: 0.758345, val_loss: 0.006103, val_mae: 0.054359, val_r2: 0.709067
2024-05-18 13:58:23 Epoch 32: lr=1e-05
2024-05-18 13:59:35 [Epoch: 32] loss: 0.005004, mae: 0.050231, r2: 0.759068, val_loss: 0.006051, val_mae: 0.054222, val_r2: 0.711513
2024-05-18 13:59:35 Epoch 33: lr=1e-05
2024-05-18 14:00:47 [Epoch: 33] loss: 0.004993, mae: 0.050204, r2: 0.759659, val_loss: 0.006089, val_mae: 0.054384, val_r2: 0.709542
2024-05-18 14:00:47 Epoch 34: lr=1e-05
2024-05-18 14:01:59 [Epoch: 34] loss: 0.004988, mae: 0.050174, r2: 0.759726, val_loss: 0.006064, val_mae: 0.054361, val_r2: 0.710707
2024-05-18 14:01:59 Epoch 35: lr=1e-05
2024-05-18 14:03:11 [Epoch: 35] loss: 0.004988, mae: 0.050163, r2: 0.759834, val_loss: 0.006084, val_mae: 0.054296, val_r2: 0.710341
2024-05-18 14:03:11 Epoch 36: lr=1e-05
2024-05-18 14:04:22 [Epoch: 36] loss: 0.004982, mae: 0.050174, r2: 0.760375, val_loss: 0.006072, val_mae: 0.054278, val_r2: 0.711019
2024-05-18 14:04:22 Epoch 37: lr=1e-05
2024-05-18 14:05:34 [Epoch: 37] loss: 0.004967, mae: 0.050094, r2: 0.760844, val_loss: 0.006076, val_mae: 0.054429, val_r2: 0.709987
2024-05-18 14:05:34 Epoch 38: lr=1e-05
2024-05-18 14:06:46 [Epoch: 38] loss: 0.004962, mae: 0.050071, r2: 0.761221, val_loss: 0.006072, val_mae: 0.054410, val_r2: 0.710634
2024-05-18 14:06:46 Epoch 39: lr=1e-05
2024-05-18 14:07:58 [Epoch: 39] loss: 0.004959, mae: 0.050052, r2: 0.761240, val_loss: 0.006049, val_mae: 0.054300, val_r2: 0.711278
2024-05-18 14:07:58 Epoch 40: lr=1e-05
2024-05-18 14:09:10 [Epoch: 40] loss: 0.004957, mae: 0.050036, r2: 0.761222, val_loss: 0.006071, val_mae: 0.054232, val_r2: 0.710535
2024-05-18 14:09:10 Epoch 41: lr=1e-05
2024-05-18 14:10:21 [Epoch: 41] loss: 0.004951, mae: 0.050022, r2: 0.761524, val_loss: 0.006080, val_mae: 0.054210, val_r2: 0.710027
2024-05-18 14:10:22 Epoch 42: lr=1e-05
2024-05-18 14:11:33 [Epoch: 42] loss: 0.004943, mae: 0.049975, r2: 0.761919, val_loss: 0.006047, val_mae: 0.054167, val_r2: 0.711793
2024-05-18 14:11:33 Epoch 43: lr=1e-05
2024-05-18 14:12:45 [Epoch: 43] loss: 0.004940, mae: 0.049924, r2: 0.762311, val_loss: 0.006093, val_mae: 0.054240, val_r2: 0.709299
2024-05-18 14:12:45 Epoch 44: lr=1e-05
2024-05-18 14:13:57 [Epoch: 44] loss: 0.004933, mae: 0.049931, r2: 0.762288, val_loss: 0.006065, val_mae: 0.054334, val_r2: 0.710801
2024-05-18 14:13:57 Epoch 45: lr=1e-05
2024-05-18 14:15:09 [Epoch: 45] loss: 0.004927, mae: 0.049883, r2: 0.762638, val_loss: 0.006062, val_mae: 0.054172, val_r2: 0.711500
2024-05-18 14:15:09 Epoch 46: lr=1e-05
2024-05-18 14:16:20 [Epoch: 46] loss: 0.004922, mae: 0.049854, r2: 0.763006, val_loss: 0.006072, val_mae: 0.054299, val_r2: 0.710248
2024-05-18 14:16:20 Epoch 47: lr=1e-05
2024-05-18 14:17:32 [Epoch: 47] loss: 0.004917, mae: 0.049845, r2: 0.763153, val_loss: 0.006101, val_mae: 0.054251, val_r2: 0.709272
2024-05-18 14:17:32 Epoch 48: lr=1e-05
2024-05-18 14:18:43 [Epoch: 48] loss: 0.004918, mae: 0.049824, r2: 0.763295, val_loss: 0.006061, val_mae: 0.054288, val_r2: 0.710948
2024-05-18 14:18:43 Epoch 49: lr=1e-05
2024-05-18 14:19:54 [Epoch: 49] loss: 0.004913, mae: 0.049809, r2: 0.763369, val_loss: 0.006043, val_mae: 0.054224, val_r2: 0.712190
2024-05-18 14:19:54 Epoch 50: lr=1e-05
2024-05-18 14:21:06 [Epoch: 50] loss: 0.004911, mae: 0.049813, r2: 0.763512, val_loss: 0.006065, val_mae: 0.054255, val_r2: 0.710902
2024-05-18 14:21:06 Epoch 51: lr=1e-05
2024-05-18 14:22:17 [Epoch: 51] loss: 0.004900, mae: 0.049758, r2: 0.764043, val_loss: 0.006049, val_mae: 0.054226, val_r2: 0.711486
2024-05-18 14:22:17 Epoch 52: lr=1e-05
2024-05-18 14:23:29 [Epoch: 52] loss: 0.004902, mae: 0.049780, r2: 0.763792, val_loss: 0.006055, val_mae: 0.054131, val_r2: 0.710673
2024-05-18 14:23:29 Epoch 53: lr=1e-05
2024-05-18 14:24:40 [Epoch: 53] loss: 0.004886, mae: 0.049696, r2: 0.764456, val_loss: 0.006054, val_mae: 0.054294, val_r2: 0.712026
2024-05-18 14:24:40 Epoch 54: lr=1e-05
2024-05-18 14:25:51 [Epoch: 54] loss: 0.004872, mae: 0.049623, r2: 0.765223, val_loss: 0.006073, val_mae: 0.054089, val_r2: 0.710730
2024-05-18 14:25:51 Epoch 55: lr=1e-05
2024-05-18 14:27:03 [Epoch: 55] loss: 0.004886, mae: 0.049686, r2: 0.764538, val_loss: 0.006055, val_mae: 0.054204, val_r2: 0.711338
2024-05-18 14:27:03 Epoch 56: lr=1e-05
2024-05-18 14:28:15 [Epoch: 56] loss: 0.004873, mae: 0.049606, r2: 0.765068, val_loss: 0.006090, val_mae: 0.054316, val_r2: 0.709838
2024-05-18 14:28:15 Epoch 57: lr=1e-05
2024-05-18 14:29:26 [Epoch: 57] loss: 0.004871, mae: 0.049644, r2: 0.765210, val_loss: 0.006032, val_mae: 0.054127, val_r2: 0.712496
2024-05-18 14:29:26 Epoch 58: lr=1e-05
2024-05-18 14:30:38 [Epoch: 58] loss: 0.004873, mae: 0.049632, r2: 0.765258, val_loss: 0.006038, val_mae: 0.054089, val_r2: 0.712412
2024-05-18 14:30:38 Epoch 59: lr=1e-05
2024-05-18 14:31:49 [Epoch: 59] loss: 0.004865, mae: 0.049571, r2: 0.765338, val_loss: 0.006059, val_mae: 0.054244, val_r2: 0.711359
2024-05-18 14:31:49 Epoch 60: lr=1e-05
2024-05-18 14:33:00 [Epoch: 60] loss: 0.004852, mae: 0.049516, r2: 0.766151, val_loss: 0.006061, val_mae: 0.054113, val_r2: 0.710758
2024-05-18 14:33:01 Epoch 61: lr=1e-05
2024-05-18 14:34:12 [Epoch: 61] loss: 0.004859, mae: 0.049573, r2: 0.765874, val_loss: 0.006067, val_mae: 0.054251, val_r2: 0.710838
2024-05-18 14:34:12 Epoch 62: lr=1e-05
2024-05-18 14:35:23 [Epoch: 62] loss: 0.004855, mae: 0.049537, r2: 0.766103, val_loss: 0.006072, val_mae: 0.054224, val_r2: 0.710393
2024-05-18 14:35:23 Epoch 63: lr=1e-05
2024-05-18 14:36:34 [Epoch: 63] loss: 0.004841, mae: 0.049459, r2: 0.766697, val_loss: 0.006043, val_mae: 0.054098, val_r2: 0.712214
2024-05-18 14:36:34 Epoch 64: lr=1e-05
2024-05-18 14:37:46 [Epoch: 64] loss: 0.004834, mae: 0.049425, r2: 0.766940, val_loss: 0.006080, val_mae: 0.054086, val_r2: 0.710048
2024-05-18 14:37:46 Epoch 65: lr=1e-05
2024-05-18 14:38:57 [Epoch: 65] loss: 0.004831, mae: 0.049455, r2: 0.766895, val_loss: 0.006056, val_mae: 0.054065, val_r2: 0.710761
2024-05-18 14:38:57 Epoch 66: lr=1e-05
2024-05-18 14:40:09 [Epoch: 66] loss: 0.004832, mae: 0.049440, r2: 0.766944, val_loss: 0.006083, val_mae: 0.054134, val_r2: 0.710185
2024-05-18 14:40:09 Epoch 67: lr=1e-05
2024-05-18 14:41:20 [Epoch: 67] loss: 0.004821, mae: 0.049349, r2: 0.767505, val_loss: 0.006072, val_mae: 0.054143, val_r2: 0.710737
2024-05-18 14:41:21 history_length: 68
2024-05-18 14:41:21 stopping: early
2024-05-18 14:41:21 Comparing y_true and y_pred:
2024-05-18 14:41:21   mse: 0.00688180
2024-05-18 14:41:21   mae: 0.06810341
2024-05-18 14:41:21   r2: -0.68553233
2024-05-18 14:41:21   corr: 0.52721907
