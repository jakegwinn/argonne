2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/51', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '51', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/51/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/51', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s5b0n0.51.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/51/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/51'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x154c3db2efd0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/51/1.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04782236
2024-05-18 13:20:02   mae: 0.16006547
2024-05-18 13:20:02   r2: -0.99425471
2024-05-18 13:20:02   corr: 0.00287265
2024-05-18 13:20:02 Data points per epoch: train = 468724, val = 117181, test = 1804
2024-05-18 13:20:02 Steps per epoch: train = 14647, val = 3661, test = 56
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.045033, mae: 0.080125, r2: -0.380408, val_loss: 0.008389, val_mae: 0.065722, val_r2: 0.603725
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:26 [Epoch: 1] loss: 0.008008, mae: 0.064008, r2: 0.620074, val_loss: 0.007595, val_mae: 0.062501, val_r2: 0.640037
2024-05-18 13:22:26 Epoch 2: lr=0.00064
2024-05-18 13:23:37 [Epoch: 2] loss: 0.007310, mae: 0.060791, r2: 0.651958, val_loss: 0.007184, val_mae: 0.059978, val_r2: 0.660099
2024-05-18 13:23:37 Epoch 3: lr=0.00046
2024-05-18 13:24:48 [Epoch: 3] loss: 0.006837, mae: 0.058638, r2: 0.673240, val_loss: 0.006880, val_mae: 0.058384, val_r2: 0.675068
2024-05-18 13:24:48 Epoch 4: lr=0.00028
2024-05-18 13:25:59 [Epoch: 4] loss: 0.006422, mae: 0.056772, r2: 0.692529, val_loss: 0.006615, val_mae: 0.056937, val_r2: 0.685867
2024-05-18 13:25:59 Epoch 5: lr=0.0001
2024-05-18 13:27:11 [Epoch: 5] loss: 0.006092, mae: 0.055233, r2: 0.707667, val_loss: 0.006444, val_mae: 0.056124, val_r2: 0.694376
2024-05-18 13:27:11 Epoch 6: lr=0.0001
2024-05-18 13:28:22 [Epoch: 6] loss: 0.005985, mae: 0.054752, r2: 0.712593, val_loss: 0.006378, val_mae: 0.056220, val_r2: 0.696840
2024-05-18 13:28:22 Epoch 7: lr=0.0001
2024-05-18 13:29:33 [Epoch: 7] loss: 0.005906, mae: 0.054384, r2: 0.716182, val_loss: 0.006355, val_mae: 0.056308, val_r2: 0.698902
2024-05-18 13:29:33 Epoch 8: lr=0.0001
2024-05-18 13:30:44 [Epoch: 8] loss: 0.005840, mae: 0.054106, r2: 0.719251, val_loss: 0.006336, val_mae: 0.055602, val_r2: 0.699045
2024-05-18 13:30:44 Epoch 9: lr=0.0001
2024-05-18 13:31:56 [Epoch: 9] loss: 0.005757, mae: 0.053750, r2: 0.723126, val_loss: 0.006303, val_mae: 0.055298, val_r2: 0.700792
2024-05-18 13:31:56 Epoch 10: lr=0.0001
2024-05-18 13:33:07 [Epoch: 10] loss: 0.005703, mae: 0.053491, r2: 0.725853, val_loss: 0.006266, val_mae: 0.055496, val_r2: 0.702290
2024-05-18 13:33:08 Epoch 11: lr=0.0001
2024-05-18 13:34:19 [Epoch: 11] loss: 0.005640, mae: 0.053218, r2: 0.728477, val_loss: 0.006231, val_mae: 0.055318, val_r2: 0.704994
2024-05-18 13:34:19 Epoch 12: lr=0.0001
2024-05-18 13:35:30 [Epoch: 12] loss: 0.005591, mae: 0.052970, r2: 0.731021, val_loss: 0.006241, val_mae: 0.055137, val_r2: 0.703339
2024-05-18 13:35:30 Epoch 13: lr=0.0001
2024-05-18 13:36:42 [Epoch: 13] loss: 0.005523, mae: 0.052671, r2: 0.734095, val_loss: 0.006230, val_mae: 0.055581, val_r2: 0.703014
2024-05-18 13:36:42 Epoch 14: lr=0.0001
2024-05-18 13:37:53 [Epoch: 14] loss: 0.005462, mae: 0.052422, r2: 0.736804, val_loss: 0.006224, val_mae: 0.054854, val_r2: 0.704537
2024-05-18 13:37:53 Epoch 15: lr=0.0001
2024-05-18 13:39:04 [Epoch: 15] loss: 0.005427, mae: 0.052202, r2: 0.738285, val_loss: 0.006147, val_mae: 0.054901, val_r2: 0.707143
2024-05-18 13:39:04 Epoch 16: lr=0.0001
2024-05-18 13:40:15 [Epoch: 16] loss: 0.005370, mae: 0.051969, r2: 0.741030, val_loss: 0.006154, val_mae: 0.054973, val_r2: 0.706689
2024-05-18 13:40:16 Epoch 17: lr=5e-05
2024-05-18 13:41:27 [Epoch: 17] loss: 0.005264, mae: 0.051471, r2: 0.746082, val_loss: 0.006146, val_mae: 0.054663, val_r2: 0.707163
2024-05-18 13:41:27 Epoch 18: lr=5e-05
2024-05-18 13:42:38 [Epoch: 18] loss: 0.005219, mae: 0.051216, r2: 0.748207, val_loss: 0.006122, val_mae: 0.054451, val_r2: 0.709374
2024-05-18 13:42:38 Epoch 19: lr=5e-05
2024-05-18 13:43:49 [Epoch: 19] loss: 0.005186, mae: 0.051089, r2: 0.749569, val_loss: 0.006119, val_mae: 0.054505, val_r2: 0.708889
2024-05-18 13:43:49 Epoch 20: lr=5e-05
2024-05-18 13:45:00 [Epoch: 20] loss: 0.005166, mae: 0.050964, r2: 0.750731, val_loss: 0.006132, val_mae: 0.054743, val_r2: 0.708744
2024-05-18 13:45:00 Epoch 21: lr=5e-05
2024-05-18 13:46:11 [Epoch: 21] loss: 0.005132, mae: 0.050838, r2: 0.752229, val_loss: 0.006124, val_mae: 0.054624, val_r2: 0.709087
2024-05-18 13:46:11 Epoch 22: lr=5e-05
2024-05-18 13:47:22 [Epoch: 22] loss: 0.005102, mae: 0.050666, r2: 0.753484, val_loss: 0.006111, val_mae: 0.054772, val_r2: 0.710192
2024-05-18 13:47:23 Epoch 23: lr=5e-05
2024-05-18 13:48:34 [Epoch: 23] loss: 0.005075, mae: 0.050557, r2: 0.754743, val_loss: 0.006116, val_mae: 0.054672, val_r2: 0.709456
2024-05-18 13:48:34 Epoch 24: lr=2.5e-05
2024-05-18 13:49:45 [Epoch: 24] loss: 0.005018, mae: 0.050259, r2: 0.757370, val_loss: 0.006102, val_mae: 0.054431, val_r2: 0.709152
2024-05-18 13:49:46 Epoch 25: lr=2.5e-05
2024-05-18 13:50:57 [Epoch: 25] loss: 0.004993, mae: 0.050168, r2: 0.758682, val_loss: 0.006136, val_mae: 0.054649, val_r2: 0.708619
2024-05-18 13:50:57 Epoch 26: lr=2.5e-05
2024-05-18 13:52:08 [Epoch: 26] loss: 0.004974, mae: 0.050078, r2: 0.759501, val_loss: 0.006098, val_mae: 0.054565, val_r2: 0.710001
2024-05-18 13:52:08 Epoch 27: lr=2.5e-05
2024-05-18 13:53:19 [Epoch: 27] loss: 0.004967, mae: 0.050047, r2: 0.759899, val_loss: 0.006115, val_mae: 0.054914, val_r2: 0.708821
2024-05-18 13:53:19 Epoch 28: lr=2.5e-05
2024-05-18 13:54:30 [Epoch: 28] loss: 0.004955, mae: 0.049973, r2: 0.760320, val_loss: 0.006114, val_mae: 0.054385, val_r2: 0.709411
2024-05-18 13:54:30 Epoch 29: lr=1.25e-05
2024-05-18 13:55:42 [Epoch: 29] loss: 0.004910, mae: 0.049758, r2: 0.762558, val_loss: 0.006130, val_mae: 0.054554, val_r2: 0.708965
2024-05-18 13:55:42 Epoch 30: lr=1.25e-05
2024-05-18 13:56:53 [Epoch: 30] loss: 0.004900, mae: 0.049747, r2: 0.762830, val_loss: 0.006114, val_mae: 0.054415, val_r2: 0.708945
2024-05-18 13:56:53 Epoch 31: lr=1.25e-05
2024-05-18 13:58:04 [Epoch: 31] loss: 0.004895, mae: 0.049710, r2: 0.763305, val_loss: 0.006096, val_mae: 0.054322, val_r2: 0.710178
2024-05-18 13:58:04 Epoch 32: lr=1.25e-05
2024-05-18 13:59:16 [Epoch: 32] loss: 0.004888, mae: 0.049677, r2: 0.763377, val_loss: 0.006116, val_mae: 0.054542, val_r2: 0.709550
2024-05-18 13:59:16 Epoch 33: lr=1.25e-05
2024-05-18 14:00:27 [Epoch: 33] loss: 0.004893, mae: 0.049706, r2: 0.763060, val_loss: 0.006101, val_mae: 0.054323, val_r2: 0.709797
2024-05-18 14:00:28 Epoch 34: lr=1e-05
2024-05-18 14:01:39 [Epoch: 34] loss: 0.004875, mae: 0.049616, r2: 0.764171, val_loss: 0.006096, val_mae: 0.054193, val_r2: 0.710240
2024-05-18 14:01:39 Epoch 35: lr=1e-05
2024-05-18 14:02:50 [Epoch: 35] loss: 0.004872, mae: 0.049556, r2: 0.764367, val_loss: 0.006094, val_mae: 0.054317, val_r2: 0.709954
2024-05-18 14:02:50 Epoch 36: lr=1e-05
2024-05-18 14:04:02 [Epoch: 36] loss: 0.004852, mae: 0.049519, r2: 0.765453, val_loss: 0.006104, val_mae: 0.054417, val_r2: 0.709543
2024-05-18 14:04:02 Epoch 37: lr=1e-05
2024-05-18 14:05:13 [Epoch: 37] loss: 0.004858, mae: 0.049534, r2: 0.765068, val_loss: 0.006125, val_mae: 0.054420, val_r2: 0.708565
2024-05-18 14:05:13 Epoch 38: lr=1e-05
2024-05-18 14:06:24 [Epoch: 38] loss: 0.004847, mae: 0.049493, r2: 0.765586, val_loss: 0.006106, val_mae: 0.054267, val_r2: 0.709096
2024-05-18 14:06:24 Epoch 39: lr=1e-05
2024-05-18 14:07:35 [Epoch: 39] loss: 0.004843, mae: 0.049471, r2: 0.765558, val_loss: 0.006102, val_mae: 0.054311, val_r2: 0.708968
2024-05-18 14:07:35 Epoch 40: lr=1e-05
2024-05-18 14:08:47 [Epoch: 40] loss: 0.004846, mae: 0.049459, r2: 0.765572, val_loss: 0.006121, val_mae: 0.054212, val_r2: 0.709238
2024-05-18 14:08:47 Epoch 41: lr=1e-05
2024-05-18 14:09:58 [Epoch: 41] loss: 0.004840, mae: 0.049412, r2: 0.765519, val_loss: 0.006109, val_mae: 0.054312, val_r2: 0.709598
2024-05-18 14:09:58 Epoch 42: lr=1e-05
2024-05-18 14:11:09 [Epoch: 42] loss: 0.004840, mae: 0.049400, r2: 0.765755, val_loss: 0.006081, val_mae: 0.054297, val_r2: 0.710445
2024-05-18 14:11:09 Epoch 43: lr=1e-05
2024-05-18 14:12:20 [Epoch: 43] loss: 0.004837, mae: 0.049407, r2: 0.765958, val_loss: 0.006107, val_mae: 0.054248, val_r2: 0.709587
2024-05-18 14:12:20 Epoch 44: lr=1e-05
2024-05-18 14:13:31 [Epoch: 44] loss: 0.004825, mae: 0.049373, r2: 0.766558, val_loss: 0.006112, val_mae: 0.054256, val_r2: 0.709702
2024-05-18 14:13:31 Epoch 45: lr=1e-05
2024-05-18 14:14:42 [Epoch: 45] loss: 0.004821, mae: 0.049360, r2: 0.766855, val_loss: 0.006104, val_mae: 0.054421, val_r2: 0.709253
2024-05-18 14:14:42 Epoch 46: lr=1e-05
2024-05-18 14:15:53 [Epoch: 46] loss: 0.004801, mae: 0.049286, r2: 0.767516, val_loss: 0.006076, val_mae: 0.054208, val_r2: 0.710277
2024-05-18 14:15:53 Epoch 47: lr=1e-05
2024-05-18 14:17:04 [Epoch: 47] loss: 0.004814, mae: 0.049281, r2: 0.766993, val_loss: 0.006108, val_mae: 0.054176, val_r2: 0.709296
2024-05-18 14:17:04 Epoch 48: lr=1e-05
2024-05-18 14:18:15 [Epoch: 48] loss: 0.004798, mae: 0.049242, r2: 0.767692, val_loss: 0.006117, val_mae: 0.054462, val_r2: 0.709036
2024-05-18 14:18:15 Epoch 49: lr=1e-05
2024-05-18 14:19:26 [Epoch: 49] loss: 0.004799, mae: 0.049238, r2: 0.767513, val_loss: 0.006095, val_mae: 0.054366, val_r2: 0.710083
2024-05-18 14:19:26 Epoch 50: lr=1e-05
2024-05-18 14:20:38 [Epoch: 50] loss: 0.004788, mae: 0.049175, r2: 0.768252, val_loss: 0.006091, val_mae: 0.054130, val_r2: 0.709837
2024-05-18 14:20:38 Epoch 51: lr=1e-05
2024-05-18 14:21:48 [Epoch: 51] loss: 0.004797, mae: 0.049218, r2: 0.767837, val_loss: 0.006075, val_mae: 0.054139, val_r2: 0.711329
2024-05-18 14:21:49 Epoch 52: lr=1e-05
2024-05-18 14:23:00 [Epoch: 52] loss: 0.004779, mae: 0.049154, r2: 0.768600, val_loss: 0.006090, val_mae: 0.054231, val_r2: 0.711016
2024-05-18 14:23:00 Epoch 53: lr=1e-05
2024-05-18 14:24:11 [Epoch: 53] loss: 0.004777, mae: 0.049120, r2: 0.768694, val_loss: 0.006117, val_mae: 0.054219, val_r2: 0.709068
2024-05-18 14:24:11 Epoch 54: lr=1e-05
2024-05-18 14:25:22 [Epoch: 54] loss: 0.004774, mae: 0.049074, r2: 0.768870, val_loss: 0.006096, val_mae: 0.054356, val_r2: 0.709890
2024-05-18 14:25:22 Epoch 55: lr=1e-05
2024-05-18 14:26:33 [Epoch: 55] loss: 0.004761, mae: 0.049056, r2: 0.769751, val_loss: 0.006148, val_mae: 0.054299, val_r2: 0.707228
2024-05-18 14:26:33 Epoch 56: lr=1e-05
2024-05-18 14:27:44 [Epoch: 56] loss: 0.004754, mae: 0.049011, r2: 0.769863, val_loss: 0.006080, val_mae: 0.054267, val_r2: 0.710220
2024-05-18 14:27:44 Epoch 57: lr=1e-05
2024-05-18 14:28:55 [Epoch: 57] loss: 0.004759, mae: 0.049013, r2: 0.769608, val_loss: 0.006101, val_mae: 0.054339, val_r2: 0.709988
2024-05-18 14:28:55 Epoch 58: lr=1e-05
2024-05-18 14:30:06 [Epoch: 58] loss: 0.004748, mae: 0.048993, r2: 0.770018, val_loss: 0.006137, val_mae: 0.054333, val_r2: 0.707501
2024-05-18 14:30:06 Epoch 59: lr=1e-05
2024-05-18 14:31:17 [Epoch: 59] loss: 0.004750, mae: 0.048979, r2: 0.770171, val_loss: 0.006116, val_mae: 0.054474, val_r2: 0.709131
2024-05-18 14:31:17 Epoch 60: lr=1e-05
2024-05-18 14:32:28 [Epoch: 60] loss: 0.004744, mae: 0.048973, r2: 0.770365, val_loss: 0.006130, val_mae: 0.054323, val_r2: 0.708487
2024-05-18 14:32:28 Epoch 61: lr=1e-05
2024-05-18 14:33:39 [Epoch: 61] loss: 0.004734, mae: 0.048917, r2: 0.770570, val_loss: 0.006119, val_mae: 0.054338, val_r2: 0.708296
2024-05-18 14:33:39 history_length: 62
2024-05-18 14:33:39 stopping: early
2024-05-18 14:33:39 Comparing y_true and y_pred:
2024-05-18 14:33:39   mse: 0.01229066
2024-05-18 14:33:39   mae: 0.08627178
2024-05-18 14:33:39   r2: 0.13801564
2024-05-18 14:33:39   corr: 0.38103063
