2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/52', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '52', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/52/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/52', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s5b0n0.52.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/52/2.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/52'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x146a11ab7c70>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/52/2.0.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04751375
2024-05-18 13:20:01   mae: 0.15995692
2024-05-18 13:20:01   r2: -1.00018023
2024-05-18 13:20:01   corr: -0.00009011
2024-05-18 13:20:01 Data points per epoch: train = 469237, val = 117310, test = 1162
2024-05-18 13:20:01 Steps per epoch: train = 14663, val = 3665, test = 36
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:15 [Epoch: 0] loss: 0.024080, mae: 0.079144, r2: 0.084634, val_loss: 0.008405, val_mae: 0.065708, val_r2: 0.598763
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:28 [Epoch: 1] loss: 0.008004, mae: 0.064034, r2: 0.621335, val_loss: 0.007668, val_mae: 0.061636, val_r2: 0.631355
2024-05-18 13:22:28 Epoch 2: lr=0.00064
2024-05-18 13:23:40 [Epoch: 2] loss: 0.007323, mae: 0.060866, r2: 0.652290, val_loss: 0.007348, val_mae: 0.059985, val_r2: 0.643820
2024-05-18 13:23:40 Epoch 3: lr=0.00046
2024-05-18 13:24:53 [Epoch: 3] loss: 0.006851, mae: 0.058729, r2: 0.673961, val_loss: 0.006867, val_mae: 0.059094, val_r2: 0.668349
2024-05-18 13:24:53 Epoch 4: lr=0.00028
2024-05-18 13:26:05 [Epoch: 4] loss: 0.006459, mae: 0.056976, r2: 0.691835, val_loss: 0.006535, val_mae: 0.056961, val_r2: 0.685923
2024-05-18 13:26:05 Epoch 5: lr=0.0001
2024-05-18 13:27:18 [Epoch: 5] loss: 0.006120, mae: 0.055357, r2: 0.707529, val_loss: 0.006421, val_mae: 0.056647, val_r2: 0.691882
2024-05-18 13:27:18 Epoch 6: lr=0.0001
2024-05-18 13:28:30 [Epoch: 6] loss: 0.006010, mae: 0.054883, r2: 0.712609, val_loss: 0.006380, val_mae: 0.055946, val_r2: 0.693658
2024-05-18 13:28:30 Epoch 7: lr=0.0001
2024-05-18 13:29:42 [Epoch: 7] loss: 0.005934, mae: 0.054573, r2: 0.716209, val_loss: 0.006340, val_mae: 0.055886, val_r2: 0.694828
2024-05-18 13:29:42 Epoch 8: lr=0.0001
2024-05-18 13:30:55 [Epoch: 8] loss: 0.005864, mae: 0.054247, r2: 0.719508, val_loss: 0.006316, val_mae: 0.056313, val_r2: 0.696443
2024-05-18 13:30:55 Epoch 9: lr=0.0001
2024-05-18 13:32:07 [Epoch: 9] loss: 0.005799, mae: 0.053926, r2: 0.722420, val_loss: 0.006304, val_mae: 0.055494, val_r2: 0.695529
2024-05-18 13:32:07 Epoch 10: lr=0.0001
2024-05-18 13:33:20 [Epoch: 10] loss: 0.005727, mae: 0.053622, r2: 0.725848, val_loss: 0.006272, val_mae: 0.055562, val_r2: 0.697497
2024-05-18 13:33:20 Epoch 11: lr=0.0001
2024-05-18 13:34:32 [Epoch: 11] loss: 0.005673, mae: 0.053361, r2: 0.728328, val_loss: 0.006260, val_mae: 0.055826, val_r2: 0.697997
2024-05-18 13:34:33 Epoch 12: lr=0.0001
2024-05-18 13:35:45 [Epoch: 12] loss: 0.005619, mae: 0.053140, r2: 0.730755, val_loss: 0.006271, val_mae: 0.056350, val_r2: 0.696482
2024-05-18 13:35:45 Epoch 13: lr=0.0001
2024-05-18 13:36:58 [Epoch: 13] loss: 0.005555, mae: 0.052832, r2: 0.733906, val_loss: 0.006218, val_mae: 0.055238, val_r2: 0.699139
2024-05-18 13:36:58 Epoch 14: lr=5e-05
2024-05-18 13:38:10 [Epoch: 14] loss: 0.005432, mae: 0.052262, r2: 0.739520, val_loss: 0.006174, val_mae: 0.055235, val_r2: 0.702080
2024-05-18 13:38:10 Epoch 15: lr=5e-05
2024-05-18 13:39:23 [Epoch: 15] loss: 0.005392, mae: 0.052092, r2: 0.741492, val_loss: 0.006157, val_mae: 0.054791, val_r2: 0.704137
2024-05-18 13:39:23 Epoch 16: lr=5e-05
2024-05-18 13:40:35 [Epoch: 16] loss: 0.005356, mae: 0.051916, r2: 0.742813, val_loss: 0.006148, val_mae: 0.054752, val_r2: 0.703502
2024-05-18 13:40:35 Epoch 17: lr=5e-05
2024-05-18 13:41:48 [Epoch: 17] loss: 0.005319, mae: 0.051758, r2: 0.744617, val_loss: 0.006162, val_mae: 0.054725, val_r2: 0.703367
2024-05-18 13:41:48 Epoch 18: lr=5e-05
2024-05-18 13:43:00 [Epoch: 18] loss: 0.005294, mae: 0.051602, r2: 0.745744, val_loss: 0.006117, val_mae: 0.054628, val_r2: 0.704692
2024-05-18 13:43:00 Epoch 19: lr=5e-05
2024-05-18 13:44:13 [Epoch: 19] loss: 0.005263, mae: 0.051495, r2: 0.747228, val_loss: 0.006126, val_mae: 0.054733, val_r2: 0.705221
2024-05-18 13:44:13 Epoch 20: lr=2.5e-05
2024-05-18 13:45:25 [Epoch: 20] loss: 0.005211, mae: 0.051243, r2: 0.749793, val_loss: 0.006124, val_mae: 0.054602, val_r2: 0.704787
2024-05-18 13:45:25 Epoch 21: lr=2.5e-05
2024-05-18 13:46:38 [Epoch: 21] loss: 0.005184, mae: 0.051111, r2: 0.751183, val_loss: 0.006114, val_mae: 0.054763, val_r2: 0.705190
2024-05-18 13:46:38 Epoch 22: lr=2.5e-05
2024-05-18 13:47:50 [Epoch: 22] loss: 0.005160, mae: 0.051007, r2: 0.752108, val_loss: 0.006125, val_mae: 0.054668, val_r2: 0.704924
2024-05-18 13:47:50 Epoch 23: lr=2.5e-05
2024-05-18 13:49:03 [Epoch: 23] loss: 0.005158, mae: 0.050970, r2: 0.752279, val_loss: 0.006134, val_mae: 0.054495, val_r2: 0.703657
2024-05-18 13:49:03 Epoch 24: lr=2.5e-05
2024-05-18 13:50:15 [Epoch: 24] loss: 0.005139, mae: 0.050895, r2: 0.753270, val_loss: 0.006148, val_mae: 0.054571, val_r2: 0.703776
2024-05-18 13:50:15 Epoch 25: lr=1.25e-05
2024-05-18 13:51:27 [Epoch: 25] loss: 0.005105, mae: 0.050746, r2: 0.754730, val_loss: 0.006100, val_mae: 0.054517, val_r2: 0.705613
2024-05-18 13:51:27 Epoch 26: lr=1.25e-05
2024-05-18 13:52:40 [Epoch: 26] loss: 0.005097, mae: 0.050690, r2: 0.755017, val_loss: 0.006124, val_mae: 0.054661, val_r2: 0.705170
2024-05-18 13:52:40 Epoch 27: lr=1.25e-05
2024-05-18 13:53:53 [Epoch: 27] loss: 0.005093, mae: 0.050670, r2: 0.755374, val_loss: 0.006125, val_mae: 0.054376, val_r2: 0.705536
2024-05-18 13:53:53 Epoch 28: lr=1.25e-05
2024-05-18 13:55:05 [Epoch: 28] loss: 0.005080, mae: 0.050644, r2: 0.755807, val_loss: 0.006128, val_mae: 0.054510, val_r2: 0.705055
2024-05-18 13:55:05 Epoch 29: lr=1.25e-05
2024-05-18 13:56:18 [Epoch: 29] loss: 0.005074, mae: 0.050592, r2: 0.756365, val_loss: 0.006114, val_mae: 0.054518, val_r2: 0.704872
2024-05-18 13:56:18 Epoch 30: lr=1e-05
2024-05-18 13:57:30 [Epoch: 30] loss: 0.005056, mae: 0.050522, r2: 0.757097, val_loss: 0.006127, val_mae: 0.054501, val_r2: 0.704347
2024-05-18 13:57:30 Epoch 31: lr=1e-05
2024-05-18 13:58:43 [Epoch: 31] loss: 0.005054, mae: 0.050519, r2: 0.756942, val_loss: 0.006122, val_mae: 0.054795, val_r2: 0.704377
2024-05-18 13:58:43 Epoch 32: lr=1e-05
2024-05-18 13:59:55 [Epoch: 32] loss: 0.005045, mae: 0.050459, r2: 0.757666, val_loss: 0.006100, val_mae: 0.054555, val_r2: 0.705958
2024-05-18 13:59:55 Epoch 33: lr=1e-05
2024-05-18 14:01:07 [Epoch: 33] loss: 0.005040, mae: 0.050464, r2: 0.757705, val_loss: 0.006103, val_mae: 0.054450, val_r2: 0.705711
2024-05-18 14:01:07 Epoch 34: lr=1e-05
2024-05-18 14:02:19 [Epoch: 34] loss: 0.005033, mae: 0.050420, r2: 0.757949, val_loss: 0.006112, val_mae: 0.054506, val_r2: 0.705314
2024-05-18 14:02:19 Epoch 35: lr=1e-05
2024-05-18 14:03:32 [Epoch: 35] loss: 0.005032, mae: 0.050423, r2: 0.758207, val_loss: 0.006112, val_mae: 0.054538, val_r2: 0.705788
2024-05-18 14:03:32 Epoch 36: lr=1e-05
2024-05-18 14:04:44 [Epoch: 36] loss: 0.005022, mae: 0.050366, r2: 0.758696, val_loss: 0.006104, val_mae: 0.054417, val_r2: 0.705952
2024-05-18 14:04:44 Epoch 37: lr=1e-05
2024-05-18 14:05:56 [Epoch: 37] loss: 0.005009, mae: 0.050278, r2: 0.759110, val_loss: 0.006097, val_mae: 0.054371, val_r2: 0.706010
2024-05-18 14:05:56 Epoch 38: lr=1e-05
2024-05-18 14:07:09 [Epoch: 38] loss: 0.005008, mae: 0.050294, r2: 0.759254, val_loss: 0.006114, val_mae: 0.054460, val_r2: 0.705771
2024-05-18 14:07:09 Epoch 39: lr=1e-05
2024-05-18 14:08:21 [Epoch: 39] loss: 0.005004, mae: 0.050278, r2: 0.759321, val_loss: 0.006126, val_mae: 0.054798, val_r2: 0.704716
2024-05-18 14:08:21 Epoch 40: lr=1e-05
2024-05-18 14:09:34 [Epoch: 40] loss: 0.005000, mae: 0.050294, r2: 0.759473, val_loss: 0.006089, val_mae: 0.054351, val_r2: 0.706554
2024-05-18 14:09:34 Epoch 41: lr=1e-05
2024-05-18 14:10:46 [Epoch: 41] loss: 0.004988, mae: 0.050221, r2: 0.760052, val_loss: 0.006115, val_mae: 0.054481, val_r2: 0.704668
2024-05-18 14:10:46 Epoch 42: lr=1e-05
2024-05-18 14:11:59 [Epoch: 42] loss: 0.004991, mae: 0.050208, r2: 0.759842, val_loss: 0.006117, val_mae: 0.054501, val_r2: 0.705494
2024-05-18 14:11:59 Epoch 43: lr=1e-05
2024-05-18 14:13:11 [Epoch: 43] loss: 0.004981, mae: 0.050140, r2: 0.760447, val_loss: 0.006097, val_mae: 0.054459, val_r2: 0.706074
2024-05-18 14:13:11 Epoch 44: lr=1e-05
2024-05-18 14:14:23 [Epoch: 44] loss: 0.004978, mae: 0.050189, r2: 0.760643, val_loss: 0.006121, val_mae: 0.054300, val_r2: 0.705056
2024-05-18 14:14:23 Epoch 45: lr=1e-05
2024-05-18 14:15:35 [Epoch: 45] loss: 0.004983, mae: 0.050157, r2: 0.760336, val_loss: 0.006121, val_mae: 0.054417, val_r2: 0.705157
2024-05-18 14:15:35 Epoch 46: lr=1e-05
2024-05-18 14:16:46 [Epoch: 46] loss: 0.004972, mae: 0.050122, r2: 0.760851, val_loss: 0.006117, val_mae: 0.054667, val_r2: 0.705310
2024-05-18 14:16:47 Epoch 47: lr=1e-05
2024-05-18 14:17:58 [Epoch: 47] loss: 0.004962, mae: 0.050082, r2: 0.761339, val_loss: 0.006106, val_mae: 0.054290, val_r2: 0.705784
2024-05-18 14:17:58 Epoch 48: lr=1e-05
2024-05-18 14:19:10 [Epoch: 48] loss: 0.004965, mae: 0.050057, r2: 0.761474, val_loss: 0.006093, val_mae: 0.054311, val_r2: 0.706335
2024-05-18 14:19:10 Epoch 49: lr=1e-05
2024-05-18 14:20:22 [Epoch: 49] loss: 0.004953, mae: 0.050029, r2: 0.761873, val_loss: 0.006125, val_mae: 0.054542, val_r2: 0.704951
2024-05-18 14:20:22 Epoch 50: lr=1e-05
2024-05-18 14:21:34 [Epoch: 50] loss: 0.004932, mae: 0.049932, r2: 0.762740, val_loss: 0.006087, val_mae: 0.054289, val_r2: 0.706753
2024-05-18 14:21:34 Epoch 51: lr=1e-05
2024-05-18 14:22:46 [Epoch: 51] loss: 0.004937, mae: 0.049942, r2: 0.762504, val_loss: 0.006133, val_mae: 0.054364, val_r2: 0.704394
2024-05-18 14:22:46 Epoch 52: lr=1e-05
2024-05-18 14:23:58 [Epoch: 52] loss: 0.004942, mae: 0.049960, r2: 0.762379, val_loss: 0.006109, val_mae: 0.054380, val_r2: 0.705363
2024-05-18 14:23:58 Epoch 53: lr=1e-05
2024-05-18 14:25:10 [Epoch: 53] loss: 0.004937, mae: 0.049943, r2: 0.762471, val_loss: 0.006092, val_mae: 0.054370, val_r2: 0.705903
2024-05-18 14:25:10 Epoch 54: lr=1e-05
2024-05-18 14:26:21 [Epoch: 54] loss: 0.004926, mae: 0.049912, r2: 0.763077, val_loss: 0.006107, val_mae: 0.054315, val_r2: 0.706041
2024-05-18 14:26:21 Epoch 55: lr=1e-05
2024-05-18 14:27:33 [Epoch: 55] loss: 0.004925, mae: 0.049885, r2: 0.763031, val_loss: 0.006093, val_mae: 0.054236, val_r2: 0.706293
2024-05-18 14:27:34 Epoch 56: lr=1e-05
2024-05-18 14:28:46 [Epoch: 56] loss: 0.004911, mae: 0.049818, r2: 0.763755, val_loss: 0.006110, val_mae: 0.054408, val_r2: 0.705199
2024-05-18 14:28:46 Epoch 57: lr=1e-05
2024-05-18 14:29:57 [Epoch: 57] loss: 0.004909, mae: 0.049797, r2: 0.763718, val_loss: 0.006114, val_mae: 0.054520, val_r2: 0.704814
2024-05-18 14:29:58 Epoch 58: lr=1e-05
2024-05-18 14:31:09 [Epoch: 58] loss: 0.004898, mae: 0.049772, r2: 0.764415, val_loss: 0.006116, val_mae: 0.054343, val_r2: 0.705060
2024-05-18 14:31:09 Epoch 59: lr=1e-05
2024-05-18 14:32:21 [Epoch: 59] loss: 0.004901, mae: 0.049797, r2: 0.764001, val_loss: 0.006106, val_mae: 0.054419, val_r2: 0.706377
2024-05-18 14:32:21 Epoch 60: lr=1e-05
2024-05-18 14:33:33 [Epoch: 60] loss: 0.004884, mae: 0.049721, r2: 0.765145, val_loss: 0.006128, val_mae: 0.054381, val_r2: 0.704039
2024-05-18 14:33:33 history_length: 61
2024-05-18 14:33:33 stopping: early
2024-05-18 14:33:33 Comparing y_true and y_pred:
2024-05-18 14:33:33   mse: 0.01601744
2024-05-18 14:33:33   mae: 0.10649409
2024-05-18 14:33:33   r2: -1.73967187
2024-05-18 14:33:33   corr: 0.13153522
