2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/91', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '91', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/91/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/91', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s0b0n0.91.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/91/3.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/91'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x1499c3965670>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/91/3.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04757861
2024-05-18 13:20:02   mae: 0.15976170
2024-05-18 13:20:02   r2: -0.99322028
2024-05-18 13:20:02   corr: 0.00338986
2024-05-18 13:20:02 Data points per epoch: train = 469639, val = 117410, test = 660
2024-05-18 13:20:02 Steps per epoch: train = 14676, val = 3669, test = 20
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:16 [Epoch: 0] loss: 0.023898, mae: 0.079327, r2: -0.184010, val_loss: 0.008820, val_mae: 0.067051, val_r2: 0.586885
2024-05-18 13:21:17 Epoch 1: lr=0.00082
2024-05-18 13:22:30 [Epoch: 1] loss: 0.007974, mae: 0.063880, r2: 0.622063, val_loss: 0.007722, val_mae: 0.063688, val_r2: 0.635526
2024-05-18 13:22:30 Epoch 2: lr=0.00064
2024-05-18 13:23:44 [Epoch: 2] loss: 0.007314, mae: 0.060842, r2: 0.652901, val_loss: 0.007248, val_mae: 0.059825, val_r2: 0.657269
2024-05-18 13:23:44 Epoch 3: lr=0.00046
2024-05-18 13:24:57 [Epoch: 3] loss: 0.006822, mae: 0.058652, r2: 0.675098, val_loss: 0.006922, val_mae: 0.058896, val_r2: 0.666209
2024-05-18 13:24:57 Epoch 4: lr=0.00028
2024-05-18 13:26:10 [Epoch: 4] loss: 0.006433, mae: 0.056806, r2: 0.692719, val_loss: 0.006598, val_mae: 0.057133, val_r2: 0.684454
2024-05-18 13:26:10 Epoch 5: lr=0.0001
2024-05-18 13:27:24 [Epoch: 5] loss: 0.006102, mae: 0.055284, r2: 0.708068, val_loss: 0.006473, val_mae: 0.056344, val_r2: 0.691656
2024-05-18 13:27:24 Epoch 6: lr=0.0001
2024-05-18 13:28:37 [Epoch: 6] loss: 0.005997, mae: 0.054803, r2: 0.713064, val_loss: 0.006399, val_mae: 0.056191, val_r2: 0.694451
2024-05-18 13:28:37 Epoch 7: lr=0.0001
2024-05-18 13:29:50 [Epoch: 7] loss: 0.005904, mae: 0.054403, r2: 0.717178, val_loss: 0.006393, val_mae: 0.056458, val_r2: 0.694553
2024-05-18 13:29:50 Epoch 8: lr=0.0001
2024-05-18 13:31:04 [Epoch: 8] loss: 0.005840, mae: 0.054087, r2: 0.720214, val_loss: 0.006342, val_mae: 0.056576, val_r2: 0.697263
2024-05-18 13:31:04 Epoch 9: lr=0.0001
2024-05-18 13:32:18 [Epoch: 9] loss: 0.005770, mae: 0.053805, r2: 0.723477, val_loss: 0.006308, val_mae: 0.055695, val_r2: 0.698201
2024-05-18 13:32:18 Epoch 10: lr=0.0001
2024-05-18 13:33:31 [Epoch: 10] loss: 0.005706, mae: 0.053513, r2: 0.726224, val_loss: 0.006272, val_mae: 0.055429, val_r2: 0.700588
2024-05-18 13:33:31 Epoch 11: lr=0.0001
2024-05-18 13:34:44 [Epoch: 11] loss: 0.005657, mae: 0.053247, r2: 0.728639, val_loss: 0.006274, val_mae: 0.056118, val_r2: 0.699771
2024-05-18 13:34:44 Epoch 12: lr=0.0001
2024-05-18 13:35:57 [Epoch: 12] loss: 0.005597, mae: 0.052971, r2: 0.731528, val_loss: 0.006260, val_mae: 0.056297, val_r2: 0.699724
2024-05-18 13:35:57 Epoch 13: lr=0.0001
2024-05-18 13:37:11 [Epoch: 13] loss: 0.005537, mae: 0.052732, r2: 0.734538, val_loss: 0.006214, val_mae: 0.055466, val_r2: 0.703843
2024-05-18 13:37:11 Epoch 14: lr=0.0001
2024-05-18 13:38:25 [Epoch: 14] loss: 0.005486, mae: 0.052514, r2: 0.736736, val_loss: 0.006214, val_mae: 0.055867, val_r2: 0.703503
2024-05-18 13:38:25 Epoch 15: lr=0.0001
2024-05-18 13:39:38 [Epoch: 15] loss: 0.005431, mae: 0.052193, r2: 0.739419, val_loss: 0.006213, val_mae: 0.054997, val_r2: 0.703593
2024-05-18 13:39:38 Epoch 16: lr=0.0001
2024-05-18 13:40:52 [Epoch: 16] loss: 0.005385, mae: 0.051984, r2: 0.741570, val_loss: 0.006180, val_mae: 0.055061, val_r2: 0.704539
2024-05-18 13:40:52 Epoch 17: lr=0.0001
2024-05-18 13:42:05 [Epoch: 17] loss: 0.005333, mae: 0.051750, r2: 0.743871, val_loss: 0.006195, val_mae: 0.054844, val_r2: 0.703691
2024-05-18 13:42:05 Epoch 18: lr=0.0001
2024-05-18 13:43:19 [Epoch: 18] loss: 0.005279, mae: 0.051526, r2: 0.746300, val_loss: 0.006148, val_mae: 0.054834, val_r2: 0.706616
2024-05-18 13:43:19 Epoch 19: lr=5e-05
2024-05-18 13:44:32 [Epoch: 19] loss: 0.005157, mae: 0.050963, r2: 0.752009, val_loss: 0.006108, val_mae: 0.054730, val_r2: 0.707545
2024-05-18 13:44:32 Epoch 20: lr=5e-05
2024-05-18 13:45:45 [Epoch: 20] loss: 0.005120, mae: 0.050770, r2: 0.753764, val_loss: 0.006091, val_mae: 0.054502, val_r2: 0.707898
2024-05-18 13:45:45 Epoch 21: lr=5e-05
2024-05-18 13:46:59 [Epoch: 21] loss: 0.005111, mae: 0.050722, r2: 0.754018, val_loss: 0.006107, val_mae: 0.054454, val_r2: 0.707279
2024-05-18 13:46:59 Epoch 22: lr=5e-05
2024-05-18 13:48:12 [Epoch: 22] loss: 0.005060, mae: 0.050504, r2: 0.756461, val_loss: 0.006128, val_mae: 0.054754, val_r2: 0.707327
2024-05-18 13:48:12 Epoch 23: lr=5e-05
2024-05-18 13:49:26 [Epoch: 23] loss: 0.005055, mae: 0.050413, r2: 0.756924, val_loss: 0.006123, val_mae: 0.054627, val_r2: 0.706831
2024-05-18 13:49:26 Epoch 24: lr=5e-05
2024-05-18 13:50:39 [Epoch: 24] loss: 0.005023, mae: 0.050313, r2: 0.758329, val_loss: 0.006117, val_mae: 0.054394, val_r2: 0.707627
2024-05-18 13:50:39 Epoch 25: lr=2.5e-05
2024-05-18 13:51:52 [Epoch: 25] loss: 0.004953, mae: 0.049983, r2: 0.761406, val_loss: 0.006123, val_mae: 0.054548, val_r2: 0.706187
2024-05-18 13:51:52 Epoch 26: lr=2.5e-05
2024-05-18 13:53:06 [Epoch: 26] loss: 0.004934, mae: 0.049941, r2: 0.762230, val_loss: 0.006096, val_mae: 0.054676, val_r2: 0.707792
2024-05-18 13:53:06 Epoch 27: lr=2.5e-05
2024-05-18 13:54:20 [Epoch: 27] loss: 0.004922, mae: 0.049847, r2: 0.762736, val_loss: 0.006108, val_mae: 0.054308, val_r2: 0.707819
2024-05-18 13:54:20 Epoch 28: lr=2.5e-05
2024-05-18 13:55:33 [Epoch: 28] loss: 0.004917, mae: 0.049785, r2: 0.762975, val_loss: 0.006095, val_mae: 0.054662, val_r2: 0.708283
2024-05-18 13:55:33 Epoch 29: lr=2.5e-05
2024-05-18 13:56:46 [Epoch: 29] loss: 0.004894, mae: 0.049716, r2: 0.764145, val_loss: 0.006109, val_mae: 0.054360, val_r2: 0.707212
2024-05-18 13:56:47 Epoch 30: lr=1.25e-05
2024-05-18 13:58:00 [Epoch: 30] loss: 0.004860, mae: 0.049521, r2: 0.765625, val_loss: 0.006083, val_mae: 0.054397, val_r2: 0.708667
2024-05-18 13:58:00 Epoch 31: lr=1.25e-05
2024-05-18 13:59:14 [Epoch: 31] loss: 0.004847, mae: 0.049473, r2: 0.766283, val_loss: 0.006095, val_mae: 0.054461, val_r2: 0.708084
2024-05-18 13:59:14 Epoch 32: lr=1.25e-05
2024-05-18 14:00:27 [Epoch: 32] loss: 0.004840, mae: 0.049413, r2: 0.767002, val_loss: 0.006090, val_mae: 0.054464, val_r2: 0.708103
2024-05-18 14:00:27 Epoch 33: lr=1.25e-05
2024-05-18 14:01:40 [Epoch: 33] loss: 0.004844, mae: 0.049451, r2: 0.766507, val_loss: 0.006098, val_mae: 0.054345, val_r2: 0.707618
2024-05-18 14:01:40 Epoch 34: lr=1.25e-05
2024-05-18 14:02:54 [Epoch: 34] loss: 0.004826, mae: 0.049363, r2: 0.767301, val_loss: 0.006118, val_mae: 0.054372, val_r2: 0.706653
2024-05-18 14:02:54 Epoch 35: lr=1e-05
2024-05-18 14:04:08 [Epoch: 35] loss: 0.004821, mae: 0.049345, r2: 0.767714, val_loss: 0.006123, val_mae: 0.054471, val_r2: 0.706563
2024-05-18 14:04:08 Epoch 36: lr=1e-05
2024-05-18 14:05:21 [Epoch: 36] loss: 0.004818, mae: 0.049309, r2: 0.767798, val_loss: 0.006104, val_mae: 0.054385, val_r2: 0.707518
2024-05-18 14:05:21 Epoch 37: lr=1e-05
2024-05-18 14:06:35 [Epoch: 37] loss: 0.004790, mae: 0.049203, r2: 0.768969, val_loss: 0.006112, val_mae: 0.054332, val_r2: 0.706567
2024-05-18 14:06:35 Epoch 38: lr=1e-05
2024-05-18 14:07:48 [Epoch: 38] loss: 0.004810, mae: 0.049327, r2: 0.768025, val_loss: 0.006123, val_mae: 0.054570, val_r2: 0.706915
2024-05-18 14:07:49 Epoch 39: lr=1e-05
2024-05-18 14:09:02 [Epoch: 39] loss: 0.004803, mae: 0.049279, r2: 0.768367, val_loss: 0.006107, val_mae: 0.054400, val_r2: 0.707179
2024-05-18 14:09:02 Epoch 40: lr=1e-05
2024-05-18 14:10:16 [Epoch: 40] loss: 0.004798, mae: 0.049235, r2: 0.768746, val_loss: 0.006075, val_mae: 0.054380, val_r2: 0.709383
2024-05-18 14:10:16 Epoch 41: lr=1e-05
2024-05-18 14:11:28 [Epoch: 41] loss: 0.004790, mae: 0.049188, r2: 0.768944, val_loss: 0.006118, val_mae: 0.054243, val_r2: 0.707084
2024-05-18 14:11:28 Epoch 42: lr=1e-05
2024-05-18 14:12:42 [Epoch: 42] loss: 0.004783, mae: 0.049143, r2: 0.769385, val_loss: 0.006081, val_mae: 0.054499, val_r2: 0.708821
2024-05-18 14:12:42 Epoch 43: lr=1e-05
2024-05-18 14:13:55 [Epoch: 43] loss: 0.004787, mae: 0.049150, r2: 0.769101, val_loss: 0.006102, val_mae: 0.054291, val_r2: 0.707725
2024-05-18 14:13:56 Epoch 44: lr=1e-05
2024-05-18 14:15:09 [Epoch: 44] loss: 0.004768, mae: 0.049076, r2: 0.770250, val_loss: 0.006107, val_mae: 0.054274, val_r2: 0.707948
2024-05-18 14:15:09 Epoch 45: lr=1e-05
2024-05-18 14:16:22 [Epoch: 45] loss: 0.004763, mae: 0.049020, r2: 0.770563, val_loss: 0.006100, val_mae: 0.054384, val_r2: 0.707333
2024-05-18 14:16:22 Epoch 46: lr=1e-05
2024-05-18 14:17:35 [Epoch: 46] loss: 0.004755, mae: 0.049019, r2: 0.770620, val_loss: 0.006103, val_mae: 0.054401, val_r2: 0.706948
2024-05-18 14:17:35 Epoch 47: lr=1e-05
2024-05-18 14:18:48 [Epoch: 47] loss: 0.004758, mae: 0.049032, r2: 0.770459, val_loss: 0.006124, val_mae: 0.054298, val_r2: 0.706448
2024-05-18 14:18:49 Epoch 48: lr=1e-05
2024-05-18 14:20:02 [Epoch: 48] loss: 0.004751, mae: 0.048995, r2: 0.770698, val_loss: 0.006094, val_mae: 0.054360, val_r2: 0.708132
2024-05-18 14:20:02 Epoch 49: lr=1e-05
2024-05-18 14:21:15 [Epoch: 49] loss: 0.004752, mae: 0.048992, r2: 0.770664, val_loss: 0.006115, val_mae: 0.054397, val_r2: 0.707224
2024-05-18 14:21:15 Epoch 50: lr=1e-05
2024-05-18 14:22:28 [Epoch: 50] loss: 0.004740, mae: 0.048942, r2: 0.771214, val_loss: 0.006092, val_mae: 0.054376, val_r2: 0.708302
2024-05-18 14:22:28 history_length: 51
2024-05-18 14:22:28 stopping: early
2024-05-18 14:22:28 Comparing y_true and y_pred:
2024-05-18 14:22:28   mse: 0.00195283
2024-05-18 14:22:28   mae: 0.03594373
2024-05-18 14:22:28   r2: -0.69953013
2024-05-18 14:22:28   corr: 0.21826226
