2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/87', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '87', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/87/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/87', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c5s0b0n0.87.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/87/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/87'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x14e2899177f0>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/87/1.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04770172
2024-05-18 13:20:02   mae: 0.15994750
2024-05-18 13:20:02   r2: -1.00051077
2024-05-18 13:20:02   corr: -0.00025539
2024-05-18 13:20:02 Data points per epoch: train = 469035, val = 117259, test = 1415
2024-05-18 13:20:02 Steps per epoch: train = 14657, val = 3664, test = 44
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:14 [Epoch: 0] loss: 0.028605, mae: 0.079911, r2: -0.745474, val_loss: 0.008648, val_mae: 0.067378, val_r2: 0.592709
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:27 [Epoch: 1] loss: 0.007970, mae: 0.063908, r2: 0.622902, val_loss: 0.008053, val_mae: 0.062893, val_r2: 0.626340
2024-05-18 13:22:27 Epoch 2: lr=0.00064
2024-05-18 13:23:39 [Epoch: 2] loss: 0.007294, mae: 0.060765, r2: 0.653899, val_loss: 0.007269, val_mae: 0.060334, val_r2: 0.654954
2024-05-18 13:23:39 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006841, mae: 0.058732, r2: 0.674825, val_loss: 0.006867, val_mae: 0.058418, val_r2: 0.675475
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:02 [Epoch: 4] loss: 0.006443, mae: 0.056892, r2: 0.693135, val_loss: 0.006624, val_mae: 0.057477, val_r2: 0.684267
2024-05-18 13:26:03 Epoch 5: lr=0.0001
2024-05-18 13:27:15 [Epoch: 5] loss: 0.006120, mae: 0.055391, r2: 0.707917, val_loss: 0.006473, val_mae: 0.056423, val_r2: 0.692072
2024-05-18 13:27:15 Epoch 6: lr=0.0001
2024-05-18 13:28:27 [Epoch: 6] loss: 0.006012, mae: 0.054893, r2: 0.712697, val_loss: 0.006401, val_mae: 0.056314, val_r2: 0.694364
2024-05-18 13:28:27 Epoch 7: lr=0.0001
2024-05-18 13:29:38 [Epoch: 7] loss: 0.005927, mae: 0.054501, r2: 0.716851, val_loss: 0.006385, val_mae: 0.056360, val_r2: 0.695624
2024-05-18 13:29:38 Epoch 8: lr=0.0001
2024-05-18 13:30:50 [Epoch: 8] loss: 0.005856, mae: 0.054212, r2: 0.720277, val_loss: 0.006357, val_mae: 0.055901, val_r2: 0.698059
2024-05-18 13:30:50 Epoch 9: lr=0.0001
2024-05-18 13:32:02 [Epoch: 9] loss: 0.005791, mae: 0.053889, r2: 0.723301, val_loss: 0.006300, val_mae: 0.055575, val_r2: 0.700265
2024-05-18 13:32:03 Epoch 10: lr=0.0001
2024-05-18 13:33:14 [Epoch: 10] loss: 0.005716, mae: 0.053594, r2: 0.726740, val_loss: 0.006295, val_mae: 0.055828, val_r2: 0.699555
2024-05-18 13:33:14 Epoch 11: lr=0.0001
2024-05-18 13:34:26 [Epoch: 11] loss: 0.005669, mae: 0.053335, r2: 0.728813, val_loss: 0.006258, val_mae: 0.055009, val_r2: 0.700790
2024-05-18 13:34:26 Epoch 12: lr=0.0001
2024-05-18 13:35:38 [Epoch: 12] loss: 0.005616, mae: 0.053096, r2: 0.731249, val_loss: 0.006227, val_mae: 0.054880, val_r2: 0.703216
2024-05-18 13:35:38 Epoch 13: lr=0.0001
2024-05-18 13:36:50 [Epoch: 13] loss: 0.005568, mae: 0.052877, r2: 0.733472, val_loss: 0.006219, val_mae: 0.055516, val_r2: 0.702915
2024-05-18 13:36:50 Epoch 14: lr=0.0001
2024-05-18 13:38:02 [Epoch: 14] loss: 0.005499, mae: 0.052571, r2: 0.736832, val_loss: 0.006235, val_mae: 0.054939, val_r2: 0.702077
2024-05-18 13:38:02 Epoch 15: lr=0.0001
2024-05-18 13:39:15 [Epoch: 15] loss: 0.005451, mae: 0.052346, r2: 0.738986, val_loss: 0.006206, val_mae: 0.055141, val_r2: 0.703788
2024-05-18 13:39:15 Epoch 16: lr=0.0001
2024-05-18 13:40:26 [Epoch: 16] loss: 0.005402, mae: 0.052096, r2: 0.741283, val_loss: 0.006172, val_mae: 0.054722, val_r2: 0.706142
2024-05-18 13:40:26 Epoch 17: lr=0.0001
2024-05-18 13:41:38 [Epoch: 17] loss: 0.005353, mae: 0.051896, r2: 0.743666, val_loss: 0.006193, val_mae: 0.054535, val_r2: 0.704315
2024-05-18 13:41:38 Epoch 18: lr=5e-05
2024-05-18 13:42:50 [Epoch: 18] loss: 0.005228, mae: 0.051300, r2: 0.749570, val_loss: 0.006171, val_mae: 0.054617, val_r2: 0.705664
2024-05-18 13:42:50 Epoch 19: lr=5e-05
2024-05-18 13:44:02 [Epoch: 19] loss: 0.005197, mae: 0.051169, r2: 0.750829, val_loss: 0.006114, val_mae: 0.054498, val_r2: 0.708256
2024-05-18 13:44:02 Epoch 20: lr=5e-05
2024-05-18 13:45:14 [Epoch: 20] loss: 0.005159, mae: 0.051004, r2: 0.752524, val_loss: 0.006134, val_mae: 0.054868, val_r2: 0.707788
2024-05-18 13:45:14 Epoch 21: lr=5e-05
2024-05-18 13:46:26 [Epoch: 21] loss: 0.005133, mae: 0.050892, r2: 0.753899, val_loss: 0.006156, val_mae: 0.054381, val_r2: 0.705496
2024-05-18 13:46:26 Epoch 22: lr=5e-05
2024-05-18 13:47:37 [Epoch: 22] loss: 0.005104, mae: 0.050716, r2: 0.755064, val_loss: 0.006151, val_mae: 0.054714, val_r2: 0.706318
2024-05-18 13:47:38 Epoch 23: lr=5e-05
2024-05-18 13:48:50 [Epoch: 23] loss: 0.005087, mae: 0.050629, r2: 0.756082, val_loss: 0.006130, val_mae: 0.054458, val_r2: 0.707821
2024-05-18 13:48:50 Epoch 24: lr=5e-05
2024-05-18 13:50:01 [Epoch: 24] loss: 0.005062, mae: 0.050544, r2: 0.757144, val_loss: 0.006099, val_mae: 0.054401, val_r2: 0.709205
2024-05-18 13:50:02 Epoch 25: lr=2.5e-05
2024-05-18 13:51:14 [Epoch: 25] loss: 0.005005, mae: 0.050235, r2: 0.759675, val_loss: 0.006116, val_mae: 0.054344, val_r2: 0.707411
2024-05-18 13:51:14 Epoch 26: lr=2.5e-05
2024-05-18 13:52:26 [Epoch: 26] loss: 0.004980, mae: 0.050112, r2: 0.760971, val_loss: 0.006127, val_mae: 0.054204, val_r2: 0.708102
2024-05-18 13:52:26 Epoch 27: lr=2.5e-05
2024-05-18 13:53:38 [Epoch: 27] loss: 0.004951, mae: 0.049996, r2: 0.762332, val_loss: 0.006113, val_mae: 0.054528, val_r2: 0.707457
2024-05-18 13:53:38 Epoch 28: lr=2.5e-05
2024-05-18 13:54:50 [Epoch: 28] loss: 0.004949, mae: 0.049976, r2: 0.762271, val_loss: 0.006139, val_mae: 0.054149, val_r2: 0.707333
2024-05-18 13:54:50 Epoch 29: lr=2.5e-05
2024-05-18 13:56:01 [Epoch: 29] loss: 0.004930, mae: 0.049899, r2: 0.763279, val_loss: 0.006115, val_mae: 0.054278, val_r2: 0.708874
2024-05-18 13:56:01 Epoch 30: lr=1.25e-05
2024-05-18 13:57:13 [Epoch: 30] loss: 0.004900, mae: 0.049761, r2: 0.764707, val_loss: 0.006099, val_mae: 0.054263, val_r2: 0.709445
2024-05-18 13:57:14 Epoch 31: lr=1.25e-05
2024-05-18 13:58:26 [Epoch: 31] loss: 0.004894, mae: 0.049689, r2: 0.765080, val_loss: 0.006135, val_mae: 0.054197, val_r2: 0.706952
2024-05-18 13:58:26 Epoch 32: lr=1.25e-05
2024-05-18 13:59:38 [Epoch: 32] loss: 0.004886, mae: 0.049677, r2: 0.765251, val_loss: 0.006109, val_mae: 0.054249, val_r2: 0.707818
2024-05-18 13:59:38 Epoch 33: lr=1.25e-05
2024-05-18 14:00:49 [Epoch: 33] loss: 0.004880, mae: 0.049612, r2: 0.765762, val_loss: 0.006104, val_mae: 0.054416, val_r2: 0.708380
2024-05-18 14:00:49 Epoch 34: lr=1.25e-05
2024-05-18 14:02:01 [Epoch: 34] loss: 0.004880, mae: 0.049602, r2: 0.765431, val_loss: 0.006119, val_mae: 0.054286, val_r2: 0.707904
2024-05-18 14:02:01 Epoch 35: lr=1e-05
2024-05-18 14:03:13 [Epoch: 35] loss: 0.004860, mae: 0.049531, r2: 0.766427, val_loss: 0.006126, val_mae: 0.054163, val_r2: 0.706699
2024-05-18 14:03:13 Epoch 36: lr=1e-05
2024-05-18 14:04:25 [Epoch: 36] loss: 0.004863, mae: 0.049571, r2: 0.766439, val_loss: 0.006100, val_mae: 0.054240, val_r2: 0.708715
2024-05-18 14:04:25 Epoch 37: lr=1e-05
2024-05-18 14:05:37 [Epoch: 37] loss: 0.004850, mae: 0.049490, r2: 0.767035, val_loss: 0.006132, val_mae: 0.054200, val_r2: 0.707630
2024-05-18 14:05:37 Epoch 38: lr=1e-05
2024-05-18 14:06:49 [Epoch: 38] loss: 0.004841, mae: 0.049448, r2: 0.767242, val_loss: 0.006130, val_mae: 0.054509, val_r2: 0.707175
2024-05-18 14:06:49 Epoch 39: lr=1e-05
2024-05-18 14:08:01 [Epoch: 39] loss: 0.004828, mae: 0.049417, r2: 0.767862, val_loss: 0.006107, val_mae: 0.054235, val_r2: 0.708594
2024-05-18 14:08:01 Epoch 40: lr=1e-05
2024-05-18 14:09:13 [Epoch: 40] loss: 0.004830, mae: 0.049385, r2: 0.767979, val_loss: 0.006086, val_mae: 0.054226, val_r2: 0.709994
2024-05-18 14:09:13 Epoch 41: lr=1e-05
2024-05-18 14:10:25 [Epoch: 41] loss: 0.004827, mae: 0.049392, r2: 0.768168, val_loss: 0.006112, val_mae: 0.054365, val_r2: 0.708171
2024-05-18 14:10:25 Epoch 42: lr=1e-05
2024-05-18 14:11:37 [Epoch: 42] loss: 0.004833, mae: 0.049402, r2: 0.767792, val_loss: 0.006101, val_mae: 0.054211, val_r2: 0.708697
2024-05-18 14:11:37 Epoch 43: lr=1e-05
2024-05-18 14:12:49 [Epoch: 43] loss: 0.004826, mae: 0.049390, r2: 0.767859, val_loss: 0.006132, val_mae: 0.054252, val_r2: 0.706707
2024-05-18 14:12:49 Epoch 44: lr=1e-05
2024-05-18 14:14:01 [Epoch: 44] loss: 0.004806, mae: 0.049298, r2: 0.769032, val_loss: 0.006126, val_mae: 0.054346, val_r2: 0.707722
2024-05-18 14:14:01 Epoch 45: lr=1e-05
2024-05-18 14:15:13 [Epoch: 45] loss: 0.004816, mae: 0.049342, r2: 0.768548, val_loss: 0.006114, val_mae: 0.054418, val_r2: 0.707703
2024-05-18 14:15:13 Epoch 46: lr=1e-05
2024-05-18 14:16:24 [Epoch: 46] loss: 0.004807, mae: 0.049279, r2: 0.768708, val_loss: 0.006090, val_mae: 0.054173, val_r2: 0.708801
2024-05-18 14:16:24 Epoch 47: lr=1e-05
2024-05-18 14:17:36 [Epoch: 47] loss: 0.004799, mae: 0.049259, r2: 0.769044, val_loss: 0.006094, val_mae: 0.054232, val_r2: 0.708836
2024-05-18 14:17:36 Epoch 48: lr=1e-05
2024-05-18 14:18:48 [Epoch: 48] loss: 0.004783, mae: 0.049174, r2: 0.769919, val_loss: 0.006123, val_mae: 0.054255, val_r2: 0.707901
2024-05-18 14:18:48 Epoch 49: lr=1e-05
2024-05-18 14:19:59 [Epoch: 49] loss: 0.004792, mae: 0.049229, r2: 0.769681, val_loss: 0.006131, val_mae: 0.054201, val_r2: 0.706470
2024-05-18 14:19:59 Epoch 50: lr=1e-05
2024-05-18 14:21:11 [Epoch: 50] loss: 0.004785, mae: 0.049190, r2: 0.770184, val_loss: 0.006096, val_mae: 0.054331, val_r2: 0.709158
2024-05-18 14:21:11 history_length: 51
2024-05-18 14:21:11 stopping: early
2024-05-18 14:21:11 Comparing y_true and y_pred:
2024-05-18 14:21:11   mse: 0.00466469
2024-05-18 14:21:11   mae: 0.04605339
2024-05-18 14:21:11   r2: 0.03440452
2024-05-18 14:21:11   corr: 0.40301767
