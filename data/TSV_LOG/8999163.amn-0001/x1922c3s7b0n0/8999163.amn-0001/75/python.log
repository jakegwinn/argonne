2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/75', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '75', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/75/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/75', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s7b0n0.75.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/75/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/75'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x14cf203fbf70>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/75/1.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04778494
2024-05-18 13:20:02   mae: 0.16013068
2024-05-18 13:20:02   r2: -1.00159606
2024-05-18 13:20:02   corr: -0.00079803
2024-05-18 13:20:02 Data points per epoch: train = 469568, val = 117392, test = 749
2024-05-18 13:20:02 Steps per epoch: train = 14674, val = 3668, test = 23
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:16 [Epoch: 0] loss: 0.032772, mae: 0.079381, r2: -1.310515, val_loss: 0.008618, val_mae: 0.067324, val_r2: 0.597251
2024-05-18 13:21:16 Epoch 1: lr=0.00082
2024-05-18 13:22:30 [Epoch: 1] loss: 0.007979, mae: 0.063902, r2: 0.621215, val_loss: 0.008039, val_mae: 0.063312, val_r2: 0.626710
2024-05-18 13:22:30 Epoch 2: lr=0.00064
2024-05-18 13:23:43 [Epoch: 2] loss: 0.007308, mae: 0.060743, r2: 0.652415, val_loss: 0.007243, val_mae: 0.059910, val_r2: 0.656968
2024-05-18 13:23:43 Epoch 3: lr=0.00046
2024-05-18 13:24:56 [Epoch: 3] loss: 0.006857, mae: 0.058734, r2: 0.672844, val_loss: 0.006924, val_mae: 0.058420, val_r2: 0.666234
2024-05-18 13:24:56 Epoch 4: lr=0.00028
2024-05-18 13:26:09 [Epoch: 4] loss: 0.006449, mae: 0.056862, r2: 0.691928, val_loss: 0.006663, val_mae: 0.057156, val_r2: 0.680398
2024-05-18 13:26:09 Epoch 5: lr=0.0001
2024-05-18 13:27:23 [Epoch: 5] loss: 0.006127, mae: 0.055368, r2: 0.706757, val_loss: 0.006487, val_mae: 0.056736, val_r2: 0.687905
2024-05-18 13:27:23 Epoch 6: lr=0.0001
2024-05-18 13:28:35 [Epoch: 6] loss: 0.006016, mae: 0.054891, r2: 0.711791, val_loss: 0.006441, val_mae: 0.055959, val_r2: 0.691331
2024-05-18 13:28:35 Epoch 7: lr=0.0001
2024-05-18 13:29:48 [Epoch: 7] loss: 0.005937, mae: 0.054524, r2: 0.715500, val_loss: 0.006364, val_mae: 0.056157, val_r2: 0.694996
2024-05-18 13:29:48 Epoch 8: lr=0.0001
2024-05-18 13:31:01 [Epoch: 8] loss: 0.005877, mae: 0.054258, r2: 0.718197, val_loss: 0.006345, val_mae: 0.056130, val_r2: 0.694853
2024-05-18 13:31:01 Epoch 9: lr=0.0001
2024-05-18 13:32:14 [Epoch: 9] loss: 0.005813, mae: 0.053988, r2: 0.721165, val_loss: 0.006325, val_mae: 0.055825, val_r2: 0.695697
2024-05-18 13:32:14 Epoch 10: lr=0.0001
2024-05-18 13:33:27 [Epoch: 10] loss: 0.005756, mae: 0.053701, r2: 0.724091, val_loss: 0.006323, val_mae: 0.056474, val_r2: 0.695106
2024-05-18 13:33:27 Epoch 11: lr=0.0001
2024-05-18 13:34:40 [Epoch: 11] loss: 0.005682, mae: 0.053357, r2: 0.727293, val_loss: 0.006302, val_mae: 0.055598, val_r2: 0.696292
2024-05-18 13:34:40 Epoch 12: lr=0.0001
2024-05-18 13:35:54 [Epoch: 12] loss: 0.005640, mae: 0.053152, r2: 0.729236, val_loss: 0.006342, val_mae: 0.055201, val_r2: 0.693440
2024-05-18 13:35:54 Epoch 13: lr=5e-05
2024-05-18 13:37:07 [Epoch: 13] loss: 0.005515, mae: 0.052571, r2: 0.735312, val_loss: 0.006211, val_mae: 0.055031, val_r2: 0.701234
2024-05-18 13:37:07 Epoch 14: lr=5e-05
2024-05-18 13:38:20 [Epoch: 14] loss: 0.005475, mae: 0.052413, r2: 0.736943, val_loss: 0.006234, val_mae: 0.055320, val_r2: 0.698693
2024-05-18 13:38:20 Epoch 15: lr=5e-05
2024-05-18 13:39:33 [Epoch: 15] loss: 0.005445, mae: 0.052232, r2: 0.738214, val_loss: 0.006181, val_mae: 0.054895, val_r2: 0.702725
2024-05-18 13:39:33 Epoch 16: lr=5e-05
2024-05-18 13:40:46 [Epoch: 16] loss: 0.005415, mae: 0.052116, r2: 0.739892, val_loss: 0.006206, val_mae: 0.055263, val_r2: 0.700268
2024-05-18 13:40:46 Epoch 17: lr=5e-05
2024-05-18 13:41:59 [Epoch: 17] loss: 0.005383, mae: 0.051958, r2: 0.741372, val_loss: 0.006193, val_mae: 0.055212, val_r2: 0.700565
2024-05-18 13:41:59 Epoch 18: lr=5e-05
2024-05-18 13:43:12 [Epoch: 18] loss: 0.005353, mae: 0.051819, r2: 0.742917, val_loss: 0.006199, val_mae: 0.055358, val_r2: 0.700667
2024-05-18 13:43:12 Epoch 19: lr=2.5e-05
2024-05-18 13:44:25 [Epoch: 19] loss: 0.005290, mae: 0.051551, r2: 0.745688, val_loss: 0.006161, val_mae: 0.054986, val_r2: 0.703075
2024-05-18 13:44:25 Epoch 20: lr=2.5e-05
2024-05-18 13:45:38 [Epoch: 20] loss: 0.005270, mae: 0.051441, r2: 0.746731, val_loss: 0.006193, val_mae: 0.054745, val_r2: 0.702570
2024-05-18 13:45:38 Epoch 21: lr=2.5e-05
2024-05-18 13:46:51 [Epoch: 21] loss: 0.005256, mae: 0.051370, r2: 0.747421, val_loss: 0.006162, val_mae: 0.054764, val_r2: 0.703592
2024-05-18 13:46:51 Epoch 22: lr=2.5e-05
2024-05-18 13:48:04 [Epoch: 22] loss: 0.005238, mae: 0.051287, r2: 0.748134, val_loss: 0.006155, val_mae: 0.055147, val_r2: 0.702515
2024-05-18 13:48:04 Epoch 23: lr=2.5e-05
2024-05-18 13:49:18 [Epoch: 23] loss: 0.005230, mae: 0.051291, r2: 0.748464, val_loss: 0.006170, val_mae: 0.054742, val_r2: 0.702762
2024-05-18 13:49:18 Epoch 24: lr=1.25e-05
2024-05-18 13:50:30 [Epoch: 24] loss: 0.005189, mae: 0.051082, r2: 0.750275, val_loss: 0.006174, val_mae: 0.054704, val_r2: 0.702385
2024-05-18 13:50:30 Epoch 25: lr=1.25e-05
2024-05-18 13:51:44 [Epoch: 25] loss: 0.005183, mae: 0.051013, r2: 0.750575, val_loss: 0.006159, val_mae: 0.054865, val_r2: 0.702421
2024-05-18 13:51:44 Epoch 26: lr=1.25e-05
2024-05-18 13:52:57 [Epoch: 26] loss: 0.005178, mae: 0.051001, r2: 0.750796, val_loss: 0.006149, val_mae: 0.054788, val_r2: 0.703196
2024-05-18 13:52:57 Epoch 27: lr=1.25e-05
2024-05-18 13:54:10 [Epoch: 27] loss: 0.005172, mae: 0.050985, r2: 0.751351, val_loss: 0.006175, val_mae: 0.054707, val_r2: 0.702137
2024-05-18 13:54:11 Epoch 28: lr=1.25e-05
2024-05-18 13:55:23 [Epoch: 28] loss: 0.005159, mae: 0.050905, r2: 0.751740, val_loss: 0.006164, val_mae: 0.054782, val_r2: 0.702569
2024-05-18 13:55:23 Epoch 29: lr=1e-05
2024-05-18 13:56:37 [Epoch: 29] loss: 0.005131, mae: 0.050779, r2: 0.753194, val_loss: 0.006168, val_mae: 0.054644, val_r2: 0.702412
2024-05-18 13:56:37 Epoch 30: lr=1e-05
2024-05-18 13:57:50 [Epoch: 30] loss: 0.005134, mae: 0.050799, r2: 0.752806, val_loss: 0.006160, val_mae: 0.054712, val_r2: 0.703115
2024-05-18 13:57:50 Epoch 31: lr=1e-05
2024-05-18 13:59:03 [Epoch: 31] loss: 0.005132, mae: 0.050810, r2: 0.752935, val_loss: 0.006172, val_mae: 0.054753, val_r2: 0.702625
2024-05-18 13:59:03 Epoch 32: lr=1e-05
2024-05-18 14:00:16 [Epoch: 32] loss: 0.005124, mae: 0.050769, r2: 0.753523, val_loss: 0.006155, val_mae: 0.054583, val_r2: 0.703107
2024-05-18 14:00:16 Epoch 33: lr=1e-05
2024-05-18 14:01:29 [Epoch: 33] loss: 0.005120, mae: 0.050737, r2: 0.753783, val_loss: 0.006168, val_mae: 0.054720, val_r2: 0.702486
2024-05-18 14:01:30 Epoch 34: lr=1e-05
2024-05-18 14:02:42 [Epoch: 34] loss: 0.005113, mae: 0.050701, r2: 0.754048, val_loss: 0.006144, val_mae: 0.054750, val_r2: 0.703369
2024-05-18 14:02:42 Epoch 35: lr=1e-05
2024-05-18 14:03:55 [Epoch: 35] loss: 0.005110, mae: 0.050674, r2: 0.754077, val_loss: 0.006179, val_mae: 0.054714, val_r2: 0.702380
2024-05-18 14:03:55 Epoch 36: lr=1e-05
2024-05-18 14:05:08 [Epoch: 36] loss: 0.005090, mae: 0.050594, r2: 0.755053, val_loss: 0.006145, val_mae: 0.054532, val_r2: 0.703130
2024-05-18 14:05:08 Epoch 37: lr=1e-05
2024-05-18 14:06:21 [Epoch: 37] loss: 0.005087, mae: 0.050622, r2: 0.755059, val_loss: 0.006153, val_mae: 0.054579, val_r2: 0.703289
2024-05-18 14:06:21 Epoch 38: lr=1e-05
2024-05-18 14:07:34 [Epoch: 38] loss: 0.005086, mae: 0.050574, r2: 0.755452, val_loss: 0.006146, val_mae: 0.054660, val_r2: 0.703363
2024-05-18 14:07:34 Epoch 39: lr=1e-05
2024-05-18 14:08:47 [Epoch: 39] loss: 0.005082, mae: 0.050622, r2: 0.755254, val_loss: 0.006143, val_mae: 0.054774, val_r2: 0.703343
2024-05-18 14:08:47 Epoch 40: lr=1e-05
2024-05-18 14:10:00 [Epoch: 40] loss: 0.005077, mae: 0.050557, r2: 0.755802, val_loss: 0.006129, val_mae: 0.054730, val_r2: 0.704284
2024-05-18 14:10:00 Epoch 41: lr=1e-05
2024-05-18 14:11:13 [Epoch: 41] loss: 0.005072, mae: 0.050507, r2: 0.755783, val_loss: 0.006144, val_mae: 0.054599, val_r2: 0.704161
2024-05-18 14:11:13 Epoch 42: lr=1e-05
2024-05-18 14:12:26 [Epoch: 42] loss: 0.005067, mae: 0.050487, r2: 0.756037, val_loss: 0.006162, val_mae: 0.054571, val_r2: 0.703140
2024-05-18 14:12:26 Epoch 43: lr=1e-05
2024-05-18 14:13:38 [Epoch: 43] loss: 0.005055, mae: 0.050444, r2: 0.756662, val_loss: 0.006147, val_mae: 0.054568, val_r2: 0.703665
2024-05-18 14:13:39 Epoch 44: lr=1e-05
2024-05-18 14:14:51 [Epoch: 44] loss: 0.005048, mae: 0.050399, r2: 0.757281, val_loss: 0.006145, val_mae: 0.054664, val_r2: 0.703781
2024-05-18 14:14:51 Epoch 45: lr=1e-05
2024-05-18 14:16:04 [Epoch: 45] loss: 0.005047, mae: 0.050402, r2: 0.757125, val_loss: 0.006121, val_mae: 0.054563, val_r2: 0.704630
2024-05-18 14:16:04 Epoch 46: lr=1e-05
2024-05-18 14:17:17 [Epoch: 46] loss: 0.005045, mae: 0.050406, r2: 0.757016, val_loss: 0.006134, val_mae: 0.054682, val_r2: 0.704659
2024-05-18 14:17:17 Epoch 47: lr=1e-05
2024-05-18 14:18:30 [Epoch: 47] loss: 0.005044, mae: 0.050369, r2: 0.757065, val_loss: 0.006119, val_mae: 0.054507, val_r2: 0.704917
2024-05-18 14:18:30 Epoch 48: lr=1e-05
2024-05-18 14:19:43 [Epoch: 48] loss: 0.005033, mae: 0.050313, r2: 0.757659, val_loss: 0.006147, val_mae: 0.054773, val_r2: 0.703856
2024-05-18 14:19:43 Epoch 49: lr=1e-05
2024-05-18 14:20:56 [Epoch: 49] loss: 0.005025, mae: 0.050309, r2: 0.758131, val_loss: 0.006145, val_mae: 0.054565, val_r2: 0.704078
2024-05-18 14:20:56 Epoch 50: lr=1e-05
2024-05-18 14:22:09 [Epoch: 50] loss: 0.005023, mae: 0.050291, r2: 0.758097, val_loss: 0.006154, val_mae: 0.054479, val_r2: 0.703370
2024-05-18 14:22:09 Epoch 51: lr=1e-05
2024-05-18 14:23:21 [Epoch: 51] loss: 0.005020, mae: 0.050315, r2: 0.758215, val_loss: 0.006143, val_mae: 0.054636, val_r2: 0.704373
2024-05-18 14:23:21 Epoch 52: lr=1e-05
2024-05-18 14:24:33 [Epoch: 52] loss: 0.005009, mae: 0.050244, r2: 0.758650, val_loss: 0.006144, val_mae: 0.054589, val_r2: 0.704316
2024-05-18 14:24:34 Epoch 53: lr=1e-05
2024-05-18 14:25:46 [Epoch: 53] loss: 0.005008, mae: 0.050210, r2: 0.758904, val_loss: 0.006132, val_mae: 0.054657, val_r2: 0.704402
2024-05-18 14:25:46 Epoch 54: lr=1e-05
2024-05-18 14:26:58 [Epoch: 54] loss: 0.004992, mae: 0.050182, r2: 0.759349, val_loss: 0.006144, val_mae: 0.054557, val_r2: 0.703536
2024-05-18 14:26:58 Epoch 55: lr=1e-05
2024-05-18 14:28:11 [Epoch: 55] loss: 0.005000, mae: 0.050159, r2: 0.759285, val_loss: 0.006151, val_mae: 0.054602, val_r2: 0.703535
2024-05-18 14:28:11 Epoch 56: lr=1e-05
2024-05-18 14:29:24 [Epoch: 56] loss: 0.004994, mae: 0.050161, r2: 0.759515, val_loss: 0.006143, val_mae: 0.054513, val_r2: 0.703874
2024-05-18 14:29:24 Epoch 57: lr=1e-05
2024-05-18 14:30:37 [Epoch: 57] loss: 0.004986, mae: 0.050095, r2: 0.759889, val_loss: 0.006147, val_mae: 0.054521, val_r2: 0.703725
2024-05-18 14:30:37 history_length: 58
2024-05-18 14:30:37 stopping: early
2024-05-18 14:30:37 Comparing y_true and y_pred:
2024-05-18 14:30:37   mse: 0.00663487
2024-05-18 14:30:37   mae: 0.06835120
2024-05-18 14:30:37   r2: -0.19318362
2024-05-18 14:30:37   corr: 0.14103222
