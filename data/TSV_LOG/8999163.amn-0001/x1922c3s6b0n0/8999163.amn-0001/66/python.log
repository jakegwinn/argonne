2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/66', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '66', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/66/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/66', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s6b0n0.66.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/66/3.0.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/66'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x155097021a60>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/66/3.0.model.h5
2024-05-18 13:20:01 Between random pairs in y_val:
2024-05-18 13:20:01   mse: 0.04795865
2024-05-18 13:20:01   mae: 0.16045428
2024-05-18 13:20:01   r2: -0.99780740
2024-05-18 13:20:01   corr: 0.00109630
2024-05-18 13:20:01 Data points per epoch: train = 469906, val = 117477, test = 326
2024-05-18 13:20:01 Steps per epoch: train = 14684, val = 3671, test = 10
2024-05-18 13:20:01 Epoch 0: lr=0.001
2024-05-18 13:21:13 [Epoch: 0] loss: 0.031336, mae: 0.079167, r2: -0.645177, val_loss: 0.008503, val_mae: 0.065532, val_r2: 0.608965
2024-05-18 13:21:13 Epoch 1: lr=0.00082
2024-05-18 13:22:23 [Epoch: 1] loss: 0.008007, mae: 0.063996, r2: 0.619084, val_loss: 0.007568, val_mae: 0.061985, val_r2: 0.647670
2024-05-18 13:22:23 Epoch 2: lr=0.00064
2024-05-18 13:23:33 [Epoch: 2] loss: 0.007291, mae: 0.060699, r2: 0.651900, val_loss: 0.007098, val_mae: 0.060060, val_r2: 0.664014
2024-05-18 13:23:33 Epoch 3: lr=0.00046
2024-05-18 13:24:43 [Epoch: 3] loss: 0.006826, mae: 0.058636, r2: 0.673029, val_loss: 0.006842, val_mae: 0.058398, val_r2: 0.676222
2024-05-18 13:24:43 Epoch 4: lr=0.00028
2024-05-18 13:25:52 [Epoch: 4] loss: 0.006426, mae: 0.056816, r2: 0.691484, val_loss: 0.006552, val_mae: 0.057311, val_r2: 0.689422
2024-05-18 13:25:53 Epoch 5: lr=0.0001
2024-05-18 13:27:02 [Epoch: 5] loss: 0.006093, mae: 0.055248, r2: 0.707199, val_loss: 0.006366, val_mae: 0.056193, val_r2: 0.697774
2024-05-18 13:27:02 Epoch 6: lr=0.0001
2024-05-18 13:28:12 [Epoch: 6] loss: 0.005980, mae: 0.054725, r2: 0.712360, val_loss: 0.006341, val_mae: 0.056527, val_r2: 0.698640
2024-05-18 13:28:12 Epoch 7: lr=0.0001
2024-05-18 13:29:22 [Epoch: 7] loss: 0.005915, mae: 0.054439, r2: 0.715421, val_loss: 0.006312, val_mae: 0.055824, val_r2: 0.701789
2024-05-18 13:29:22 Epoch 8: lr=0.0001
2024-05-18 13:30:32 [Epoch: 8] loss: 0.005838, mae: 0.054085, r2: 0.719080, val_loss: 0.006286, val_mae: 0.055552, val_r2: 0.701062
2024-05-18 13:30:32 Epoch 9: lr=0.0001
2024-05-18 13:31:42 [Epoch: 9] loss: 0.005776, mae: 0.053817, r2: 0.721823, val_loss: 0.006271, val_mae: 0.055465, val_r2: 0.703190
2024-05-18 13:31:42 Epoch 10: lr=0.0001
2024-05-18 13:32:52 [Epoch: 10] loss: 0.005714, mae: 0.053545, r2: 0.724893, val_loss: 0.006219, val_mae: 0.055320, val_r2: 0.705860
2024-05-18 13:32:52 Epoch 11: lr=0.0001
2024-05-18 13:34:01 [Epoch: 11] loss: 0.005652, mae: 0.053266, r2: 0.727642, val_loss: 0.006194, val_mae: 0.055388, val_r2: 0.706015
2024-05-18 13:34:02 Epoch 12: lr=0.0001
2024-05-18 13:35:11 [Epoch: 12] loss: 0.005593, mae: 0.052988, r2: 0.730304, val_loss: 0.006179, val_mae: 0.054920, val_r2: 0.708145
2024-05-18 13:35:11 Epoch 13: lr=0.0001
2024-05-18 13:36:21 [Epoch: 13] loss: 0.005542, mae: 0.052755, r2: 0.732847, val_loss: 0.006165, val_mae: 0.054865, val_r2: 0.707933
2024-05-18 13:36:21 Epoch 14: lr=0.0001
2024-05-18 13:37:31 [Epoch: 14] loss: 0.005491, mae: 0.052542, r2: 0.735250, val_loss: 0.006160, val_mae: 0.055154, val_r2: 0.707941
2024-05-18 13:37:31 Epoch 15: lr=0.0001
2024-05-18 13:38:41 [Epoch: 15] loss: 0.005442, mae: 0.052308, r2: 0.737419, val_loss: 0.006138, val_mae: 0.054753, val_r2: 0.709388
2024-05-18 13:38:41 Epoch 16: lr=5e-05
2024-05-18 13:39:51 [Epoch: 16] loss: 0.005325, mae: 0.051722, r2: 0.743120, val_loss: 0.006108, val_mae: 0.054783, val_r2: 0.710126
2024-05-18 13:39:51 Epoch 17: lr=5e-05
2024-05-18 13:41:01 [Epoch: 17] loss: 0.005286, mae: 0.051552, r2: 0.744966, val_loss: 0.006123, val_mae: 0.054748, val_r2: 0.710746
2024-05-18 13:41:01 Epoch 18: lr=5e-05
2024-05-18 13:42:11 [Epoch: 18] loss: 0.005256, mae: 0.051449, r2: 0.746382, val_loss: 0.006116, val_mae: 0.054843, val_r2: 0.709462
2024-05-18 13:42:11 Epoch 19: lr=5e-05
2024-05-18 13:43:21 [Epoch: 19] loss: 0.005219, mae: 0.051282, r2: 0.747906, val_loss: 0.006089, val_mae: 0.054549, val_r2: 0.711182
2024-05-18 13:43:21 Epoch 20: lr=5e-05
2024-05-18 13:44:31 [Epoch: 20] loss: 0.005187, mae: 0.051122, r2: 0.749312, val_loss: 0.006096, val_mae: 0.054352, val_r2: 0.710476
2024-05-18 13:44:31 Epoch 21: lr=5e-05
2024-05-18 13:45:41 [Epoch: 21] loss: 0.005164, mae: 0.050983, r2: 0.750740, val_loss: 0.006105, val_mae: 0.054409, val_r2: 0.711204
2024-05-18 13:45:41 Epoch 22: lr=2.5e-05
2024-05-18 13:46:51 [Epoch: 22] loss: 0.005095, mae: 0.050664, r2: 0.753765, val_loss: 0.006132, val_mae: 0.054448, val_r2: 0.710183
2024-05-18 13:46:51 Epoch 23: lr=2.5e-05
2024-05-18 13:48:01 [Epoch: 23] loss: 0.005095, mae: 0.050657, r2: 0.753599, val_loss: 0.006109, val_mae: 0.054441, val_r2: 0.710681
2024-05-18 13:48:01 Epoch 24: lr=2.5e-05
2024-05-18 13:49:12 [Epoch: 24] loss: 0.005059, mae: 0.050528, r2: 0.755450, val_loss: 0.006090, val_mae: 0.054571, val_r2: 0.710805
2024-05-18 13:49:12 Epoch 25: lr=2.5e-05
2024-05-18 13:50:22 [Epoch: 25] loss: 0.005054, mae: 0.050473, r2: 0.755568, val_loss: 0.006102, val_mae: 0.054535, val_r2: 0.710253
2024-05-18 13:50:22 Epoch 26: lr=2.5e-05
2024-05-18 13:51:32 [Epoch: 26] loss: 0.005022, mae: 0.050328, r2: 0.757300, val_loss: 0.006075, val_mae: 0.054426, val_r2: 0.712698
2024-05-18 13:51:32 Epoch 27: lr=1.25e-05
2024-05-18 13:52:42 [Epoch: 27] loss: 0.004996, mae: 0.050219, r2: 0.758203, val_loss: 0.006081, val_mae: 0.054506, val_r2: 0.711605
2024-05-18 13:52:42 Epoch 28: lr=1.25e-05
2024-05-18 13:53:52 [Epoch: 28] loss: 0.005003, mae: 0.050232, r2: 0.758135, val_loss: 0.006082, val_mae: 0.054321, val_r2: 0.711887
2024-05-18 13:53:52 Epoch 29: lr=1.25e-05
2024-05-18 13:55:02 [Epoch: 29] loss: 0.004984, mae: 0.050168, r2: 0.758919, val_loss: 0.006081, val_mae: 0.054505, val_r2: 0.711212
2024-05-18 13:55:02 Epoch 30: lr=1.25e-05
2024-05-18 13:56:12 [Epoch: 30] loss: 0.004977, mae: 0.050111, r2: 0.759141, val_loss: 0.006081, val_mae: 0.054331, val_r2: 0.711902
2024-05-18 13:56:13 Epoch 31: lr=1.25e-05
2024-05-18 13:57:23 [Epoch: 31] loss: 0.004985, mae: 0.050115, r2: 0.758869, val_loss: 0.006073, val_mae: 0.054482, val_r2: 0.712423
2024-05-18 13:57:23 Epoch 32: lr=1e-05
2024-05-18 13:58:33 [Epoch: 32] loss: 0.004946, mae: 0.049964, r2: 0.760578, val_loss: 0.006117, val_mae: 0.054583, val_r2: 0.710402
2024-05-18 13:58:33 Epoch 33: lr=1e-05
2024-05-18 13:59:43 [Epoch: 33] loss: 0.004956, mae: 0.049979, r2: 0.760344, val_loss: 0.006069, val_mae: 0.054437, val_r2: 0.712438
2024-05-18 13:59:43 Epoch 34: lr=1e-05
2024-05-18 14:00:53 [Epoch: 34] loss: 0.004945, mae: 0.049961, r2: 0.760892, val_loss: 0.006108, val_mae: 0.054448, val_r2: 0.710481
2024-05-18 14:00:53 Epoch 35: lr=1e-05
2024-05-18 14:02:03 [Epoch: 35] loss: 0.004938, mae: 0.049930, r2: 0.761157, val_loss: 0.006117, val_mae: 0.054354, val_r2: 0.710409
2024-05-18 14:02:03 Epoch 36: lr=1e-05
2024-05-18 14:03:14 [Epoch: 36] loss: 0.004937, mae: 0.049916, r2: 0.761193, val_loss: 0.006078, val_mae: 0.054317, val_r2: 0.711657
2024-05-18 14:03:14 Epoch 37: lr=1e-05
2024-05-18 14:04:24 [Epoch: 37] loss: 0.004931, mae: 0.049895, r2: 0.761533, val_loss: 0.006077, val_mae: 0.054381, val_r2: 0.711443
2024-05-18 14:04:24 Epoch 38: lr=1e-05
2024-05-18 14:05:34 [Epoch: 38] loss: 0.004931, mae: 0.049870, r2: 0.761496, val_loss: 0.006104, val_mae: 0.054311, val_r2: 0.710785
2024-05-18 14:05:35 Epoch 39: lr=1e-05
2024-05-18 14:06:44 [Epoch: 39] loss: 0.004921, mae: 0.049820, r2: 0.761852, val_loss: 0.006091, val_mae: 0.054450, val_r2: 0.711088
2024-05-18 14:06:45 Epoch 40: lr=1e-05
2024-05-18 14:07:55 [Epoch: 40] loss: 0.004919, mae: 0.049831, r2: 0.761710, val_loss: 0.006057, val_mae: 0.054287, val_r2: 0.713016
2024-05-18 14:07:55 Epoch 41: lr=1e-05
2024-05-18 14:09:05 [Epoch: 41] loss: 0.004909, mae: 0.049795, r2: 0.762566, val_loss: 0.006068, val_mae: 0.054247, val_r2: 0.712299
2024-05-18 14:09:05 Epoch 42: lr=1e-05
2024-05-18 14:10:15 [Epoch: 42] loss: 0.004902, mae: 0.049776, r2: 0.762665, val_loss: 0.006105, val_mae: 0.054343, val_r2: 0.710363
2024-05-18 14:10:15 Epoch 43: lr=1e-05
2024-05-18 14:11:24 [Epoch: 43] loss: 0.004907, mae: 0.049785, r2: 0.762481, val_loss: 0.006083, val_mae: 0.054352, val_r2: 0.711158
2024-05-18 14:11:24 Epoch 44: lr=1e-05
2024-05-18 14:12:34 [Epoch: 44] loss: 0.004905, mae: 0.049790, r2: 0.762610, val_loss: 0.006088, val_mae: 0.054403, val_r2: 0.711516
2024-05-18 14:12:34 Epoch 45: lr=1e-05
2024-05-18 14:13:44 [Epoch: 45] loss: 0.004890, mae: 0.049705, r2: 0.763191, val_loss: 0.006081, val_mae: 0.054533, val_r2: 0.711023
2024-05-18 14:13:44 Epoch 46: lr=1e-05
2024-05-18 14:14:54 [Epoch: 46] loss: 0.004886, mae: 0.049683, r2: 0.763289, val_loss: 0.006076, val_mae: 0.054261, val_r2: 0.711725
2024-05-18 14:14:54 Epoch 47: lr=1e-05
2024-05-18 14:16:04 [Epoch: 47] loss: 0.004877, mae: 0.049676, r2: 0.763917, val_loss: 0.006092, val_mae: 0.054390, val_r2: 0.711363
2024-05-18 14:16:04 Epoch 48: lr=1e-05
2024-05-18 14:17:14 [Epoch: 48] loss: 0.004869, mae: 0.049630, r2: 0.764254, val_loss: 0.006104, val_mae: 0.054221, val_r2: 0.711041
2024-05-18 14:17:14 Epoch 49: lr=1e-05
2024-05-18 14:18:24 [Epoch: 49] loss: 0.004871, mae: 0.049611, r2: 0.764174, val_loss: 0.006087, val_mae: 0.054380, val_r2: 0.711663
2024-05-18 14:18:24 Epoch 50: lr=1e-05
2024-05-18 14:19:34 [Epoch: 50] loss: 0.004854, mae: 0.049538, r2: 0.765076, val_loss: 0.006093, val_mae: 0.054286, val_r2: 0.710370
2024-05-18 14:19:34 history_length: 51
2024-05-18 14:19:34 stopping: early
2024-05-18 14:19:34 Comparing y_true and y_pred:
2024-05-18 14:19:34   mse: 0.00317550
2024-05-18 14:19:34   mae: 0.05048705
2024-05-18 14:19:34   r2: -1.63592569
2024-05-18 14:19:34   corr: 0.30978639
