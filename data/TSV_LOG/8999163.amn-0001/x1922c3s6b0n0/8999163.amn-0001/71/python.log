2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/71', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '71', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/71/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/71', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s6b0n0.71.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/71/5.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/71'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x14feeec94b50>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/71/5.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04826933
2024-05-18 13:20:02   mae: 0.16076012
2024-05-18 13:20:02   r2: -1.00128850
2024-05-18 13:20:02   corr: -0.00064425
2024-05-18 13:20:02 Data points per epoch: train = 469876, val = 117469, test = 364
2024-05-18 13:20:02 Steps per epoch: train = 14683, val = 3670, test = 11
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:15 [Epoch: 0] loss: 0.026875, mae: 0.079776, r2: -0.058589, val_loss: 0.009088, val_mae: 0.069388, val_r2: 0.567454
2024-05-18 13:21:16 Epoch 1: lr=0.00082
2024-05-18 13:22:27 [Epoch: 1] loss: 0.008021, mae: 0.064050, r2: 0.618887, val_loss: 0.008144, val_mae: 0.063681, val_r2: 0.616280
2024-05-18 13:22:27 Epoch 2: lr=0.00064
2024-05-18 13:23:39 [Epoch: 2] loss: 0.007348, mae: 0.061020, r2: 0.649574, val_loss: 0.007146, val_mae: 0.059318, val_r2: 0.664195
2024-05-18 13:23:39 Epoch 3: lr=0.00046
2024-05-18 13:24:50 [Epoch: 3] loss: 0.006887, mae: 0.058923, r2: 0.670848, val_loss: 0.006837, val_mae: 0.057916, val_r2: 0.677122
2024-05-18 13:24:51 Epoch 4: lr=0.00028
2024-05-18 13:26:02 [Epoch: 4] loss: 0.006497, mae: 0.057106, r2: 0.688687, val_loss: 0.006740, val_mae: 0.059435, val_r2: 0.681061
2024-05-18 13:26:02 Epoch 5: lr=0.0001
2024-05-18 13:27:14 [Epoch: 5] loss: 0.006163, mae: 0.055548, r2: 0.704290, val_loss: 0.006406, val_mae: 0.056459, val_r2: 0.697009
2024-05-18 13:27:14 Epoch 6: lr=0.0001
2024-05-18 13:28:26 [Epoch: 6] loss: 0.006055, mae: 0.055101, r2: 0.708982, val_loss: 0.006356, val_mae: 0.056147, val_r2: 0.700868
2024-05-18 13:28:26 Epoch 7: lr=0.0001
2024-05-18 13:29:37 [Epoch: 7] loss: 0.005966, mae: 0.054672, r2: 0.713098, val_loss: 0.006322, val_mae: 0.055657, val_r2: 0.700374
2024-05-18 13:29:37 Epoch 8: lr=0.0001
2024-05-18 13:30:49 [Epoch: 8] loss: 0.005907, mae: 0.054416, r2: 0.715670, val_loss: 0.006291, val_mae: 0.056014, val_r2: 0.701146
2024-05-18 13:30:49 Epoch 9: lr=0.0001
2024-05-18 13:32:01 [Epoch: 9] loss: 0.005834, mae: 0.054060, r2: 0.719422, val_loss: 0.006278, val_mae: 0.055912, val_r2: 0.702434
2024-05-18 13:32:01 Epoch 10: lr=0.0001
2024-05-18 13:33:13 [Epoch: 10] loss: 0.005779, mae: 0.053838, r2: 0.721844, val_loss: 0.006227, val_mae: 0.055120, val_r2: 0.704865
2024-05-18 13:33:13 Epoch 11: lr=0.0001
2024-05-18 13:34:24 [Epoch: 11] loss: 0.005716, mae: 0.053557, r2: 0.724803, val_loss: 0.006221, val_mae: 0.055116, val_r2: 0.706631
2024-05-18 13:34:24 Epoch 12: lr=0.0001
2024-05-18 13:35:36 [Epoch: 12] loss: 0.005650, mae: 0.053252, r2: 0.727926, val_loss: 0.006174, val_mae: 0.055105, val_r2: 0.707544
2024-05-18 13:35:36 Epoch 13: lr=0.0001
2024-05-18 13:36:48 [Epoch: 13] loss: 0.005599, mae: 0.053026, r2: 0.730208, val_loss: 0.006182, val_mae: 0.055490, val_r2: 0.706520
2024-05-18 13:36:48 Epoch 14: lr=0.0001
2024-05-18 13:37:59 [Epoch: 14] loss: 0.005541, mae: 0.052750, r2: 0.733074, val_loss: 0.006135, val_mae: 0.054966, val_r2: 0.708732
2024-05-18 13:37:59 Epoch 15: lr=0.0001
2024-05-18 13:39:11 [Epoch: 15] loss: 0.005500, mae: 0.052550, r2: 0.735146, val_loss: 0.006139, val_mae: 0.054789, val_r2: 0.709037
2024-05-18 13:39:11 Epoch 16: lr=0.0001
2024-05-18 13:40:23 [Epoch: 16] loss: 0.005458, mae: 0.052384, r2: 0.736981, val_loss: 0.006133, val_mae: 0.054429, val_r2: 0.708576
2024-05-18 13:40:23 Epoch 17: lr=0.0001
2024-05-18 13:41:34 [Epoch: 17] loss: 0.005403, mae: 0.052094, r2: 0.739451, val_loss: 0.006096, val_mae: 0.054567, val_r2: 0.711240
2024-05-18 13:41:34 Epoch 18: lr=5e-05
2024-05-18 13:42:46 [Epoch: 18] loss: 0.005281, mae: 0.051532, r2: 0.745315, val_loss: 0.006061, val_mae: 0.054693, val_r2: 0.712061
2024-05-18 13:42:46 Epoch 19: lr=5e-05
2024-05-18 13:43:57 [Epoch: 19] loss: 0.005240, mae: 0.051358, r2: 0.747215, val_loss: 0.006048, val_mae: 0.054328, val_r2: 0.712992
2024-05-18 13:43:57 Epoch 20: lr=5e-05
2024-05-18 13:45:09 [Epoch: 20] loss: 0.005213, mae: 0.051192, r2: 0.748448, val_loss: 0.006094, val_mae: 0.054839, val_r2: 0.710435
2024-05-18 13:45:09 Epoch 21: lr=5e-05
2024-05-18 13:46:21 [Epoch: 21] loss: 0.005189, mae: 0.051105, r2: 0.749713, val_loss: 0.006121, val_mae: 0.054346, val_r2: 0.709240
2024-05-18 13:46:21 Epoch 22: lr=5e-05
2024-05-18 13:47:32 [Epoch: 22] loss: 0.005170, mae: 0.050990, r2: 0.750448, val_loss: 0.006040, val_mae: 0.054611, val_r2: 0.714222
2024-05-18 13:47:32 Epoch 23: lr=5e-05
2024-05-18 13:48:44 [Epoch: 23] loss: 0.005137, mae: 0.050856, r2: 0.752069, val_loss: 0.006050, val_mae: 0.054386, val_r2: 0.712984
2024-05-18 13:48:44 Epoch 24: lr=2.5e-05
2024-05-18 13:49:56 [Epoch: 24] loss: 0.005061, mae: 0.050477, r2: 0.755433, val_loss: 0.006058, val_mae: 0.054319, val_r2: 0.712540
2024-05-18 13:49:56 Epoch 25: lr=2.5e-05
2024-05-18 13:51:07 [Epoch: 25] loss: 0.005053, mae: 0.050481, r2: 0.755649, val_loss: 0.006064, val_mae: 0.054280, val_r2: 0.712505
2024-05-18 13:51:07 Epoch 26: lr=2.5e-05
2024-05-18 13:52:19 [Epoch: 26] loss: 0.005039, mae: 0.050366, r2: 0.756677, val_loss: 0.006055, val_mae: 0.054708, val_r2: 0.711999
2024-05-18 13:52:19 Epoch 27: lr=2.5e-05
2024-05-18 13:53:31 [Epoch: 27] loss: 0.005027, mae: 0.050290, r2: 0.757191, val_loss: 0.006040, val_mae: 0.054081, val_r2: 0.714294
2024-05-18 13:53:31 Epoch 28: lr=2.5e-05
2024-05-18 13:54:42 [Epoch: 28] loss: 0.005007, mae: 0.050219, r2: 0.758028, val_loss: 0.006057, val_mae: 0.054345, val_r2: 0.712762
2024-05-18 13:54:42 Epoch 29: lr=1.25e-05
2024-05-18 13:55:54 [Epoch: 29] loss: 0.004980, mae: 0.050088, r2: 0.759217, val_loss: 0.006040, val_mae: 0.054359, val_r2: 0.713607
2024-05-18 13:55:54 Epoch 30: lr=1.25e-05
2024-05-18 13:57:06 [Epoch: 30] loss: 0.004979, mae: 0.050053, r2: 0.759161, val_loss: 0.006036, val_mae: 0.054237, val_r2: 0.712710
2024-05-18 13:57:06 Epoch 31: lr=1.25e-05
2024-05-18 13:58:18 [Epoch: 31] loss: 0.004967, mae: 0.050030, r2: 0.759834, val_loss: 0.006052, val_mae: 0.054132, val_r2: 0.712189
2024-05-18 13:58:18 Epoch 32: lr=1.25e-05
2024-05-18 13:59:29 [Epoch: 32] loss: 0.004959, mae: 0.050000, r2: 0.760220, val_loss: 0.006017, val_mae: 0.054168, val_r2: 0.713469
2024-05-18 13:59:29 Epoch 33: lr=1.25e-05
2024-05-18 14:00:41 [Epoch: 33] loss: 0.004943, mae: 0.049884, r2: 0.761227, val_loss: 0.006023, val_mae: 0.054232, val_r2: 0.713969
2024-05-18 14:00:41 Epoch 34: lr=1e-05
2024-05-18 14:01:53 [Epoch: 34] loss: 0.004943, mae: 0.049928, r2: 0.760960, val_loss: 0.006024, val_mae: 0.054295, val_r2: 0.714277
2024-05-18 14:01:53 Epoch 35: lr=1e-05
2024-05-18 14:03:04 [Epoch: 35] loss: 0.004937, mae: 0.049896, r2: 0.761435, val_loss: 0.006031, val_mae: 0.054080, val_r2: 0.713951
2024-05-18 14:03:04 Epoch 36: lr=1e-05
2024-05-18 14:04:16 [Epoch: 36] loss: 0.004920, mae: 0.049818, r2: 0.762108, val_loss: 0.006040, val_mae: 0.054212, val_r2: 0.713450
2024-05-18 14:04:16 Epoch 37: lr=1e-05
2024-05-18 14:05:28 [Epoch: 37] loss: 0.004917, mae: 0.049800, r2: 0.762363, val_loss: 0.006036, val_mae: 0.054057, val_r2: 0.712943
2024-05-18 14:05:28 Epoch 38: lr=1e-05
2024-05-18 14:06:40 [Epoch: 38] loss: 0.004912, mae: 0.049776, r2: 0.762475, val_loss: 0.006057, val_mae: 0.054231, val_r2: 0.712739
2024-05-18 14:06:40 Epoch 39: lr=1e-05
2024-05-18 14:07:51 [Epoch: 39] loss: 0.004906, mae: 0.049740, r2: 0.762666, val_loss: 0.006024, val_mae: 0.054154, val_r2: 0.714306
2024-05-18 14:07:51 Epoch 40: lr=1e-05
2024-05-18 14:09:03 [Epoch: 40] loss: 0.004896, mae: 0.049667, r2: 0.763185, val_loss: 0.006046, val_mae: 0.054306, val_r2: 0.713009
2024-05-18 14:09:03 Epoch 41: lr=1e-05
2024-05-18 14:10:14 [Epoch: 41] loss: 0.004904, mae: 0.049729, r2: 0.762789, val_loss: 0.006009, val_mae: 0.054066, val_r2: 0.714776
2024-05-18 14:10:14 Epoch 42: lr=1e-05
2024-05-18 14:11:26 [Epoch: 42] loss: 0.004893, mae: 0.049697, r2: 0.763312, val_loss: 0.006020, val_mae: 0.054406, val_r2: 0.714258
2024-05-18 14:11:26 Epoch 43: lr=1e-05
2024-05-18 14:12:37 [Epoch: 43] loss: 0.004887, mae: 0.049652, r2: 0.763707, val_loss: 0.006030, val_mae: 0.054173, val_r2: 0.713071
2024-05-18 14:12:37 Epoch 44: lr=1e-05
2024-05-18 14:13:49 [Epoch: 44] loss: 0.004873, mae: 0.049577, r2: 0.764170, val_loss: 0.006046, val_mae: 0.053971, val_r2: 0.713309
2024-05-18 14:13:49 Epoch 45: lr=1e-05
2024-05-18 14:15:00 [Epoch: 45] loss: 0.004881, mae: 0.049624, r2: 0.763941, val_loss: 0.006041, val_mae: 0.054332, val_r2: 0.713182
2024-05-18 14:15:00 Epoch 46: lr=1e-05
2024-05-18 14:16:12 [Epoch: 46] loss: 0.004873, mae: 0.049580, r2: 0.764013, val_loss: 0.006039, val_mae: 0.054167, val_r2: 0.713048
2024-05-18 14:16:12 Epoch 47: lr=1e-05
2024-05-18 14:17:23 [Epoch: 47] loss: 0.004861, mae: 0.049539, r2: 0.764807, val_loss: 0.006041, val_mae: 0.054310, val_r2: 0.712692
2024-05-18 14:17:23 Epoch 48: lr=1e-05
2024-05-18 14:18:35 [Epoch: 48] loss: 0.004862, mae: 0.049577, r2: 0.764706, val_loss: 0.006031, val_mae: 0.054111, val_r2: 0.713817
2024-05-18 14:18:35 Epoch 49: lr=1e-05
2024-05-18 14:19:46 [Epoch: 49] loss: 0.004846, mae: 0.049503, r2: 0.765655, val_loss: 0.006032, val_mae: 0.054056, val_r2: 0.713623
2024-05-18 14:19:46 Epoch 50: lr=1e-05
2024-05-18 14:20:58 [Epoch: 50] loss: 0.004858, mae: 0.049537, r2: 0.764927, val_loss: 0.006057, val_mae: 0.054095, val_r2: 0.712688
2024-05-18 14:20:58 Epoch 51: lr=1e-05
2024-05-18 14:22:09 [Epoch: 51] loss: 0.004850, mae: 0.049492, r2: 0.765318, val_loss: 0.006047, val_mae: 0.054065, val_r2: 0.712503
2024-05-18 14:22:09 history_length: 52
2024-05-18 14:22:09 stopping: early
2024-05-18 14:22:09 Comparing y_true and y_pred:
2024-05-18 14:22:09   mse: 0.00179296
2024-05-18 14:22:09   mae: 0.02695504
2024-05-18 14:22:09   r2: -0.13947660
2024-05-18 14:22:09   corr: 0.05040783
