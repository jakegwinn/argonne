2024-05-18 13:19:43 UNO RUN ...
2024-05-18 13:19:43 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8999163.amn-0001/67', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8999163.amn-0001', 'run_id': '67', 'logfile': '/dev/shm/Uno/save/8999163.amn-0001/67/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8999163.amn-0001/67', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s6b0n0.67.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8999163.amn-0001/67/3.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8999163.amn-0001/67'}
2024-05-18 13:19:43 Feature encoding submodel for cell.rnaseq:
2024-05-18 13:19:43 Model: "cell.rnaseq"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense (Dense)               (None, 1000)              959000    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout (Permane  (None, 1000)              0         
2024-05-18 13:19:43  ntDropout)                                                      
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Trainable params: 2961000 (11.30 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Feature encoding submodel for drug.descriptors:
2024-05-18 13:19:43 Model: "drug.descriptors"
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape              Param #   
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-18 13:19:43  nentDropout)                                                    
2024-05-18 13:19:43                                                                  
2024-05-18 13:19:43 =================================================================
2024-05-18 13:19:43 Total params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Trainable params: 3616000 (13.79 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 _________________________________________________________________
2024-05-18 13:19:43 Combined model:
2024-05-18 13:19:43 Model: "model"
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:43  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-18 13:19:43  yer)                                                                                             
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-18 13:19:43  nputLayer)                                                                                       
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-18 13:19:43  al)                                                                ]']                           
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-18 13:19:43                                                                      'drug.descriptors[0][0]']    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-18 13:19:43  nentDropout)                                                                                     
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-18 13:19:43  anentDropout)                                                                                    
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-18 13:19:43                                                                                                   
2024-05-18 13:19:43 ==================================================================================================
2024-05-18 13:19:43 Total params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Trainable params: 12583001 (48.00 MB)
2024-05-18 13:19:43 Non-trainable params: 0 (0.00 Byte)
2024-05-18 13:19:43 __________________________________________________________________________________________________
2024-05-18 13:19:44 CKPT CONSTRUCT...
2024-05-18 13:19:44 CKPT CONSTRUCT OK.
2024-05-18 13:19:44 template model: <keras.src.engine.functional.Functional object at 0x15355f78bb80>
2024-05-18 13:19:45 COMPILE
2024-05-18 13:19:45 Will save weights to: /dev/shm/Uno/save/8999163.amn-0001/67/3.1.model.h5
2024-05-18 13:20:02 Between random pairs in y_val:
2024-05-18 13:20:02   mse: 0.04732386
2024-05-18 13:20:02   mae: 0.15948452
2024-05-18 13:20:02   r2: -0.99423318
2024-05-18 13:20:02   corr: 0.00288341
2024-05-18 13:20:02 Data points per epoch: train = 468664, val = 117167, test = 1878
2024-05-18 13:20:02 Steps per epoch: train = 14645, val = 3661, test = 58
2024-05-18 13:20:02 Epoch 0: lr=0.001
2024-05-18 13:21:15 [Epoch: 0] loss: 0.031666, mae: 0.079773, r2: -0.557334, val_loss: 0.008726, val_mae: 0.066342, val_r2: 0.589285
2024-05-18 13:21:15 Epoch 1: lr=0.00082
2024-05-18 13:22:26 [Epoch: 1] loss: 0.007994, mae: 0.063939, r2: 0.619893, val_loss: 0.007616, val_mae: 0.062218, val_r2: 0.638917
2024-05-18 13:22:26 Epoch 2: lr=0.00064
2024-05-18 13:23:38 [Epoch: 2] loss: 0.007304, mae: 0.060785, r2: 0.651811, val_loss: 0.007172, val_mae: 0.060235, val_r2: 0.659111
2024-05-18 13:23:38 Epoch 3: lr=0.00046
2024-05-18 13:24:49 [Epoch: 3] loss: 0.006834, mae: 0.058610, r2: 0.673468, val_loss: 0.006808, val_mae: 0.058872, val_r2: 0.676444
2024-05-18 13:24:50 Epoch 4: lr=0.00028
2024-05-18 13:26:01 [Epoch: 4] loss: 0.006421, mae: 0.056746, r2: 0.692385, val_loss: 0.006647, val_mae: 0.056759, val_r2: 0.683220
2024-05-18 13:26:02 Epoch 5: lr=0.0001
2024-05-18 13:27:13 [Epoch: 5] loss: 0.006086, mae: 0.055176, r2: 0.707622, val_loss: 0.006419, val_mae: 0.056668, val_r2: 0.692502
2024-05-18 13:27:13 Epoch 6: lr=0.0001
2024-05-18 13:28:24 [Epoch: 6] loss: 0.005979, mae: 0.054735, r2: 0.712860, val_loss: 0.006372, val_mae: 0.056354, val_r2: 0.693662
2024-05-18 13:28:24 Epoch 7: lr=0.0001
2024-05-18 13:29:36 [Epoch: 7] loss: 0.005904, mae: 0.054360, r2: 0.716197, val_loss: 0.006345, val_mae: 0.056177, val_r2: 0.694538
2024-05-18 13:29:36 Epoch 8: lr=0.0001
2024-05-18 13:30:48 [Epoch: 8] loss: 0.005823, mae: 0.054013, r2: 0.720105, val_loss: 0.006317, val_mae: 0.055669, val_r2: 0.696287
2024-05-18 13:30:48 Epoch 9: lr=0.0001
2024-05-18 13:31:59 [Epoch: 9] loss: 0.005760, mae: 0.053786, r2: 0.722732, val_loss: 0.006295, val_mae: 0.055738, val_r2: 0.698422
2024-05-18 13:31:59 Epoch 10: lr=0.0001
2024-05-18 13:33:11 [Epoch: 10] loss: 0.005699, mae: 0.053442, r2: 0.725616, val_loss: 0.006284, val_mae: 0.055419, val_r2: 0.696393
2024-05-18 13:33:11 Epoch 11: lr=0.0001
2024-05-18 13:34:23 [Epoch: 11] loss: 0.005639, mae: 0.053207, r2: 0.728501, val_loss: 0.006246, val_mae: 0.055594, val_r2: 0.701487
2024-05-18 13:34:23 Epoch 12: lr=0.0001
2024-05-18 13:35:35 [Epoch: 12] loss: 0.005569, mae: 0.052903, r2: 0.731843, val_loss: 0.006246, val_mae: 0.055335, val_r2: 0.699807
2024-05-18 13:35:35 Epoch 13: lr=0.0001
2024-05-18 13:36:47 [Epoch: 13] loss: 0.005524, mae: 0.052653, r2: 0.733783, val_loss: 0.006226, val_mae: 0.055194, val_r2: 0.701706
2024-05-18 13:36:47 Epoch 14: lr=5e-05
2024-05-18 13:37:59 [Epoch: 14] loss: 0.005403, mae: 0.052099, r2: 0.739496, val_loss: 0.006186, val_mae: 0.054987, val_r2: 0.702526
2024-05-18 13:37:59 Epoch 15: lr=5e-05
2024-05-18 13:39:11 [Epoch: 15] loss: 0.005366, mae: 0.051933, r2: 0.741426, val_loss: 0.006186, val_mae: 0.054844, val_r2: 0.702134
2024-05-18 13:39:11 Epoch 16: lr=5e-05
2024-05-18 13:40:22 [Epoch: 16] loss: 0.005331, mae: 0.051729, r2: 0.742967, val_loss: 0.006167, val_mae: 0.055490, val_r2: 0.703415
2024-05-18 13:40:22 Epoch 17: lr=5e-05
2024-05-18 13:41:34 [Epoch: 17] loss: 0.005306, mae: 0.051620, r2: 0.744203, val_loss: 0.006155, val_mae: 0.054921, val_r2: 0.704107
2024-05-18 13:41:34 Epoch 18: lr=5e-05
2024-05-18 13:42:46 [Epoch: 18] loss: 0.005279, mae: 0.051509, r2: 0.745444, val_loss: 0.006148, val_mae: 0.054768, val_r2: 0.704485
2024-05-18 13:42:46 Epoch 19: lr=5e-05
2024-05-18 13:43:58 [Epoch: 19] loss: 0.005247, mae: 0.051364, r2: 0.747013, val_loss: 0.006139, val_mae: 0.054772, val_r2: 0.705377
2024-05-18 13:43:58 Epoch 20: lr=2.5e-05
2024-05-18 13:45:09 [Epoch: 20] loss: 0.005172, mae: 0.051001, r2: 0.750274, val_loss: 0.006122, val_mae: 0.054702, val_r2: 0.706113
2024-05-18 13:45:09 Epoch 21: lr=2.5e-05
2024-05-18 13:46:21 [Epoch: 21] loss: 0.005163, mae: 0.050977, r2: 0.750838, val_loss: 0.006130, val_mae: 0.054736, val_r2: 0.706203
2024-05-18 13:46:21 Epoch 22: lr=2.5e-05
2024-05-18 13:47:33 [Epoch: 22] loss: 0.005141, mae: 0.050842, r2: 0.751863, val_loss: 0.006126, val_mae: 0.054419, val_r2: 0.706099
2024-05-18 13:47:33 Epoch 23: lr=2.5e-05
2024-05-18 13:48:45 [Epoch: 23] loss: 0.005129, mae: 0.050795, r2: 0.752565, val_loss: 0.006144, val_mae: 0.054843, val_r2: 0.705105
2024-05-18 13:48:45 Epoch 24: lr=2.5e-05
2024-05-18 13:49:57 [Epoch: 24] loss: 0.005111, mae: 0.050732, r2: 0.753355, val_loss: 0.006137, val_mae: 0.054557, val_r2: 0.705248
2024-05-18 13:49:57 Epoch 25: lr=1.25e-05
2024-05-18 13:51:09 [Epoch: 25] loss: 0.005082, mae: 0.050580, r2: 0.754668, val_loss: 0.006122, val_mae: 0.054547, val_r2: 0.705983
2024-05-18 13:51:09 Epoch 26: lr=1.25e-05
2024-05-18 13:52:21 [Epoch: 26] loss: 0.005072, mae: 0.050558, r2: 0.755211, val_loss: 0.006148, val_mae: 0.054645, val_r2: 0.704601
2024-05-18 13:52:21 Epoch 27: lr=1.25e-05
2024-05-18 13:53:32 [Epoch: 27] loss: 0.005057, mae: 0.050489, r2: 0.755779, val_loss: 0.006126, val_mae: 0.054939, val_r2: 0.705776
2024-05-18 13:53:33 Epoch 28: lr=1.25e-05
2024-05-18 13:54:45 [Epoch: 28] loss: 0.005049, mae: 0.050430, r2: 0.756370, val_loss: 0.006132, val_mae: 0.054628, val_r2: 0.705224
2024-05-18 13:54:45 Epoch 29: lr=1.25e-05
2024-05-18 13:55:56 [Epoch: 29] loss: 0.005054, mae: 0.050447, r2: 0.755817, val_loss: 0.006124, val_mae: 0.054569, val_r2: 0.705702
2024-05-18 13:55:56 Epoch 30: lr=1e-05
2024-05-18 13:57:08 [Epoch: 30] loss: 0.005027, mae: 0.050344, r2: 0.757305, val_loss: 0.006120, val_mae: 0.054558, val_r2: 0.706002
2024-05-18 13:57:08 Epoch 31: lr=1e-05
2024-05-18 13:58:20 [Epoch: 31] loss: 0.005043, mae: 0.050355, r2: 0.756591, val_loss: 0.006144, val_mae: 0.054831, val_r2: 0.704510
2024-05-18 13:58:20 Epoch 32: lr=1e-05
2024-05-18 13:59:32 [Epoch: 32] loss: 0.005030, mae: 0.050326, r2: 0.757043, val_loss: 0.006098, val_mae: 0.054483, val_r2: 0.707104
2024-05-18 13:59:32 Epoch 33: lr=1e-05
2024-05-18 14:00:43 [Epoch: 33] loss: 0.005019, mae: 0.050278, r2: 0.757501, val_loss: 0.006151, val_mae: 0.054591, val_r2: 0.704301
2024-05-18 14:00:43 Epoch 34: lr=1e-05
2024-05-18 14:01:55 [Epoch: 34] loss: 0.005014, mae: 0.050261, r2: 0.757743, val_loss: 0.006115, val_mae: 0.054475, val_r2: 0.705888
2024-05-18 14:01:55 Epoch 35: lr=1e-05
2024-05-18 14:03:07 [Epoch: 35] loss: 0.005011, mae: 0.050240, r2: 0.757864, val_loss: 0.006154, val_mae: 0.054637, val_r2: 0.704206
2024-05-18 14:03:07 Epoch 36: lr=1e-05
2024-05-18 14:04:19 [Epoch: 36] loss: 0.005005, mae: 0.050256, r2: 0.758325, val_loss: 0.006127, val_mae: 0.054654, val_r2: 0.705149
2024-05-18 14:04:19 Epoch 37: lr=1e-05
2024-05-18 14:05:31 [Epoch: 37] loss: 0.005004, mae: 0.050234, r2: 0.758231, val_loss: 0.006124, val_mae: 0.054515, val_r2: 0.705272
2024-05-18 14:05:31 Epoch 38: lr=1e-05
2024-05-18 14:06:43 [Epoch: 38] loss: 0.004998, mae: 0.050165, r2: 0.758453, val_loss: 0.006137, val_mae: 0.054639, val_r2: 0.704753
2024-05-18 14:06:43 Epoch 39: lr=1e-05
2024-05-18 14:07:54 [Epoch: 39] loss: 0.004998, mae: 0.050180, r2: 0.758391, val_loss: 0.006141, val_mae: 0.054680, val_r2: 0.704642
2024-05-18 14:07:54 Epoch 40: lr=1e-05
2024-05-18 14:09:06 [Epoch: 40] loss: 0.004975, mae: 0.050114, r2: 0.759655, val_loss: 0.006091, val_mae: 0.054411, val_r2: 0.707180
2024-05-18 14:09:06 Epoch 41: lr=1e-05
2024-05-18 14:10:18 [Epoch: 41] loss: 0.004973, mae: 0.050086, r2: 0.759640, val_loss: 0.006139, val_mae: 0.054551, val_r2: 0.704446
2024-05-18 14:10:18 Epoch 42: lr=1e-05
2024-05-18 14:11:29 [Epoch: 42] loss: 0.004974, mae: 0.050067, r2: 0.759709, val_loss: 0.006114, val_mae: 0.054538, val_r2: 0.706330
2024-05-18 14:11:29 Epoch 43: lr=1e-05
2024-05-18 14:12:41 [Epoch: 43] loss: 0.004972, mae: 0.050070, r2: 0.759996, val_loss: 0.006101, val_mae: 0.054457, val_r2: 0.706952
2024-05-18 14:12:41 Epoch 44: lr=1e-05
2024-05-18 14:13:52 [Epoch: 44] loss: 0.004951, mae: 0.049983, r2: 0.760684, val_loss: 0.006123, val_mae: 0.054497, val_r2: 0.705376
2024-05-18 14:13:52 Epoch 45: lr=1e-05
2024-05-18 14:15:04 [Epoch: 45] loss: 0.004948, mae: 0.049947, r2: 0.760855, val_loss: 0.006155, val_mae: 0.054647, val_r2: 0.704219
2024-05-18 14:15:04 Epoch 46: lr=1e-05
2024-05-18 14:16:15 [Epoch: 46] loss: 0.004943, mae: 0.049930, r2: 0.761014, val_loss: 0.006130, val_mae: 0.054638, val_r2: 0.704635
2024-05-18 14:16:15 Epoch 47: lr=1e-05
2024-05-18 14:17:26 [Epoch: 47] loss: 0.004947, mae: 0.049960, r2: 0.760980, val_loss: 0.006120, val_mae: 0.054507, val_r2: 0.706066
2024-05-18 14:17:26 Epoch 48: lr=1e-05
2024-05-18 14:18:38 [Epoch: 48] loss: 0.004936, mae: 0.049884, r2: 0.761357, val_loss: 0.006133, val_mae: 0.054474, val_r2: 0.705177
2024-05-18 14:18:38 Epoch 49: lr=1e-05
2024-05-18 14:19:49 [Epoch: 49] loss: 0.004931, mae: 0.049865, r2: 0.761834, val_loss: 0.006113, val_mae: 0.054420, val_r2: 0.706147
2024-05-18 14:19:49 Epoch 50: lr=1e-05
2024-05-18 14:21:00 [Epoch: 50] loss: 0.004919, mae: 0.049816, r2: 0.762206, val_loss: 0.006103, val_mae: 0.054619, val_r2: 0.706615
2024-05-18 14:21:01 history_length: 51
2024-05-18 14:21:01 stopping: early
2024-05-18 14:21:01 Comparing y_true and y_pred:
2024-05-18 14:21:01   mse: 0.02927403
2024-05-18 14:21:01   mae: 0.12922760
2024-05-18 14:21:01   r2: -0.50595997
2024-05-18 14:21:01   corr: 0.12286706
