2024-05-17 17:41:53 UNO RUN ...
2024-05-17 17:41:53 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8998722.amn-0001/43', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8998722.amn-0001', 'run_id': '43', 'logfile': '/dev/shm/Uno/save/8998722.amn-0001/43/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8998722.amn-0001/43', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c2s4b0n0.43.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8998722.amn-0001/43/3.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8998722.amn-0001/43'}
2024-05-17 17:41:54 Feature encoding submodel for cell.rnaseq:
2024-05-17 17:41:54 Model: "cell.rnaseq"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense (Dense)               (None, 1000)              959000    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout (Permane  (None, 1000)              0         
2024-05-17 17:41:54  ntDropout)                                                      
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Trainable params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Feature encoding submodel for drug.descriptors:
2024-05-17 17:41:54 Model: "drug.descriptors"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Trainable params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Combined model:
2024-05-17 17:41:54 Model: "model"
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-17 17:41:54  yer)                                                                                             
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-17 17:41:54  nputLayer)                                                                                       
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-17 17:41:54  al)                                                                ]']                           
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-17 17:41:54                                                                      'drug.descriptors[0][0]']    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-17 17:41:54  anentDropout)                                                                                    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54 Total params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Trainable params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54 CKPT CONSTRUCT...
2024-05-17 17:41:54 CKPT CONSTRUCT OK.
2024-05-17 17:41:54 template model: <keras.src.engine.functional.Functional object at 0x154807cb6af0>
2024-05-17 17:41:56 COMPILE
2024-05-17 17:41:56 Will save weights to: /dev/shm/Uno/save/8998722.amn-0001/43/3.1.model.h5
2024-05-17 17:42:11 Between random pairs in y_val:
2024-05-17 17:42:11   mse: 0.04787770
2024-05-17 17:42:11   mae: 0.16014203
2024-05-17 17:42:11   r2: -0.99859173
2024-05-17 17:42:11   corr: 0.00070414
2024-05-17 17:42:11 Data points per epoch: train = 469697, val = 117425, test = 587
2024-05-17 17:42:11 Steps per epoch: train = 14678, val = 3669, test = 18
2024-05-17 17:42:11 Epoch 0: lr=0.001
2024-05-17 17:43:25 [Epoch: 0] loss: 0.025677, mae: 0.079247, r2: -0.112881, val_loss: 0.008655, val_mae: 0.067062, val_r2: 0.598015
2024-05-17 17:43:26 Epoch 1: lr=0.00082
2024-05-17 17:44:38 [Epoch: 1] loss: 0.007986, mae: 0.063906, r2: 0.620492, val_loss: 0.007988, val_mae: 0.062791, val_r2: 0.623986
2024-05-17 17:44:38 Epoch 2: lr=0.00064
2024-05-17 17:45:51 [Epoch: 2] loss: 0.007319, mae: 0.060861, r2: 0.651403, val_loss: 0.007202, val_mae: 0.059574, val_r2: 0.657951
2024-05-17 17:45:51 Epoch 3: lr=0.00046
2024-05-17 17:47:03 [Epoch: 3] loss: 0.006844, mae: 0.058706, r2: 0.673103, val_loss: 0.006915, val_mae: 0.058326, val_r2: 0.670550
2024-05-17 17:47:04 Epoch 4: lr=0.00028
2024-05-17 17:48:17 [Epoch: 4] loss: 0.006446, mae: 0.056893, r2: 0.691343, val_loss: 0.006669, val_mae: 0.057543, val_r2: 0.682376
2024-05-17 17:48:17 Epoch 5: lr=0.0001
2024-05-17 17:49:29 [Epoch: 5] loss: 0.006120, mae: 0.055350, r2: 0.706341, val_loss: 0.006460, val_mae: 0.056619, val_r2: 0.694098
2024-05-17 17:49:30 Epoch 6: lr=0.0001
2024-05-17 17:50:42 [Epoch: 6] loss: 0.006001, mae: 0.054846, r2: 0.711866, val_loss: 0.006424, val_mae: 0.056010, val_r2: 0.694531
2024-05-17 17:50:42 Epoch 7: lr=0.0001
2024-05-17 17:51:55 [Epoch: 7] loss: 0.005913, mae: 0.054414, r2: 0.715962, val_loss: 0.006363, val_mae: 0.056185, val_r2: 0.697998
2024-05-17 17:51:55 Epoch 8: lr=0.0001
2024-05-17 17:53:08 [Epoch: 8] loss: 0.005847, mae: 0.054125, r2: 0.718932, val_loss: 0.006396, val_mae: 0.055742, val_r2: 0.695020
2024-05-17 17:53:08 Epoch 9: lr=0.0001
2024-05-17 17:54:21 [Epoch: 9] loss: 0.005784, mae: 0.053839, r2: 0.722103, val_loss: 0.006324, val_mae: 0.056127, val_r2: 0.700102
2024-05-17 17:54:21 Epoch 10: lr=0.0001
2024-05-17 17:55:33 [Epoch: 10] loss: 0.005721, mae: 0.053555, r2: 0.724893, val_loss: 0.006316, val_mae: 0.055603, val_r2: 0.699995
2024-05-17 17:55:33 Epoch 11: lr=0.0001
2024-05-17 17:56:46 [Epoch: 11] loss: 0.005668, mae: 0.053321, r2: 0.727602, val_loss: 0.006255, val_mae: 0.055423, val_r2: 0.702310
2024-05-17 17:56:46 Epoch 12: lr=0.0001
2024-05-17 17:58:00 [Epoch: 12] loss: 0.005602, mae: 0.053023, r2: 0.730529, val_loss: 0.006250, val_mae: 0.055273, val_r2: 0.703244
2024-05-17 17:58:00 Epoch 13: lr=0.0001
2024-05-17 17:59:12 [Epoch: 13] loss: 0.005558, mae: 0.052780, r2: 0.732513, val_loss: 0.006257, val_mae: 0.056257, val_r2: 0.703951
2024-05-17 17:59:13 Epoch 14: lr=0.0001
2024-05-17 18:00:25 [Epoch: 14] loss: 0.005496, mae: 0.052568, r2: 0.735428, val_loss: 0.006231, val_mae: 0.055495, val_r2: 0.703901
2024-05-17 18:00:26 Epoch 15: lr=5e-05
2024-05-17 18:01:38 [Epoch: 15] loss: 0.005388, mae: 0.052045, r2: 0.740359, val_loss: 0.006192, val_mae: 0.055286, val_r2: 0.704613
2024-05-17 18:01:38 Epoch 16: lr=5e-05
2024-05-17 18:02:51 [Epoch: 16] loss: 0.005347, mae: 0.051836, r2: 0.742535, val_loss: 0.006189, val_mae: 0.055182, val_r2: 0.705185
2024-05-17 18:02:51 Epoch 17: lr=5e-05
2024-05-17 18:04:03 [Epoch: 17] loss: 0.005312, mae: 0.051701, r2: 0.744037, val_loss: 0.006182, val_mae: 0.054987, val_r2: 0.706195
2024-05-17 18:04:03 Epoch 18: lr=5e-05
2024-05-17 18:05:16 [Epoch: 18] loss: 0.005286, mae: 0.051520, r2: 0.745271, val_loss: 0.006172, val_mae: 0.054938, val_r2: 0.706982
2024-05-17 18:05:16 Epoch 19: lr=5e-05
2024-05-17 18:06:29 [Epoch: 19] loss: 0.005252, mae: 0.051364, r2: 0.746580, val_loss: 0.006154, val_mae: 0.054706, val_r2: 0.707891
2024-05-17 18:06:29 Epoch 20: lr=5e-05
2024-05-17 18:07:42 [Epoch: 20] loss: 0.005223, mae: 0.051258, r2: 0.748347, val_loss: 0.006172, val_mae: 0.054949, val_r2: 0.706573
2024-05-17 18:07:42 Epoch 21: lr=2.5e-05
2024-05-17 18:08:55 [Epoch: 21] loss: 0.005167, mae: 0.050972, r2: 0.750754, val_loss: 0.006148, val_mae: 0.055024, val_r2: 0.707300
2024-05-17 18:08:55 Epoch 22: lr=2.5e-05
2024-05-17 18:10:08 [Epoch: 22] loss: 0.005139, mae: 0.050836, r2: 0.752260, val_loss: 0.006183, val_mae: 0.054694, val_r2: 0.706254
2024-05-17 18:10:08 Epoch 23: lr=2.5e-05
2024-05-17 18:11:21 [Epoch: 23] loss: 0.005124, mae: 0.050813, r2: 0.752676, val_loss: 0.006165, val_mae: 0.054897, val_r2: 0.707212
2024-05-17 18:11:21 Epoch 24: lr=2.5e-05
2024-05-17 18:12:34 [Epoch: 24] loss: 0.005113, mae: 0.050727, r2: 0.753159, val_loss: 0.006172, val_mae: 0.054717, val_r2: 0.706364
2024-05-17 18:12:34 Epoch 25: lr=2.5e-05
2024-05-17 18:13:46 [Epoch: 25] loss: 0.005103, mae: 0.050691, r2: 0.753693, val_loss: 0.006152, val_mae: 0.054716, val_r2: 0.707375
2024-05-17 18:13:46 Epoch 26: lr=1.25e-05
2024-05-17 18:14:59 [Epoch: 26] loss: 0.005055, mae: 0.050459, r2: 0.755943, val_loss: 0.006141, val_mae: 0.054745, val_r2: 0.707380
2024-05-17 18:14:59 Epoch 27: lr=1.25e-05
2024-05-17 18:16:12 [Epoch: 27] loss: 0.005053, mae: 0.050451, r2: 0.756072, val_loss: 0.006164, val_mae: 0.055087, val_r2: 0.706149
2024-05-17 18:16:12 Epoch 28: lr=1.25e-05
2024-05-17 18:17:25 [Epoch: 28] loss: 0.005040, mae: 0.050417, r2: 0.756745, val_loss: 0.006156, val_mae: 0.054599, val_r2: 0.706667
2024-05-17 18:17:25 Epoch 29: lr=1.25e-05
2024-05-17 18:18:38 [Epoch: 29] loss: 0.005039, mae: 0.050344, r2: 0.756831, val_loss: 0.006146, val_mae: 0.054676, val_r2: 0.706953
2024-05-17 18:18:38 Epoch 30: lr=1.25e-05
2024-05-17 18:19:51 [Epoch: 30] loss: 0.005033, mae: 0.050378, r2: 0.756886, val_loss: 0.006138, val_mae: 0.054839, val_r2: 0.707822
2024-05-17 18:19:51 Epoch 31: lr=1e-05
2024-05-17 18:21:03 [Epoch: 31] loss: 0.005023, mae: 0.050307, r2: 0.757432, val_loss: 0.006185, val_mae: 0.054922, val_r2: 0.704656
2024-05-17 18:21:03 Epoch 32: lr=1e-05
2024-05-17 18:22:16 [Epoch: 32] loss: 0.005001, mae: 0.050226, r2: 0.758436, val_loss: 0.006151, val_mae: 0.054622, val_r2: 0.706936
2024-05-17 18:22:16 Epoch 33: lr=1e-05
2024-05-17 18:23:29 [Epoch: 33] loss: 0.005007, mae: 0.050248, r2: 0.758142, val_loss: 0.006161, val_mae: 0.054667, val_r2: 0.706249
2024-05-17 18:23:29 Epoch 34: lr=1e-05
2024-05-17 18:24:41 [Epoch: 34] loss: 0.004999, mae: 0.050202, r2: 0.758588, val_loss: 0.006165, val_mae: 0.054734, val_r2: 0.706270
2024-05-17 18:24:42 Epoch 35: lr=1e-05
2024-05-17 18:25:55 [Epoch: 35] loss: 0.004998, mae: 0.050201, r2: 0.758699, val_loss: 0.006148, val_mae: 0.054814, val_r2: 0.706824
2024-05-17 18:25:55 Epoch 36: lr=1e-05
2024-05-17 18:27:08 [Epoch: 36] loss: 0.004992, mae: 0.050129, r2: 0.758822, val_loss: 0.006145, val_mae: 0.054722, val_r2: 0.706946
2024-05-17 18:27:08 Epoch 37: lr=1e-05
2024-05-17 18:28:21 [Epoch: 37] loss: 0.004989, mae: 0.050140, r2: 0.759004, val_loss: 0.006165, val_mae: 0.054731, val_r2: 0.706298
2024-05-17 18:28:21 Epoch 38: lr=1e-05
2024-05-17 18:29:33 [Epoch: 38] loss: 0.004986, mae: 0.050095, r2: 0.759278, val_loss: 0.006162, val_mae: 0.054801, val_r2: 0.706608
2024-05-17 18:29:33 Epoch 39: lr=1e-05
2024-05-17 18:30:46 [Epoch: 39] loss: 0.004975, mae: 0.050095, r2: 0.759610, val_loss: 0.006131, val_mae: 0.054654, val_r2: 0.707910
2024-05-17 18:30:46 Epoch 40: lr=1e-05
2024-05-17 18:31:59 [Epoch: 40] loss: 0.004964, mae: 0.050040, r2: 0.760224, val_loss: 0.006144, val_mae: 0.054569, val_r2: 0.707469
2024-05-17 18:31:59 Epoch 41: lr=1e-05
2024-05-17 18:33:11 [Epoch: 41] loss: 0.004961, mae: 0.050004, r2: 0.760494, val_loss: 0.006154, val_mae: 0.054681, val_r2: 0.707028
2024-05-17 18:33:12 Epoch 42: lr=1e-05
2024-05-17 18:34:24 [Epoch: 42] loss: 0.004962, mae: 0.049991, r2: 0.760351, val_loss: 0.006158, val_mae: 0.054658, val_r2: 0.706672
2024-05-17 18:34:24 Epoch 43: lr=1e-05
2024-05-17 18:35:37 [Epoch: 43] loss: 0.004959, mae: 0.050010, r2: 0.760557, val_loss: 0.006151, val_mae: 0.054639, val_r2: 0.707304
2024-05-17 18:35:37 Epoch 44: lr=1e-05
2024-05-17 18:36:50 [Epoch: 44] loss: 0.004940, mae: 0.049927, r2: 0.761324, val_loss: 0.006165, val_mae: 0.054732, val_r2: 0.706261
2024-05-17 18:36:50 Epoch 45: lr=1e-05
2024-05-17 18:38:02 [Epoch: 45] loss: 0.004943, mae: 0.049937, r2: 0.761203, val_loss: 0.006210, val_mae: 0.054771, val_r2: 0.703926
2024-05-17 18:38:02 Epoch 46: lr=1e-05
2024-05-17 18:39:15 [Epoch: 46] loss: 0.004944, mae: 0.049957, r2: 0.761157, val_loss: 0.006127, val_mae: 0.054493, val_r2: 0.708030
2024-05-17 18:39:15 Epoch 47: lr=1e-05
2024-05-17 18:40:27 [Epoch: 47] loss: 0.004926, mae: 0.049875, r2: 0.761911, val_loss: 0.006155, val_mae: 0.054700, val_r2: 0.706470
2024-05-17 18:40:27 Epoch 48: lr=1e-05
2024-05-17 18:41:40 [Epoch: 48] loss: 0.004929, mae: 0.049875, r2: 0.761760, val_loss: 0.006162, val_mae: 0.054851, val_r2: 0.705882
2024-05-17 18:41:40 Epoch 49: lr=1e-05
2024-05-17 18:42:52 [Epoch: 49] loss: 0.004926, mae: 0.049827, r2: 0.761872, val_loss: 0.006155, val_mae: 0.054660, val_r2: 0.706466
2024-05-17 18:42:52 Epoch 50: lr=1e-05
2024-05-17 18:44:04 [Epoch: 50] loss: 0.004911, mae: 0.049782, r2: 0.762551, val_loss: 0.006161, val_mae: 0.054596, val_r2: 0.706238
2024-05-17 18:44:04 Epoch 51: lr=1e-05
2024-05-17 18:45:17 [Epoch: 51] loss: 0.004915, mae: 0.049790, r2: 0.762608, val_loss: 0.006161, val_mae: 0.054613, val_r2: 0.706358
2024-05-17 18:45:17 Epoch 52: lr=1e-05
2024-05-17 18:46:29 [Epoch: 52] loss: 0.004911, mae: 0.049764, r2: 0.762681, val_loss: 0.006152, val_mae: 0.054619, val_r2: 0.706993
2024-05-17 18:46:29 Epoch 53: lr=1e-05
2024-05-17 18:47:42 [Epoch: 53] loss: 0.004891, mae: 0.049692, r2: 0.763600, val_loss: 0.006127, val_mae: 0.054485, val_r2: 0.708301
2024-05-17 18:47:42 Epoch 54: lr=1e-05
2024-05-17 18:48:54 [Epoch: 54] loss: 0.004891, mae: 0.049689, r2: 0.763732, val_loss: 0.006161, val_mae: 0.054544, val_r2: 0.706124
2024-05-17 18:48:54 Epoch 55: lr=1e-05
2024-05-17 18:50:06 [Epoch: 55] loss: 0.004892, mae: 0.049692, r2: 0.763744, val_loss: 0.006160, val_mae: 0.054528, val_r2: 0.706063
2024-05-17 18:50:07 Epoch 56: lr=1e-05
2024-05-17 18:51:19 [Epoch: 56] loss: 0.004877, mae: 0.049626, r2: 0.764260, val_loss: 0.006121, val_mae: 0.054610, val_r2: 0.708723
2024-05-17 18:51:19 Epoch 57: lr=1e-05
2024-05-17 18:52:31 [Epoch: 57] loss: 0.004884, mae: 0.049656, r2: 0.764115, val_loss: 0.006178, val_mae: 0.054702, val_r2: 0.705542
2024-05-17 18:52:31 Epoch 58: lr=1e-05
2024-05-17 18:53:43 [Epoch: 58] loss: 0.004875, mae: 0.049599, r2: 0.764510, val_loss: 0.006131, val_mae: 0.054553, val_r2: 0.707738
2024-05-17 18:53:43 Epoch 59: lr=1e-05
2024-05-17 18:54:56 [Epoch: 59] loss: 0.004878, mae: 0.049620, r2: 0.764360, val_loss: 0.006113, val_mae: 0.054472, val_r2: 0.708309
2024-05-17 18:54:56 Epoch 60: lr=1e-05
2024-05-17 18:56:08 [Epoch: 60] loss: 0.004864, mae: 0.049584, r2: 0.764896, val_loss: 0.006164, val_mae: 0.054615, val_r2: 0.705487
2024-05-17 18:56:08 Epoch 61: lr=1e-05
2024-05-17 18:57:21 [Epoch: 61] loss: 0.004864, mae: 0.049548, r2: 0.765063, val_loss: 0.006182, val_mae: 0.054575, val_r2: 0.705547
2024-05-17 18:57:21 Epoch 62: lr=1e-05
2024-05-17 18:58:33 [Epoch: 62] loss: 0.004863, mae: 0.049536, r2: 0.765024, val_loss: 0.006153, val_mae: 0.054543, val_r2: 0.706710
2024-05-17 18:58:33 Epoch 63: lr=1e-05
2024-05-17 18:59:45 [Epoch: 63] loss: 0.004856, mae: 0.049503, r2: 0.765248, val_loss: 0.006155, val_mae: 0.054669, val_r2: 0.706581
2024-05-17 18:59:45 Epoch 64: lr=1e-05
2024-05-17 19:00:58 [Epoch: 64] loss: 0.004852, mae: 0.049476, r2: 0.765455, val_loss: 0.006149, val_mae: 0.054662, val_r2: 0.706811
2024-05-17 19:00:58 Epoch 65: lr=1e-05
2024-05-17 19:02:10 [Epoch: 65] loss: 0.004843, mae: 0.049446, r2: 0.765980, val_loss: 0.006160, val_mae: 0.054616, val_r2: 0.706594
2024-05-17 19:02:10 Epoch 66: lr=1e-05
2024-05-17 19:03:22 [Epoch: 66] loss: 0.004844, mae: 0.049442, r2: 0.765858, val_loss: 0.006149, val_mae: 0.054522, val_r2: 0.706911
2024-05-17 19:03:22 Epoch 67: lr=1e-05
2024-05-17 19:04:34 [Epoch: 67] loss: 0.004831, mae: 0.049397, r2: 0.766628, val_loss: 0.006163, val_mae: 0.054552, val_r2: 0.706049
2024-05-17 19:04:34 Epoch 68: lr=1e-05
2024-05-17 19:05:47 [Epoch: 68] loss: 0.004817, mae: 0.049324, r2: 0.767129, val_loss: 0.006167, val_mae: 0.054514, val_r2: 0.705877
2024-05-17 19:05:47 Epoch 69: lr=1e-05
2024-05-17 19:06:59 [Epoch: 69] loss: 0.004822, mae: 0.049346, r2: 0.766937, val_loss: 0.006169, val_mae: 0.054777, val_r2: 0.705823
2024-05-17 19:07:00 history_length: 70
2024-05-17 19:07:00 stopping: early
2024-05-17 19:07:00 Comparing y_true and y_pred:
2024-05-17 19:07:00   mse: 0.00734733
2024-05-17 19:07:00   mae: 0.07045575
2024-05-17 19:07:00   r2: -0.66838849
2024-05-17 19:07:00   corr: 0.30238179
