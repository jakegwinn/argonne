2024-05-17 17:41:53 UNO RUN ...
2024-05-17 17:41:53 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8998722.amn-0001/133', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8998722.amn-0001', 'run_id': '133', 'logfile': '/dev/shm/Uno/save/8998722.amn-0001/133/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8998722.amn-0001/133', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s7b0n0.133.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8998722.amn-0001/133/0.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8998722.amn-0001/133'}
2024-05-17 17:41:54 Feature encoding submodel for cell.rnaseq:
2024-05-17 17:41:54 Model: "cell.rnaseq"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense (Dense)               (None, 1000)              959000    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout (Permane  (None, 1000)              0         
2024-05-17 17:41:54  ntDropout)                                                      
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Trainable params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Feature encoding submodel for drug.descriptors:
2024-05-17 17:41:54 Model: "drug.descriptors"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Trainable params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Combined model:
2024-05-17 17:41:54 Model: "model"
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-17 17:41:54  yer)                                                                                             
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-17 17:41:54  nputLayer)                                                                                       
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-17 17:41:54  al)                                                                ]']                           
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-17 17:41:54                                                                      'drug.descriptors[0][0]']    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-17 17:41:54  anentDropout)                                                                                    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54 Total params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Trainable params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54 CKPT CONSTRUCT...
2024-05-17 17:41:54 CKPT CONSTRUCT OK.
2024-05-17 17:41:54 template model: <keras.src.engine.functional.Functional object at 0x14d7e8046850>
2024-05-17 17:41:55 COMPILE
2024-05-17 17:41:56 Will save weights to: /dev/shm/Uno/save/8998722.amn-0001/133/0.1.model.h5
2024-05-17 17:42:12 Between random pairs in y_val:
2024-05-17 17:42:12   mse: 0.04797294
2024-05-17 17:42:12   mae: 0.15984886
2024-05-17 17:42:12   r2: -0.99851386
2024-05-17 17:42:12   corr: 0.00074307
2024-05-17 17:42:12 Data points per epoch: train = 469620, val = 117405, test = 684
2024-05-17 17:42:12 Steps per epoch: train = 14675, val = 3668, test = 21
2024-05-17 17:42:12 Epoch 0: lr=0.001
2024-05-17 17:43:24 [Epoch: 0] loss: 0.023214, mae: 0.079047, r2: 0.186697, val_loss: 0.008543, val_mae: 0.066064, val_r2: 0.600899
2024-05-17 17:43:24 Epoch 1: lr=0.00082
2024-05-17 17:44:35 [Epoch: 1] loss: 0.007980, mae: 0.063847, r2: 0.621489, val_loss: 0.007905, val_mae: 0.062113, val_r2: 0.624303
2024-05-17 17:44:35 Epoch 2: lr=0.00064
2024-05-17 17:45:46 [Epoch: 2] loss: 0.007314, mae: 0.060795, r2: 0.652000, val_loss: 0.007446, val_mae: 0.060051, val_r2: 0.648767
2024-05-17 17:45:46 Epoch 3: lr=0.00046
2024-05-17 17:46:57 [Epoch: 3] loss: 0.006885, mae: 0.058832, r2: 0.671742, val_loss: 0.006938, val_mae: 0.059503, val_r2: 0.671167
2024-05-17 17:46:57 Epoch 4: lr=0.00028
2024-05-17 17:48:07 [Epoch: 4] loss: 0.006485, mae: 0.057013, r2: 0.690073, val_loss: 0.006715, val_mae: 0.057023, val_r2: 0.680777
2024-05-17 17:48:07 Epoch 5: lr=0.0001
2024-05-17 17:49:18 [Epoch: 5] loss: 0.006167, mae: 0.055528, r2: 0.704908, val_loss: 0.006489, val_mae: 0.056685, val_r2: 0.690627
2024-05-17 17:49:18 Epoch 6: lr=0.0001
2024-05-17 17:50:29 [Epoch: 6] loss: 0.006055, mae: 0.055037, r2: 0.709949, val_loss: 0.006429, val_mae: 0.056575, val_r2: 0.691855
2024-05-17 17:50:29 Epoch 7: lr=0.0001
2024-05-17 17:51:39 [Epoch: 7] loss: 0.005976, mae: 0.054684, r2: 0.713599, val_loss: 0.006398, val_mae: 0.056436, val_r2: 0.695108
2024-05-17 17:51:39 Epoch 8: lr=0.0001
2024-05-17 17:52:51 [Epoch: 8] loss: 0.005904, mae: 0.054391, r2: 0.716933, val_loss: 0.006355, val_mae: 0.056048, val_r2: 0.697382
2024-05-17 17:52:51 Epoch 9: lr=0.0001
2024-05-17 17:54:01 [Epoch: 9] loss: 0.005820, mae: 0.053988, r2: 0.720817, val_loss: 0.006359, val_mae: 0.055575, val_r2: 0.697090
2024-05-17 17:54:01 Epoch 10: lr=0.0001
2024-05-17 17:55:12 [Epoch: 10] loss: 0.005765, mae: 0.053745, r2: 0.723663, val_loss: 0.006308, val_mae: 0.055504, val_r2: 0.698575
2024-05-17 17:55:12 Epoch 11: lr=0.0001
2024-05-17 17:56:22 [Epoch: 11] loss: 0.005715, mae: 0.053507, r2: 0.725786, val_loss: 0.006275, val_mae: 0.055611, val_r2: 0.700117
2024-05-17 17:56:22 Epoch 12: lr=0.0001
2024-05-17 17:57:33 [Epoch: 12] loss: 0.005649, mae: 0.053197, r2: 0.728905, val_loss: 0.006283, val_mae: 0.055554, val_r2: 0.699758
2024-05-17 17:57:33 Epoch 13: lr=0.0001
2024-05-17 17:58:43 [Epoch: 13] loss: 0.005587, mae: 0.052960, r2: 0.731650, val_loss: 0.006237, val_mae: 0.054940, val_r2: 0.701823
2024-05-17 17:58:43 Epoch 14: lr=0.0001
2024-05-17 17:59:54 [Epoch: 14] loss: 0.005540, mae: 0.052744, r2: 0.734119, val_loss: 0.006234, val_mae: 0.054889, val_r2: 0.701466
2024-05-17 17:59:54 Epoch 15: lr=0.0001
2024-05-17 18:01:04 [Epoch: 15] loss: 0.005483, mae: 0.052443, r2: 0.736663, val_loss: 0.006195, val_mae: 0.055159, val_r2: 0.704413
2024-05-17 18:01:05 Epoch 16: lr=0.0001
2024-05-17 18:02:15 [Epoch: 16] loss: 0.005445, mae: 0.052270, r2: 0.738270, val_loss: 0.006172, val_mae: 0.055304, val_r2: 0.705278
2024-05-17 18:02:15 Epoch 17: lr=0.0001
2024-05-17 18:03:26 [Epoch: 17] loss: 0.005387, mae: 0.051997, r2: 0.740989, val_loss: 0.006172, val_mae: 0.055253, val_r2: 0.705585
2024-05-17 18:03:26 Epoch 18: lr=0.0001
2024-05-17 18:04:37 [Epoch: 18] loss: 0.005343, mae: 0.051794, r2: 0.743129, val_loss: 0.006194, val_mae: 0.055518, val_r2: 0.704374
2024-05-17 18:04:37 Epoch 19: lr=5e-05
2024-05-17 18:05:48 [Epoch: 19] loss: 0.005220, mae: 0.051191, r2: 0.748933, val_loss: 0.006145, val_mae: 0.054925, val_r2: 0.705295
2024-05-17 18:05:48 Epoch 20: lr=5e-05
2024-05-17 18:06:58 [Epoch: 20] loss: 0.005199, mae: 0.051085, r2: 0.749838, val_loss: 0.006108, val_mae: 0.054520, val_r2: 0.707825
2024-05-17 18:06:58 Epoch 21: lr=5e-05
2024-05-17 18:08:09 [Epoch: 21] loss: 0.005151, mae: 0.050838, r2: 0.752173, val_loss: 0.006132, val_mae: 0.054750, val_r2: 0.707483
2024-05-17 18:08:09 Epoch 22: lr=5e-05
2024-05-17 18:09:19 [Epoch: 22] loss: 0.005126, mae: 0.050798, r2: 0.753169, val_loss: 0.006110, val_mae: 0.054371, val_r2: 0.708821
2024-05-17 18:09:19 Epoch 23: lr=5e-05
2024-05-17 18:10:30 [Epoch: 23] loss: 0.005093, mae: 0.050586, r2: 0.754730, val_loss: 0.006094, val_mae: 0.054432, val_r2: 0.708688
2024-05-17 18:10:30 Epoch 24: lr=5e-05
2024-05-17 18:11:40 [Epoch: 24] loss: 0.005083, mae: 0.050528, r2: 0.755311, val_loss: 0.006112, val_mae: 0.054605, val_r2: 0.708552
2024-05-17 18:11:40 Epoch 25: lr=5e-05
2024-05-17 18:12:51 [Epoch: 25] loss: 0.005051, mae: 0.050406, r2: 0.756699, val_loss: 0.006101, val_mae: 0.054862, val_r2: 0.707623
2024-05-17 18:12:51 Epoch 26: lr=2.5e-05
2024-05-17 18:14:01 [Epoch: 26] loss: 0.004988, mae: 0.050058, r2: 0.759649, val_loss: 0.006103, val_mae: 0.054284, val_r2: 0.709403
2024-05-17 18:14:01 Epoch 27: lr=2.5e-05
2024-05-17 18:15:12 [Epoch: 27] loss: 0.004970, mae: 0.050011, r2: 0.760532, val_loss: 0.006082, val_mae: 0.054596, val_r2: 0.708941
2024-05-17 18:15:12 Epoch 28: lr=2.5e-05
2024-05-17 18:16:22 [Epoch: 28] loss: 0.004948, mae: 0.049933, r2: 0.761455, val_loss: 0.006109, val_mae: 0.054244, val_r2: 0.707971
2024-05-17 18:16:23 Epoch 29: lr=2.5e-05
2024-05-17 18:17:33 [Epoch: 29] loss: 0.004935, mae: 0.049827, r2: 0.762147, val_loss: 0.006092, val_mae: 0.054132, val_r2: 0.708624
2024-05-17 18:17:33 Epoch 30: lr=2.5e-05
2024-05-17 18:18:44 [Epoch: 30] loss: 0.004924, mae: 0.049761, r2: 0.762612, val_loss: 0.006101, val_mae: 0.054645, val_r2: 0.708497
2024-05-17 18:18:44 Epoch 31: lr=1.25e-05
2024-05-17 18:19:55 [Epoch: 31] loss: 0.004891, mae: 0.049667, r2: 0.764207, val_loss: 0.006085, val_mae: 0.054173, val_r2: 0.709486
2024-05-17 18:19:55 Epoch 32: lr=1.25e-05
2024-05-17 18:21:05 [Epoch: 32] loss: 0.004884, mae: 0.049567, r2: 0.764456, val_loss: 0.006078, val_mae: 0.054318, val_r2: 0.709920
2024-05-17 18:21:05 Epoch 33: lr=1.25e-05
2024-05-17 18:22:16 [Epoch: 33] loss: 0.004893, mae: 0.049631, r2: 0.764324, val_loss: 0.006091, val_mae: 0.054508, val_r2: 0.707921
2024-05-17 18:22:17 Epoch 34: lr=1.25e-05
2024-05-17 18:23:27 [Epoch: 34] loss: 0.004864, mae: 0.049513, r2: 0.765498, val_loss: 0.006088, val_mae: 0.054254, val_r2: 0.709000
2024-05-17 18:23:27 Epoch 35: lr=1.25e-05
2024-05-17 18:24:38 [Epoch: 35] loss: 0.004863, mae: 0.049484, r2: 0.765460, val_loss: 0.006076, val_mae: 0.054260, val_r2: 0.709655
2024-05-17 18:24:38 Epoch 36: lr=1e-05
2024-05-17 18:25:49 [Epoch: 36] loss: 0.004861, mae: 0.049491, r2: 0.765558, val_loss: 0.006091, val_mae: 0.054310, val_r2: 0.708751
2024-05-17 18:25:49 Epoch 37: lr=1e-05
2024-05-17 18:27:00 [Epoch: 37] loss: 0.004855, mae: 0.049444, r2: 0.766103, val_loss: 0.006079, val_mae: 0.054268, val_r2: 0.709006
2024-05-17 18:27:00 Epoch 38: lr=1e-05
2024-05-17 18:28:10 [Epoch: 38] loss: 0.004840, mae: 0.049417, r2: 0.766523, val_loss: 0.006090, val_mae: 0.054205, val_r2: 0.709038
2024-05-17 18:28:10 Epoch 39: lr=1e-05
2024-05-17 18:29:21 [Epoch: 39] loss: 0.004839, mae: 0.049392, r2: 0.766576, val_loss: 0.006083, val_mae: 0.054071, val_r2: 0.710186
2024-05-17 18:29:21 Epoch 40: lr=1e-05
2024-05-17 18:30:31 [Epoch: 40] loss: 0.004828, mae: 0.049326, r2: 0.766887, val_loss: 0.006073, val_mae: 0.054320, val_r2: 0.708786
2024-05-17 18:30:31 Epoch 41: lr=1e-05
2024-05-17 18:31:42 [Epoch: 41] loss: 0.004817, mae: 0.049274, r2: 0.767766, val_loss: 0.006078, val_mae: 0.054038, val_r2: 0.708963
2024-05-17 18:31:42 Epoch 42: lr=1e-05
2024-05-17 18:32:53 [Epoch: 42] loss: 0.004826, mae: 0.049305, r2: 0.767118, val_loss: 0.006080, val_mae: 0.054351, val_r2: 0.709602
2024-05-17 18:32:53 Epoch 43: lr=1e-05
2024-05-17 18:34:03 [Epoch: 43] loss: 0.004814, mae: 0.049267, r2: 0.767761, val_loss: 0.006082, val_mae: 0.054416, val_r2: 0.708991
2024-05-17 18:34:03 Epoch 44: lr=1e-05
2024-05-17 18:35:14 [Epoch: 44] loss: 0.004810, mae: 0.049224, r2: 0.767823, val_loss: 0.006071, val_mae: 0.054172, val_r2: 0.709053
2024-05-17 18:35:14 Epoch 45: lr=1e-05
2024-05-17 18:36:24 [Epoch: 45] loss: 0.004797, mae: 0.049174, r2: 0.768623, val_loss: 0.006104, val_mae: 0.054106, val_r2: 0.708685
2024-05-17 18:36:24 Epoch 46: lr=1e-05
2024-05-17 18:37:35 [Epoch: 46] loss: 0.004805, mae: 0.049190, r2: 0.768328, val_loss: 0.006086, val_mae: 0.054253, val_r2: 0.709040
2024-05-17 18:37:35 Epoch 47: lr=1e-05
2024-05-17 18:38:45 [Epoch: 47] loss: 0.004800, mae: 0.049187, r2: 0.768428, val_loss: 0.006103, val_mae: 0.054240, val_r2: 0.707208
2024-05-17 18:38:46 Epoch 48: lr=1e-05
2024-05-17 18:39:56 [Epoch: 48] loss: 0.004789, mae: 0.049114, r2: 0.769026, val_loss: 0.006102, val_mae: 0.054392, val_r2: 0.708120
2024-05-17 18:39:56 Epoch 49: lr=1e-05
2024-05-17 18:41:06 [Epoch: 49] loss: 0.004790, mae: 0.049140, r2: 0.768978, val_loss: 0.006090, val_mae: 0.054119, val_r2: 0.708776
2024-05-17 18:41:06 Epoch 50: lr=1e-05
2024-05-17 18:42:17 [Epoch: 50] loss: 0.004785, mae: 0.049118, r2: 0.769134, val_loss: 0.006077, val_mae: 0.054194, val_r2: 0.709129
2024-05-17 18:42:17 Epoch 51: lr=1e-05
2024-05-17 18:43:27 [Epoch: 51] loss: 0.004781, mae: 0.049073, r2: 0.769149, val_loss: 0.006087, val_mae: 0.054211, val_r2: 0.708027
2024-05-17 18:43:27 Epoch 52: lr=1e-05
2024-05-17 18:44:37 [Epoch: 52] loss: 0.004775, mae: 0.049062, r2: 0.769661, val_loss: 0.006085, val_mae: 0.054359, val_r2: 0.708428
2024-05-17 18:44:38 Epoch 53: lr=1e-05
2024-05-17 18:45:48 [Epoch: 53] loss: 0.004772, mae: 0.049041, r2: 0.769897, val_loss: 0.006068, val_mae: 0.054142, val_r2: 0.709832
2024-05-17 18:45:48 Epoch 54: lr=1e-05
2024-05-17 18:46:59 [Epoch: 54] loss: 0.004769, mae: 0.048993, r2: 0.769695, val_loss: 0.006082, val_mae: 0.054248, val_r2: 0.708587
2024-05-17 18:46:59 Epoch 55: lr=1e-05
2024-05-17 18:48:09 [Epoch: 55] loss: 0.004756, mae: 0.048954, r2: 0.770395, val_loss: 0.006120, val_mae: 0.054513, val_r2: 0.707437
2024-05-17 18:48:09 Epoch 56: lr=1e-05
2024-05-17 18:49:19 [Epoch: 56] loss: 0.004748, mae: 0.048947, r2: 0.770679, val_loss: 0.006088, val_mae: 0.054189, val_r2: 0.708766
2024-05-17 18:49:19 Epoch 57: lr=1e-05
2024-05-17 18:50:29 [Epoch: 57] loss: 0.004749, mae: 0.048945, r2: 0.770694, val_loss: 0.006073, val_mae: 0.054169, val_r2: 0.709976
2024-05-17 18:50:29 Epoch 58: lr=1e-05
2024-05-17 18:51:40 [Epoch: 58] loss: 0.004744, mae: 0.048927, r2: 0.771015, val_loss: 0.006094, val_mae: 0.054094, val_r2: 0.708586
2024-05-17 18:51:40 Epoch 59: lr=1e-05
2024-05-17 18:52:50 [Epoch: 59] loss: 0.004730, mae: 0.048814, r2: 0.771858, val_loss: 0.006119, val_mae: 0.054297, val_r2: 0.707114
2024-05-17 18:52:50 Epoch 60: lr=1e-05
2024-05-17 18:54:00 [Epoch: 60] loss: 0.004732, mae: 0.048865, r2: 0.771399, val_loss: 0.006099, val_mae: 0.054470, val_r2: 0.707777
2024-05-17 18:54:01 Epoch 61: lr=1e-05
2024-05-17 18:55:11 [Epoch: 61] loss: 0.004733, mae: 0.048856, r2: 0.771444, val_loss: 0.006089, val_mae: 0.054199, val_r2: 0.709434
2024-05-17 18:55:11 Epoch 62: lr=1e-05
2024-05-17 18:56:21 [Epoch: 62] loss: 0.004727, mae: 0.048822, r2: 0.771889, val_loss: 0.006113, val_mae: 0.054358, val_r2: 0.707586
2024-05-17 18:56:22 Epoch 63: lr=1e-05
2024-05-17 18:57:32 [Epoch: 63] loss: 0.004718, mae: 0.048828, r2: 0.772214, val_loss: 0.006112, val_mae: 0.054176, val_r2: 0.708174
2024-05-17 18:57:32 history_length: 64
2024-05-17 18:57:32 stopping: early
2024-05-17 18:57:32 Comparing y_true and y_pred:
2024-05-17 18:57:32   mse: 0.00527669
2024-05-17 18:57:32   mae: 0.06297695
2024-05-17 18:57:32   r2: -0.38506421
2024-05-17 18:57:32   corr: 0.32051162
