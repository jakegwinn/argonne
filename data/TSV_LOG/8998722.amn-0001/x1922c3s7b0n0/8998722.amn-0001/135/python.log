2024-05-17 17:41:53 UNO RUN ...
2024-05-17 17:41:53 Params: {'model_name': 'uno', 'train_sources': ['CCLE'], 'test_sources': ['train'], 'cell_types': None, 'cell_features': ['rnaseq'], 'drug_features': ['descriptors'], 'dense': [1000, 1000, 1000, 1000, 1000], 'dense_feature_layers': [1000, 1000, 1000], 'activation': 'relu', 'loss': 'mse', 'optimizer': 'adamax', 'scaling': 'std', 'dropout': 0.1, 'epochs': 75, 'batch_size': 32, 'val_split': 0.2, 'cv': 1, 'max_val_loss': 1.0, 'learning_rate': 0.0001, 'base_lr': None, 'agg_dose': 'AUC', 'residual': False, 'reduce_lr': True, 'warmup_lr': True, 'batch_normalization': False, 'feature_subsample': 0, 'rng_seed': 2018, 'no_gen': False, 'verbose': False, 'preprocess_rnaseq': 'source_scale', 'gpus': [0], 'use_landmark_genes': True, 'no_feature_source': True, 'no_response_source': True, 'save_path': '/dev/shm/Uno/save/8998722.amn-0001/135', 'single': True, 'on_memory_loader': True, 'ckpt_checksum': True, 'ckpt_save_interval': 0, 'timeout': -1, 'train_bool': True, 'profiling': False, 'experiment_id': '8998722.amn-0001', 'run_id': '135', 'logfile': '/dev/shm/Uno/save/8998722.amn-0001/135/python.log', 'shuffle': False, 'ckpt_restart_mode': 'off', 'ckpt_skip_epochs': 0, 'ckpt_directory': '/dev/shm/Uno/save/8998722.amn-0001/135', 'ckpt_save_best': True, 'ckpt_save_best_metric': 'val_loss', 'ckpt_save_weights_only': False, 'ckpt_keep_mode': 'linear', 'ckpt_keep_limit': 5, 'by_cell': None, 'by_drug': None, 'cell_subset_path': '', 'drug_subset_path': '', 'drug_median_response_min': -1, 'drug_median_response_max': 1, 'dense_cell_feature_layers': None, 'dense_drug_feature_layers': None, 'use_filtered_genes': False, 'feature_subset_path': '', 'cell_feature_subset_path': '', 'drug_feature_subset_path': '', 'es': True, 'cp': False, 'tb': False, 'tb_prefix': 'tb', 'partition_by': None, 'cache': None, 'export_csv': None, 'export_data': None, 'use_exported_data': '/dev/shm/Uno/x1922c3s7b0n0.135.merged.landmark.h5', 'growth_bins': 0, 'initial_weights': None, 'save_weights': '/dev/shm/Uno/save/8998722.amn-0001/135/1.1.model.h5', 'config_file': '/home/brettin/CSC249ADOA01_CNDA/brettin/Benchmarks/Pilot1/Uno/uno_auc_model.txt', 'data_type': <class 'numpy.float32'>, 'data_dir': '/dev/shm/Uno/uno/Data', 'output_dir': '/dev/shm/Uno/uno/Output/8998722.amn-0001/135'}
2024-05-17 17:41:54 Feature encoding submodel for cell.rnaseq:
2024-05-17 17:41:54 Model: "cell.rnaseq"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_1 (InputLayer)        [(None, 958)]             0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense (Dense)               (None, 1000)              959000    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout (Permane  (None, 1000)              0         
2024-05-17 17:41:54  ntDropout)                                                      
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_1 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_1 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_2 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_2 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Trainable params: 2961000 (11.30 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Feature encoding submodel for drug.descriptors:
2024-05-17 17:41:54 Model: "drug.descriptors"
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape              Param #   
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54  input_2 (InputLayer)        [(None, 1613)]            0         
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_3 (Dense)             (None, 1000)              1614000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_3 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_4 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_4 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  dense_5 (Dense)             (None, 1000)              1001000   
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54  permanent_dropout_5 (Perma  (None, 1000)              0         
2024-05-17 17:41:54  nentDropout)                                                    
2024-05-17 17:41:54                                                                  
2024-05-17 17:41:54 =================================================================
2024-05-17 17:41:54 Total params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Trainable params: 3616000 (13.79 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 _________________________________________________________________
2024-05-17 17:41:54 Combined model:
2024-05-17 17:41:54 Model: "model"
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54  Layer (type)                Output Shape                 Param #   Connected to                  
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54  input.cell.rnaseq (InputLa  [(None, 958)]                0         []                            
2024-05-17 17:41:54  yer)                                                                                             
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  input.drug1.descriptors (I  [(None, 1613)]               0         []                            
2024-05-17 17:41:54  nputLayer)                                                                                       
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  cell.rnaseq (Functional)    (None, 1000)                 2961000   ['input.cell.rnaseq[0][0]']   
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  drug.descriptors (Function  (None, 1000)                 3616000   ['input.drug1.descriptors[0][0
2024-05-17 17:41:54  al)                                                                ]']                           
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  concatenate (Concatenate)   (None, 2000)                 0         ['cell.rnaseq[0][0]',         
2024-05-17 17:41:54                                                                      'drug.descriptors[0][0]']    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_6 (Dense)             (None, 1000)                 2001000   ['concatenate[0][0]']         
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_6 (Perma  (None, 1000)                 0         ['dense_6[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_7 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_6[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_7 (Perma  (None, 1000)                 0         ['dense_7[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_8 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_7[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_8 (Perma  (None, 1000)                 0         ['dense_8[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_9 (Dense)             (None, 1000)                 1001000   ['permanent_dropout_8[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_9 (Perma  (None, 1000)                 0         ['dense_9[0][0]']             
2024-05-17 17:41:54  nentDropout)                                                                                     
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_10 (Dense)            (None, 1000)                 1001000   ['permanent_dropout_9[0][0]'] 
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  permanent_dropout_10 (Perm  (None, 1000)                 0         ['dense_10[0][0]']            
2024-05-17 17:41:54  anentDropout)                                                                                    
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54  dense_11 (Dense)            (None, 1)                    1001      ['permanent_dropout_10[0][0]']
2024-05-17 17:41:54                                                                                                   
2024-05-17 17:41:54 ==================================================================================================
2024-05-17 17:41:54 Total params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Trainable params: 12583001 (48.00 MB)
2024-05-17 17:41:54 Non-trainable params: 0 (0.00 Byte)
2024-05-17 17:41:54 __________________________________________________________________________________________________
2024-05-17 17:41:54 CKPT CONSTRUCT...
2024-05-17 17:41:54 CKPT CONSTRUCT OK.
2024-05-17 17:41:54 template model: <keras.src.engine.functional.Functional object at 0x154b0c0c4bb0>
2024-05-17 17:41:56 COMPILE
2024-05-17 17:41:56 Will save weights to: /dev/shm/Uno/save/8998722.amn-0001/135/1.1.model.h5
2024-05-17 17:42:12 Between random pairs in y_val:
2024-05-17 17:42:12   mse: 0.04787747
2024-05-17 17:42:12   mae: 0.16003337
2024-05-17 17:42:12   r2: -0.99761647
2024-05-17 17:42:12   corr: 0.00119176
2024-05-17 17:42:12 Data points per epoch: train = 469550, val = 117388, test = 771
2024-05-17 17:42:12 Steps per epoch: train = 14673, val = 3668, test = 24
2024-05-17 17:42:12 Epoch 0: lr=0.001
2024-05-17 17:43:26 [Epoch: 0] loss: 0.032539, mae: 0.079677, r2: -0.027812, val_loss: 0.008571, val_mae: 0.065919, val_r2: 0.601405
2024-05-17 17:43:26 Epoch 1: lr=0.00082
2024-05-17 17:44:39 [Epoch: 1] loss: 0.008001, mae: 0.064001, r2: 0.619963, val_loss: 0.007700, val_mae: 0.062519, val_r2: 0.633690
2024-05-17 17:44:39 Epoch 2: lr=0.00064
2024-05-17 17:45:51 [Epoch: 2] loss: 0.007331, mae: 0.060895, r2: 0.650997, val_loss: 0.007217, val_mae: 0.060893, val_r2: 0.657221
2024-05-17 17:45:51 Epoch 3: lr=0.00046
2024-05-17 17:47:04 [Epoch: 3] loss: 0.006836, mae: 0.058687, r2: 0.673168, val_loss: 0.006867, val_mae: 0.057834, val_r2: 0.675522
2024-05-17 17:47:04 Epoch 4: lr=0.00028
2024-05-17 17:48:16 [Epoch: 4] loss: 0.006439, mae: 0.056804, r2: 0.691927, val_loss: 0.006563, val_mae: 0.057222, val_r2: 0.690358
2024-05-17 17:48:17 Epoch 5: lr=0.0001
2024-05-17 17:49:29 [Epoch: 5] loss: 0.006105, mae: 0.055259, r2: 0.707168, val_loss: 0.006373, val_mae: 0.056267, val_r2: 0.697816
2024-05-17 17:49:29 Epoch 6: lr=0.0001
2024-05-17 17:50:41 [Epoch: 6] loss: 0.005994, mae: 0.054749, r2: 0.712258, val_loss: 0.006347, val_mae: 0.055797, val_r2: 0.699703
2024-05-17 17:50:41 Epoch 7: lr=0.0001
2024-05-17 17:51:54 [Epoch: 7] loss: 0.005917, mae: 0.054425, r2: 0.715697, val_loss: 0.006330, val_mae: 0.055683, val_r2: 0.699249
2024-05-17 17:51:54 Epoch 8: lr=0.0001
2024-05-17 17:53:07 [Epoch: 8] loss: 0.005847, mae: 0.054081, r2: 0.718982, val_loss: 0.006292, val_mae: 0.055969, val_r2: 0.701070
2024-05-17 17:53:07 Epoch 9: lr=0.0001
2024-05-17 17:54:19 [Epoch: 9] loss: 0.005786, mae: 0.053806, r2: 0.721802, val_loss: 0.006244, val_mae: 0.055594, val_r2: 0.703417
2024-05-17 17:54:20 Epoch 10: lr=0.0001
2024-05-17 17:55:32 [Epoch: 10] loss: 0.005730, mae: 0.053561, r2: 0.724402, val_loss: 0.006219, val_mae: 0.055210, val_r2: 0.705724
2024-05-17 17:55:32 Epoch 11: lr=0.0001
2024-05-17 17:56:45 [Epoch: 11] loss: 0.005670, mae: 0.053286, r2: 0.727396, val_loss: 0.006244, val_mae: 0.055308, val_r2: 0.705094
2024-05-17 17:56:45 Epoch 12: lr=0.0001
2024-05-17 17:57:58 [Epoch: 12] loss: 0.005612, mae: 0.053024, r2: 0.729870, val_loss: 0.006190, val_mae: 0.055096, val_r2: 0.706192
2024-05-17 17:57:58 Epoch 13: lr=0.0001
2024-05-17 17:59:11 [Epoch: 13] loss: 0.005555, mae: 0.052733, r2: 0.732619, val_loss: 0.006199, val_mae: 0.055734, val_r2: 0.705062
2024-05-17 17:59:11 Epoch 14: lr=0.0001
2024-05-17 18:00:23 [Epoch: 14] loss: 0.005498, mae: 0.052493, r2: 0.735390, val_loss: 0.006151, val_mae: 0.054942, val_r2: 0.708558
2024-05-17 18:00:23 Epoch 15: lr=5e-05
2024-05-17 18:01:36 [Epoch: 15] loss: 0.005390, mae: 0.051975, r2: 0.740358, val_loss: 0.006161, val_mae: 0.054584, val_r2: 0.707706
2024-05-17 18:01:36 Epoch 16: lr=5e-05
2024-05-17 18:02:48 [Epoch: 16] loss: 0.005341, mae: 0.051754, r2: 0.742563, val_loss: 0.006119, val_mae: 0.054783, val_r2: 0.709327
2024-05-17 18:02:48 Epoch 17: lr=5e-05
2024-05-17 18:04:02 [Epoch: 17] loss: 0.005306, mae: 0.051579, r2: 0.744232, val_loss: 0.006088, val_mae: 0.054608, val_r2: 0.710988
2024-05-17 18:04:02 Epoch 18: lr=5e-05
2024-05-17 18:05:15 [Epoch: 18] loss: 0.005275, mae: 0.051473, r2: 0.745557, val_loss: 0.006116, val_mae: 0.054584, val_r2: 0.709544
2024-05-17 18:05:15 Epoch 19: lr=5e-05
2024-05-17 18:06:27 [Epoch: 19] loss: 0.005246, mae: 0.051343, r2: 0.747111, val_loss: 0.006090, val_mae: 0.054323, val_r2: 0.711281
2024-05-17 18:06:27 Epoch 20: lr=5e-05
2024-05-17 18:07:40 [Epoch: 20] loss: 0.005211, mae: 0.051137, r2: 0.748636, val_loss: 0.006098, val_mae: 0.054930, val_r2: 0.710443
2024-05-17 18:07:40 Epoch 21: lr=5e-05
2024-05-17 18:08:53 [Epoch: 21] loss: 0.005193, mae: 0.051067, r2: 0.749549, val_loss: 0.006103, val_mae: 0.055111, val_r2: 0.710068
2024-05-17 18:08:53 Epoch 22: lr=2.5e-05
2024-05-17 18:10:06 [Epoch: 22] loss: 0.005131, mae: 0.050762, r2: 0.752366, val_loss: 0.006085, val_mae: 0.054616, val_r2: 0.710403
2024-05-17 18:10:06 Epoch 23: lr=2.5e-05
2024-05-17 18:11:19 [Epoch: 23] loss: 0.005103, mae: 0.050654, r2: 0.753892, val_loss: 0.006088, val_mae: 0.054515, val_r2: 0.711274
2024-05-17 18:11:19 Epoch 24: lr=2.5e-05
2024-05-17 18:12:32 [Epoch: 24] loss: 0.005093, mae: 0.050595, r2: 0.754043, val_loss: 0.006101, val_mae: 0.054415, val_r2: 0.709987
2024-05-17 18:12:32 Epoch 25: lr=2.5e-05
2024-05-17 18:13:44 [Epoch: 25] loss: 0.005088, mae: 0.050597, r2: 0.754270, val_loss: 0.006073, val_mae: 0.054456, val_r2: 0.711230
2024-05-17 18:13:44 Epoch 26: lr=2.5e-05
2024-05-17 18:14:57 [Epoch: 26] loss: 0.005066, mae: 0.050471, r2: 0.755423, val_loss: 0.006077, val_mae: 0.054375, val_r2: 0.711031
2024-05-17 18:14:57 Epoch 27: lr=1.25e-05
2024-05-17 18:16:10 [Epoch: 27] loss: 0.005029, mae: 0.050318, r2: 0.757058, val_loss: 0.006071, val_mae: 0.054460, val_r2: 0.711534
2024-05-17 18:16:10 Epoch 28: lr=1.25e-05
2024-05-17 18:17:23 [Epoch: 28] loss: 0.005021, mae: 0.050294, r2: 0.757174, val_loss: 0.006085, val_mae: 0.054399, val_r2: 0.710795
2024-05-17 18:17:23 Epoch 29: lr=1.25e-05
2024-05-17 18:18:35 [Epoch: 29] loss: 0.005016, mae: 0.050247, r2: 0.757794, val_loss: 0.006097, val_mae: 0.054594, val_r2: 0.710453
2024-05-17 18:18:35 Epoch 30: lr=1.25e-05
2024-05-17 18:19:48 [Epoch: 30] loss: 0.004999, mae: 0.050160, r2: 0.758626, val_loss: 0.006077, val_mae: 0.054438, val_r2: 0.711067
2024-05-17 18:19:48 Epoch 31: lr=1.25e-05
2024-05-17 18:21:01 [Epoch: 31] loss: 0.005002, mae: 0.050192, r2: 0.758170, val_loss: 0.006110, val_mae: 0.054342, val_r2: 0.709472
2024-05-17 18:21:01 Epoch 32: lr=1e-05
2024-05-17 18:22:14 [Epoch: 32] loss: 0.004992, mae: 0.050097, r2: 0.758693, val_loss: 0.006079, val_mae: 0.054512, val_r2: 0.711120
2024-05-17 18:22:14 Epoch 33: lr=1e-05
2024-05-17 18:23:26 [Epoch: 33] loss: 0.004979, mae: 0.050074, r2: 0.759500, val_loss: 0.006079, val_mae: 0.054358, val_r2: 0.711400
2024-05-17 18:23:26 Epoch 34: lr=1e-05
2024-05-17 18:24:39 [Epoch: 34] loss: 0.004966, mae: 0.050009, r2: 0.760138, val_loss: 0.006068, val_mae: 0.054456, val_r2: 0.711360
2024-05-17 18:24:39 Epoch 35: lr=1e-05
2024-05-17 18:25:51 [Epoch: 35] loss: 0.004969, mae: 0.050031, r2: 0.760194, val_loss: 0.006077, val_mae: 0.054429, val_r2: 0.711079
2024-05-17 18:25:51 Epoch 36: lr=1e-05
2024-05-17 18:27:04 [Epoch: 36] loss: 0.004963, mae: 0.049981, r2: 0.760022, val_loss: 0.006089, val_mae: 0.054543, val_r2: 0.710669
2024-05-17 18:27:04 Epoch 37: lr=1e-05
2024-05-17 18:28:17 [Epoch: 37] loss: 0.004952, mae: 0.049949, r2: 0.760796, val_loss: 0.006120, val_mae: 0.054383, val_r2: 0.709909
2024-05-17 18:28:17 Epoch 38: lr=1e-05
2024-05-17 18:29:30 [Epoch: 38] loss: 0.004949, mae: 0.049899, r2: 0.760840, val_loss: 0.006077, val_mae: 0.054378, val_r2: 0.711239
2024-05-17 18:29:30 Epoch 39: lr=1e-05
2024-05-17 18:30:42 [Epoch: 39] loss: 0.004948, mae: 0.049930, r2: 0.761002, val_loss: 0.006066, val_mae: 0.054207, val_r2: 0.711368
2024-05-17 18:30:42 Epoch 40: lr=1e-05
2024-05-17 18:31:55 [Epoch: 40] loss: 0.004946, mae: 0.049886, r2: 0.761067, val_loss: 0.006089, val_mae: 0.054306, val_r2: 0.711045
2024-05-17 18:31:55 Epoch 41: lr=1e-05
2024-05-17 18:33:07 [Epoch: 41] loss: 0.004930, mae: 0.049833, r2: 0.761933, val_loss: 0.006088, val_mae: 0.054190, val_r2: 0.710812
2024-05-17 18:33:08 Epoch 42: lr=1e-05
2024-05-17 18:34:21 [Epoch: 42] loss: 0.004936, mae: 0.049853, r2: 0.761546, val_loss: 0.006111, val_mae: 0.054167, val_r2: 0.709761
2024-05-17 18:34:21 Epoch 43: lr=1e-05
2024-05-17 18:35:34 [Epoch: 43] loss: 0.004931, mae: 0.049819, r2: 0.761741, val_loss: 0.006067, val_mae: 0.054408, val_r2: 0.711689
2024-05-17 18:35:34 Epoch 44: lr=1e-05
2024-05-17 18:36:46 [Epoch: 44] loss: 0.004917, mae: 0.049758, r2: 0.762377, val_loss: 0.006097, val_mae: 0.054536, val_r2: 0.709978
2024-05-17 18:36:46 Epoch 45: lr=1e-05
2024-05-17 18:37:59 [Epoch: 45] loss: 0.004910, mae: 0.049759, r2: 0.762502, val_loss: 0.006089, val_mae: 0.054352, val_r2: 0.710004
2024-05-17 18:37:59 Epoch 46: lr=1e-05
2024-05-17 18:39:11 [Epoch: 46] loss: 0.004914, mae: 0.049732, r2: 0.762506, val_loss: 0.006080, val_mae: 0.054339, val_r2: 0.710992
2024-05-17 18:39:11 Epoch 47: lr=1e-05
2024-05-17 18:40:23 [Epoch: 47] loss: 0.004903, mae: 0.049699, r2: 0.763118, val_loss: 0.006105, val_mae: 0.054535, val_r2: 0.709319
2024-05-17 18:40:23 Epoch 48: lr=1e-05
2024-05-17 18:41:35 [Epoch: 48] loss: 0.004896, mae: 0.049682, r2: 0.763327, val_loss: 0.006092, val_mae: 0.054447, val_r2: 0.710444
2024-05-17 18:41:35 Epoch 49: lr=1e-05
2024-05-17 18:42:48 [Epoch: 49] loss: 0.004901, mae: 0.049699, r2: 0.762988, val_loss: 0.006065, val_mae: 0.054162, val_r2: 0.711715
2024-05-17 18:42:48 Epoch 50: lr=1e-05
2024-05-17 18:44:00 [Epoch: 50] loss: 0.004884, mae: 0.049640, r2: 0.763985, val_loss: 0.006072, val_mae: 0.054239, val_r2: 0.711555
2024-05-17 18:44:00 Epoch 51: lr=1e-05
2024-05-17 18:45:12 [Epoch: 51] loss: 0.004884, mae: 0.049595, r2: 0.763896, val_loss: 0.006087, val_mae: 0.054255, val_r2: 0.711107
2024-05-17 18:45:12 Epoch 52: lr=1e-05
2024-05-17 18:46:24 [Epoch: 52] loss: 0.004884, mae: 0.049568, r2: 0.764079, val_loss: 0.006103, val_mae: 0.054384, val_r2: 0.709861
2024-05-17 18:46:24 Epoch 53: lr=1e-05
2024-05-17 18:47:36 [Epoch: 53] loss: 0.004869, mae: 0.049551, r2: 0.764612, val_loss: 0.006069, val_mae: 0.054154, val_r2: 0.711468
2024-05-17 18:47:37 Epoch 54: lr=1e-05
2024-05-17 18:48:49 [Epoch: 54] loss: 0.004867, mae: 0.049527, r2: 0.764683, val_loss: 0.006099, val_mae: 0.054393, val_r2: 0.710221
2024-05-17 18:48:49 Epoch 55: lr=1e-05
2024-05-17 18:50:01 [Epoch: 55] loss: 0.004870, mae: 0.049529, r2: 0.764568, val_loss: 0.006064, val_mae: 0.054125, val_r2: 0.711752
2024-05-17 18:50:01 Epoch 56: lr=1e-05
2024-05-17 18:51:13 [Epoch: 56] loss: 0.004852, mae: 0.049451, r2: 0.765396, val_loss: 0.006077, val_mae: 0.054161, val_r2: 0.711511
2024-05-17 18:51:13 Epoch 57: lr=1e-05
2024-05-17 18:52:25 [Epoch: 57] loss: 0.004863, mae: 0.049475, r2: 0.764887, val_loss: 0.006077, val_mae: 0.054273, val_r2: 0.711160
2024-05-17 18:52:25 Epoch 58: lr=1e-05
2024-05-17 18:53:37 [Epoch: 58] loss: 0.004848, mae: 0.049433, r2: 0.765601, val_loss: 0.006073, val_mae: 0.054261, val_r2: 0.711811
2024-05-17 18:53:38 Epoch 59: lr=1e-05
2024-05-17 18:54:50 [Epoch: 59] loss: 0.004849, mae: 0.049417, r2: 0.765395, val_loss: 0.006082, val_mae: 0.054514, val_r2: 0.710611
2024-05-17 18:54:50 Epoch 60: lr=1e-05
2024-05-17 18:56:02 [Epoch: 60] loss: 0.004838, mae: 0.049394, r2: 0.765982, val_loss: 0.006078, val_mae: 0.054243, val_r2: 0.710765
2024-05-17 18:56:02 Epoch 61: lr=1e-05
2024-05-17 18:57:14 [Epoch: 61] loss: 0.004844, mae: 0.049384, r2: 0.765642, val_loss: 0.006072, val_mae: 0.054126, val_r2: 0.711572
2024-05-17 18:57:14 Epoch 62: lr=1e-05
2024-05-17 18:58:26 [Epoch: 62] loss: 0.004835, mae: 0.049390, r2: 0.766262, val_loss: 0.006089, val_mae: 0.054348, val_r2: 0.710560
2024-05-17 18:58:26 Epoch 63: lr=1e-05
2024-05-17 18:59:38 [Epoch: 63] loss: 0.004832, mae: 0.049343, r2: 0.766534, val_loss: 0.006083, val_mae: 0.054106, val_r2: 0.711149
2024-05-17 18:59:38 Epoch 64: lr=1e-05
2024-05-17 19:00:50 [Epoch: 64] loss: 0.004828, mae: 0.049340, r2: 0.766466, val_loss: 0.006077, val_mae: 0.054101, val_r2: 0.711560
2024-05-17 19:00:50 Epoch 65: lr=1e-05
2024-05-17 19:02:02 [Epoch: 65] loss: 0.004823, mae: 0.049321, r2: 0.766775, val_loss: 0.006063, val_mae: 0.054199, val_r2: 0.711852
2024-05-17 19:02:03 Epoch 66: lr=1e-05
2024-05-17 19:03:15 [Epoch: 66] loss: 0.004816, mae: 0.049309, r2: 0.766980, val_loss: 0.006079, val_mae: 0.054191, val_r2: 0.710884
2024-05-17 19:03:15 Epoch 67: lr=1e-05
2024-05-17 19:04:27 [Epoch: 67] loss: 0.004803, mae: 0.049215, r2: 0.767850, val_loss: 0.006104, val_mae: 0.054282, val_r2: 0.709350
2024-05-17 19:04:27 Epoch 68: lr=1e-05
2024-05-17 19:05:39 [Epoch: 68] loss: 0.004796, mae: 0.049207, r2: 0.768223, val_loss: 0.006074, val_mae: 0.054116, val_r2: 0.711744
2024-05-17 19:05:39 Epoch 69: lr=1e-05
2024-05-17 19:06:51 [Epoch: 69] loss: 0.004790, mae: 0.049173, r2: 0.768179, val_loss: 0.006088, val_mae: 0.054169, val_r2: 0.710767
2024-05-17 19:06:52 Epoch 70: lr=1e-05
2024-05-17 19:08:04 [Epoch: 70] loss: 0.004797, mae: 0.049231, r2: 0.768076, val_loss: 0.006081, val_mae: 0.054231, val_r2: 0.712102
2024-05-17 19:08:04 Epoch 71: lr=1e-05
2024-05-17 19:09:16 [Epoch: 71] loss: 0.004787, mae: 0.049151, r2: 0.768612, val_loss: 0.006076, val_mae: 0.054243, val_r2: 0.711039
2024-05-17 19:09:16 Epoch 72: lr=1e-05
2024-05-17 19:10:28 [Epoch: 72] loss: 0.004765, mae: 0.049075, r2: 0.769489, val_loss: 0.006099, val_mae: 0.054230, val_r2: 0.710070
2024-05-17 19:10:28 Epoch 73: lr=1e-05
2024-05-17 19:11:40 [Epoch: 73] loss: 0.004782, mae: 0.049117, r2: 0.768893, val_loss: 0.006088, val_mae: 0.054176, val_r2: 0.710273
2024-05-17 19:11:40 Epoch 74: lr=1e-05
2024-05-17 19:12:53 [Epoch: 74] loss: 0.004774, mae: 0.049060, r2: 0.769217, val_loss: 0.006083, val_mae: 0.054009, val_r2: 0.711124
2024-05-17 19:12:53 history_length: 75
2024-05-17 19:12:53 stopping: complete
2024-05-17 19:12:53 Comparing y_true and y_pred:
2024-05-17 19:12:53   mse: 0.04107735
2024-05-17 19:12:53   mae: 0.18286517
2024-05-17 19:12:53   r2: -3.91533380
2024-05-17 19:12:53   corr: 0.27961004
